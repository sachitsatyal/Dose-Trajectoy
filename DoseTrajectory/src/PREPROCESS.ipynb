{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "747ad4e8",
   "metadata": {},
   "source": [
    "## Examining the MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed613426",
   "metadata": {
    "id": "7f38de35-7f6f-4e53-802e-dec368830b62",
    "outputId": "17cb5bda-fbc9-4eb6-ab38-e5b24e15e8e8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'file_path' with the path to your data file\n",
    "file_path = 'Dataset/GSE206125/GSE206125_kuramochi_C_to_T320_metadata_g1.tsv'\n",
    "\n",
    "# Load the metadata file with tab-separated values\n",
    "metadata_df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Display the columns to understand the structure\n",
    "print(\"Columns in the metadata file:\")\n",
    "print(metadata_df.columns)\n",
    "\n",
    "# Display a sample of the data to inspect the first few rows\n",
    "print(\"\\nSample rows of the metadata file:\")\n",
    "print(metadata_df.head())\n",
    "\n",
    "# Check unique values in 'orig.ident'\n",
    "if 'orig.ident' in metadata_df.columns:\n",
    "    unique_orig_ident = metadata_df['orig.ident'].unique()\n",
    "    print(\"\\nUnique values in 'orig.ident':\")\n",
    "    print(unique_orig_ident)\n",
    "else:\n",
    "    print(\"\\nColumn 'orig.ident' not found in the metadata file. Please check column names.\")\n",
    "\n",
    "# Count the distribution of samples across unique 'orig.ident' values\n",
    "if 'orig.ident' in metadata_df.columns:\n",
    "    print(\"\\nDistribution of samples by 'orig.ident':\")\n",
    "    print(metadata_df['orig.ident'].value_counts())\n",
    "else:\n",
    "    print(\"\\nCannot count 'orig.ident' as the column does not exist.\")\n",
    "print((metadata_df['State'].unique()))\n",
    "metadata_df.groupby('orig.ident')['State'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477eda1f",
   "metadata": {},
   "source": [
    "## PLotting to find the Outliers and Unwanted nUMI, nGene and percent.mito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d53913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the metadata\n",
    "file_path = 'Dataset/GSE206125/GSE206125_kuramochi_C_to_T320_metadata_g1.tsv'  # Update this path\n",
    "metadata_df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Set up figure layout\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot Histogram of nGene\n",
    "sns.histplot(metadata_df['nGene'], bins=50, kde=True, ax=axes[0])\n",
    "axes[0].set_title(\"Distribution of nGene\")\n",
    "axes[0].set_xlabel(\"nGene (Number of Genes per Cell)\")\n",
    "\n",
    "# Plot Histogram of nUMI\n",
    "sns.histplot(metadata_df['nUMI'], bins=50, kde=True, ax=axes[1])\n",
    "axes[1].set_title(\"Distribution of nUMI\")\n",
    "axes[1].set_xlabel(\"nUMI (Total UMI Counts per Cell)\")\n",
    "\n",
    "# Plot Histogram of percent.mito\n",
    "sns.histplot(metadata_df['percent.mito'], bins=50, kde=True, ax=axes[2])\n",
    "axes[2].set_title(\"Distribution of percent.mito\")\n",
    "axes[2].set_xlabel(\"Mitochondrial Percentage per Cell\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ac204",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ nGene (Number of Genes Detected per Cell)\n",
    "\n",
    "Most cells have 500-2500 detected genes, with a long tail extending to ~5000.\n",
    "\n",
    "Sharp drop-off beyond ~3500 genes, suggesting potential doublets (two cells merged into one during capture).\n",
    "\n",
    "A few very low-gene-count cells (~200 genes), likely empty droplets or dead cells.\n",
    "\n",
    "üìå Filter:\n",
    "\n",
    "Remove cells with nGene < 200 (likely empty droplets).\n",
    "Remove cells with nGene > 4000 (likely doublets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7acb462",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£  nUMI (Total UMI Counts per Cell)\n",
    "\n",
    "Most cells have 1000-5000 UMI counts.\n",
    "\n",
    "Some extreme values (~15,000+) are likely doublets or over-sequenced cells.\n",
    "\n",
    "A sharp peak at very low UMI counts suggests the presence of low-quality cells or empty droplets.\n",
    "\n",
    "üìåFilter:\n",
    "\n",
    "Remove cells with nUMI < 500 (likely low-quality).\n",
    "\n",
    "Remove cells with nUMI > 15,000 (possible doublets or over-sequencing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af18854",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ percent.mito (Mitochondrial RNA Fraction)\n",
    "\n",
    "Most cells fall between 5-12% mitochondrial RNA.\n",
    "\n",
    "A gradual decline starts beyond 12%, with a sharper drop beyond 15%.\n",
    "\n",
    "Very few cells exceed 15%, suggesting apoptosis or stress.\n",
    "\n",
    "üìå Filter:\n",
    "\n",
    "Keep cells with percent.mito < 15%.\n",
    "Remove cells with percent.mito > 15% (likely stressed or apoptotic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7cdc6c",
   "metadata": {},
   "source": [
    "## FIltering on Basis of PLot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d573c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filtering thresholds\n",
    "min_genes = 200\n",
    "max_genes = 4000\n",
    "min_umi = 500\n",
    "max_umi = 15000\n",
    "max_mito = 0.15  # 15%\n",
    "\n",
    "# Apply the filters\n",
    "filtered_metadata = metadata_df[\n",
    "    (metadata_df['nGene'] > min_genes) &\n",
    "    (metadata_df['nGene'] < max_genes) &\n",
    "    (metadata_df['nUMI'] > min_umi) &\n",
    "    (metadata_df['nUMI'] < max_umi) &\n",
    "    (metadata_df['percent.mito'] < max_mito)\n",
    "]\n",
    "\n",
    "# Print results\n",
    "print(f\"Original cell count: {metadata_df.shape[0]}\")\n",
    "print(f\"Filtered cell count: {filtered_metadata.shape[0]}\")\n",
    "\n",
    "# Save the filtered metadata\n",
    "filtered_metadata.to_csv('Dataset/GSE206125/filtered_metadata.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata\n",
    "file_path = 'Dataset/GSE206125/filtered_metadata.tsv'  # Update this path\n",
    "metadata_df = pd.read_csv(file_path, sep='\\t')\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42760c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata_df[\"orig.ident\"].value_counts())  # See all dosage groups in metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e270ea",
   "metadata": {},
   "source": [
    "## Loading scRNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0857e6a9",
   "metadata": {
    "id": "1aafc30c-7249-410e-85d6-37df0e7f59cd",
    "outputId": "62481501-52fd-41dd-ea4f-50c84366ea0b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the metadata file\n",
    "metadata_path = \"Dataset/GSE206125/filtered_metadata.tsv\"\n",
    "metadata_df = pd.read_csv(metadata_path, sep=\"\\t\")\n",
    "\n",
    "# Load the expression matrix\n",
    "expression_path = \"Dataset/GSE206125/kuramochi_all_C_to_T320_filtered.csv\"\n",
    "expression_df = pd.read_csv(expression_path, sep=\",\", index_col=0)  # Ensure gene names are the index\n",
    "\n",
    "print(\"Metadata and expression data loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6614a17",
   "metadata": {},
   "source": [
    "## Merging scRNA  data with Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab49d10",
   "metadata": {},
   "source": [
    "### Check mismatches between metadata and expression matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db5185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix naming inconsistencies in metadata cell names\n",
    "metadata_df[\"cell\"] = (\n",
    "    metadata_df[\"cell\"]\n",
    "    .str.replace(\"2nd\", \"\", regex=True)  # Remove \"2nd_\" from metadata\n",
    "    .str.replace(\"ctrlI\", \"ctrl\", regex=True)  # Ensure \"ctrlI\" is replaced with \"ctrl\"\n",
    "    .str.strip()  # Remove leading/trailing spaces\n",
    ")\n",
    "\n",
    "# Fix naming inconsistencies in expression matrix column names\n",
    "expression_df.columns = (\n",
    "    expression_df.columns\n",
    "    .str.replace(\"2nd\", \"\", regex=True)  # Remove \"2nd_\" from expression data\n",
    "    .str.replace(\"ctrlI\", \"ctrl\", regex=True)  # Ensure \"ctrlI\" is replaced with \"ctrl\"\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Naming inconsistencies fixed for both metadata and expression data!\")\n",
    "\n",
    "\n",
    "print(\"Renaming fixes applied successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1932d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cell names to sets for comparison\n",
    "metadata_cells = set(metadata_df[\"cell\"].str.strip())  # Remove extra spaces\n",
    "expression_cells = set(expression_df.columns.str.strip())  # Ensure clean column names\n",
    "\n",
    "# Find missing cell barcodes\n",
    "missing_meta_cells = list(metadata_cells - expression_cells)\n",
    "missing_expr_cells = list(expression_cells - metadata_cells)\n",
    "\n",
    "print(f\"Cells in metadata but missing in expression matrix: {len(missing_meta_cells)}\")\n",
    "print(f\"Example missing in expression: {missing_meta_cells[:10]}\")\n",
    "\n",
    "print(f\"Cells in expression matrix but missing in metadata: {len(missing_expr_cells)}\")\n",
    "print(f\"Example missing in metadata: {missing_expr_cells[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04951d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update metadata and expression cell lists\n",
    "metadata_cells = set(metadata_df[\"cell\"])\n",
    "expression_cells = set(expression_df.columns)\n",
    "\n",
    "# Find the intersection (common cells)\n",
    "matching_cells = list(metadata_cells & expression_cells)\n",
    "\n",
    "print(f\"Final matching cells count after renaming: {len(matching_cells)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29041490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only matching cells in metadata\n",
    "metadata_df = metadata_df[metadata_df[\"cell\"].isin(matching_cells)]\n",
    "\n",
    "# Keep only matching columns in expression matrix\n",
    "expression_df = expression_df[matching_cells]\n",
    "\n",
    "print(\"Filtered both datasets to include only matching cells.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a95629",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13c1a1",
   "metadata": {
    "id": "5653de11-9fc9-481f-b11e-c6e97644e3f6",
    "outputId": "326aee38-145b-4130-f65c-306d2ab652f7"
   },
   "outputs": [],
   "source": [
    "# Merge metadata with expression matrix (transpose expression matrix)\n",
    "merged_df = metadata_df.set_index(\"cell\").join(expression_df.T, how=\"inner\")\n",
    "\n",
    "# Save the merged dataset\n",
    "merged_df.to_csv(\"Dataset/GSE206125/merged_scRNA_metadata.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "merger = \"Dataset/GSE206125/merged_scRNA_metadata.tsv\"\n",
    "merged_df = pd.read_csv(merger, sep=\"\\t\", index_col=0)  # Ensure gene names are the index\n",
    "\n",
    "print(f\"Final merged dataset shape: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8878bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of control cells\n",
    "control_cells_in_merged = merged_df[merged_df[\"orig.ident\"] == \"C\"]\n",
    "\n",
    "print(f\"Number of control cells in merged dataset: {control_cells_in_merged.shape[0]}\")\n",
    "\n",
    "# Show some control cell rows\n",
    "print(\"Sample control cells in merged dataset:\")\n",
    "print(control_cells_in_merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66be0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of cells per dosage and state\n",
    "dosage_state_counts = merged_df.groupby([\"orig.ident\", \"State\"]).size().reset_index(name=\"Cell Count\")\n",
    "\n",
    "# Print the table\n",
    "print(\"Number of cells for each dosage with state:\")\n",
    "print(dosage_state_counts)\n",
    "\n",
    "# Display in pivot format for easier viewing\n",
    "pivot_table = dosage_state_counts.pivot(index=\"orig.ident\", columns=\"State\", values=\"Cell Count\").fillna(0)\n",
    "\n",
    "# Print the pivot table\n",
    "print(\"\\nPivot Table of Cell Counts (Dosage √ó State):\")\n",
    "print(pivot_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd60122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index if the cell barcodes are stored as an index\n",
    "merged_df = merged_df.reset_index()\n",
    "\n",
    "# Rename the first column correctly\n",
    "merged_df = merged_df.rename(columns={merged_df.columns[0]: \"cell\"})\n",
    "\n",
    "# Verify the change\n",
    "print(\"‚úÖ First column correctly renamed to 'cell':\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0bb546",
   "metadata": {},
   "source": [
    "## DIfferential Gene Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab323c",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28754e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract expression matrix (excluding metadata columns)\n",
    "expression_data = merged_df.drop(columns=[\"cell\", \"nGene\", \"nUMI\", \"orig.ident\", \"percent.mito\", \"State\"])\n",
    "\n",
    "# Perform log1p normalization (log(x+1) transformation)\n",
    "normalized_data = np.log1p(expression_data)\n",
    "\n",
    "# Add metadata back to the normalized dataframe\n",
    "normalized_df = merged_df[[\"cell\", \"nGene\", \"nUMI\", \"orig.ident\", \"percent.mito\", \"State\"]].join(normalized_data)\n",
    "\n",
    "print(\"‚úÖ Normalization complete. Data is now log-transformed and ready for DEG analysis.\")\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeab80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged dataset\n",
    "normalized_df.to_csv(\"Dataset/GSE206125/merged_scRNA_metadata_normalized.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012fb649",
   "metadata": {},
   "source": [
    "### Load normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcc8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "merger = \"Dataset/GSE206125/merged_scRNA_metadata_normalized.tsv\"\n",
    "normalized_df = pd.read_csv(merger, sep=\"\\t\", index_col=0)  # Ensure gene names are the index\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f28f7e3",
   "metadata": {},
   "source": [
    "## DEG for dosage vs control group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Ensure normalized_df is loaded\n",
    "# Extract unique dosages (excluding control 'C')\n",
    "dosage_groups = normalized_df[\"orig.ident\"].unique().tolist()\n",
    "dosage_groups.remove(\"C\")  # Remove control from the list\n",
    "\n",
    "# Define base directory for storing results\n",
    "base_dir = \"DEG_Results\"\n",
    "os.makedirs(base_dir, exist_ok=True)  # Create the main directory if it doesn't exist\n",
    "\n",
    "# Extract control group expression data\n",
    "control_cells = normalized_df[normalized_df[\"orig.ident\"] == \"C\"].drop(\n",
    "    columns=[\"cell\", \"nGene\", \"nUMI\", \"orig.ident\", \"percent.mito\", \"State\"]\n",
    ")\n",
    "control_cells = control_cells.apply(pd.to_numeric, errors=\"coerce\")  # Ensure numeric\n",
    "control_cells = control_cells.dropna(axis=1, how=\"all\")  # Drop genes with all NaNs\n",
    "\n",
    "# Remove genes that have zero expression in ALL control samples\n",
    "nonzero_genes_control = control_cells.columns[(control_cells.sum(axis=0) > 0)]\n",
    "control_cells = control_cells[nonzero_genes_control]  # Keep only expressed genes\n",
    "\n",
    "# Perform DEG analysis for each dosage vs. control\n",
    "deg_results = {}\n",
    "\n",
    "for dosage in dosage_groups:\n",
    "    print(f\"Processing {dosage} vs. Control...\")\n",
    "\n",
    "    # Create a folder for the current dosage\n",
    "    dosage_folder = os.path.join(base_dir, f\"DEG_{dosage}\")\n",
    "    os.makedirs(dosage_folder, exist_ok=True)\n",
    "\n",
    "    # Extract expression data for the current dosage\n",
    "    dosage_cells = normalized_df[normalized_df[\"orig.ident\"] == dosage].drop(\n",
    "        columns=[\"cell\", \"nGene\", \"nUMI\", \"orig.ident\", \"percent.mito\", \"State\"]\n",
    "    )\n",
    "    dosage_cells = dosage_cells.apply(pd.to_numeric, errors=\"coerce\")  # Ensure numeric\n",
    "    dosage_cells = dosage_cells.dropna(axis=1, how=\"all\")  # Drop genes with all NaNs\n",
    "\n",
    "    # Keep only genes that are expressed in at least one dosage sample\n",
    "    nonzero_genes_dosage = dosage_cells.columns[(dosage_cells.sum(axis=0) > 0)]\n",
    "    dosage_cells = dosage_cells[nonzero_genes_dosage]  # Keep only expressed genes\n",
    "\n",
    "    # Find the intersection of genes present in both control and dosage\n",
    "    common_genes = list(set(control_cells.columns) & set(dosage_cells.columns))\n",
    "\n",
    "    # Filter control and dosage to keep only these genes\n",
    "    control_cells_filtered = control_cells[common_genes]\n",
    "    dosage_cells_filtered = dosage_cells[common_genes]\n",
    "\n",
    "    p_values = []\n",
    "    log_fold_changes = []\n",
    "    retained_genes = []\n",
    "\n",
    "    for gene in common_genes:\n",
    "        # Drop NaN values before performing statistical tests\n",
    "        control_values = control_cells_filtered[gene].dropna()\n",
    "        dosage_values = dosage_cells_filtered[gene].dropna()\n",
    "\n",
    "        # Skip genes that are empty after filtering\n",
    "        if control_values.empty or dosage_values.empty:\n",
    "            continue\n",
    "\n",
    "        # Skip genes that have zero expression in both groups\n",
    "        if (control_values.sum() == 0 and dosage_values.sum() == 0):\n",
    "            continue\n",
    "\n",
    "        # Perform Wilcoxon test\n",
    "        try:\n",
    "            stat, p_val = stats.mannwhitneyu(dosage_values, control_values, alternative=\"two-sided\")\n",
    "        except ValueError:\n",
    "            continue  # Skip genes with only a single unique value\n",
    "\n",
    "        # Compute log fold-change\n",
    "        log_fc = dosage_values.mean() - control_values.mean()\n",
    "\n",
    "        p_values.append(p_val)\n",
    "        log_fold_changes.append(log_fc)\n",
    "        retained_genes.append(gene)\n",
    "\n",
    "    # Store DEG results in a DataFrame\n",
    "    deg_df = pd.DataFrame({\"Gene\": retained_genes, \"P-Value\": p_values, \"Log2FC\": log_fold_changes})\n",
    "\n",
    "    # Apply significance filtering (p-value < 0.05 and abs(Log2FC) > 0.5)\n",
    "    deg_df = deg_df[(deg_df[\"P-Value\"] < 0.05) & (abs(deg_df[\"Log2FC\"]) > 0.4)]\n",
    "\n",
    "    # Save results in the respective dosage folder\n",
    "    file_path = os.path.join(dosage_folder, f\"DEG_{dosage}_vs_Control.csv\")\n",
    "    deg_df.to_csv(file_path, index=False)\n",
    "    deg_results[dosage] = deg_df\n",
    "\n",
    "    print(f\"‚úÖ Saved: {file_path} (Total DEGs: {len(deg_df)})\")\n",
    "\n",
    "print(\"\\nüéØ All DEG results have been stored in respective folders!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d3cf9d",
   "metadata": {},
   "source": [
    "## DEG among States within each Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b217e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import scipy.stats as stats\n",
    "\n",
    "# # Define base directory\n",
    "# base_dir = \"DEG_Results\"\n",
    "\n",
    "# # Perform DEG analysis for each dosage comparing different states\n",
    "# for dosage in dosage_groups:\n",
    "#     print(f\"\\nüîπ Processing {dosage} - State-wise DEG Analysis\")\n",
    "\n",
    "#     # Define folder for the dosage\n",
    "#     dosage_folder = os.path.join(base_dir, f\"DEG_{dosage}\")\n",
    "\n",
    "#     # Identify the unique states in this dosage\n",
    "#     dosage_df = normalized_df[normalized_df[\"orig.ident\"] == dosage]\n",
    "#     states = sorted(dosage_df[\"State\"].unique())  # Sort for correct order\n",
    "\n",
    "#     # Compare consecutive states within the dosage\n",
    "#     for i in range(len(states) - 1):\n",
    "#         state_1 = states[i]\n",
    "#         state_2 = states[i + 1]\n",
    "\n",
    "#         print(f\"üî¨ Comparing {dosage}: {state_1} vs. {state_2}\")\n",
    "\n",
    "#         # Extract expression data for both states\n",
    "#         state_1_cells = dosage_df[dosage_df[\"State\"] == state_1].drop(columns=[\"cell\", \"nGene\", \"nUMI\", \"orig.ident\", \"percent.mito\", \"State\"])\n",
    "#         state_2_cells = dosage_df[dosage_df[\"State\"] == state_2].drop(columns=[\"cell\", \"nGene\", \"nUMI\", \"orig.ident\", \"percent.mito\", \"State\"])\n",
    "\n",
    "#         # Ensure numeric data\n",
    "#         state_1_cells = state_1_cells.apply(pd.to_numeric, errors=\"coerce\")\n",
    "#         state_2_cells = state_2_cells.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "#         # Perform Wilcoxon Rank-Sum Test (Mann-Whitney U test) for each gene\n",
    "#         p_values = []\n",
    "#         log_fold_changes = []\n",
    "#         valid_genes = []\n",
    "\n",
    "#         for gene in state_1_cells.columns:\n",
    "#             if gene in state_2_cells.columns:\n",
    "#                 # Drop NaNs\n",
    "#                 gene_state_1 = state_1_cells[gene].dropna()\n",
    "#                 gene_state_2 = state_2_cells[gene].dropna()\n",
    "\n",
    "#                 # Skip genes with insufficient data points\n",
    "#                 if len(gene_state_1) < 2 or len(gene_state_2) < 2:\n",
    "#                     continue\n",
    "\n",
    "#                 try:\n",
    "#                     stat, p_val = stats.mannwhitneyu(gene_state_1, gene_state_2, alternative=\"two-sided\")\n",
    "\n",
    "#                     # Compute log2 fold change using log-transformed means\n",
    "#                     mean_s1 = np.mean(gene_state_1)\n",
    "#                     mean_s2 = np.mean(gene_state_2)\n",
    "\n",
    "#                     log_fc = np.log2(mean_s2 + 1e-6) - np.log2(mean_s1 + 1e-6)  # Avoid log(0)\n",
    "\n",
    "#                     p_values.append(p_val)\n",
    "#                     log_fold_changes.append(log_fc)\n",
    "#                     valid_genes.append(gene)\n",
    "\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"‚ö†Ô∏è Skipping {gene} due to error: {e}\")\n",
    "#                     continue\n",
    "\n",
    "#         # Store DEG results in a DataFrame\n",
    "#         deg_df = pd.DataFrame({\"Gene\": valid_genes, \"P-Value\": p_values, \"Log2FC\": log_fold_changes})\n",
    "\n",
    "#         # Apply significance filtering (p-value < 0.05)\n",
    "#         deg_df = deg_df[(deg_df[\"P-Value\"] < 0.05) & (abs(deg_df[\"Log2FC\"]) > 2)]\n",
    "\n",
    "#         # Save results in dosage folder\n",
    "#         file_path = os.path.join(dosage_folder, f\"DEG_{dosage}_{state_1}_vs_{state_2}.csv\")\n",
    "#         deg_df.to_csv(file_path, index=False)\n",
    "\n",
    "#         print(f\"‚úÖ Saved: {file_path}\")\n",
    "\n",
    "# print(\"\\nüéØ State-wise DEG Analysis Completed for All Dosages!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755353d9",
   "metadata": {},
   "source": [
    "## DEG across all the Dosage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79320fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import scipy.stats as stats\n",
    "# import glob\n",
    "# import os\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# # Corrected path\n",
    "# deg_folder = \"DEG_Results/\"\n",
    "# deg_files = glob.glob(os.path.join(deg_folder, \"DEG_*\", \"DEG_*_vs_Control.csv\"))  # Search in subfolders\n",
    "\n",
    "# # Dictionary to store DEG data for each dosage\n",
    "# deg_data = {}\n",
    "\n",
    "# # Read all DEG results\n",
    "# for file in deg_files:\n",
    "#     dosage = file.split(\"/\")[-2]  # Extract dosage name from folder name\n",
    "#     df = pd.read_csv(file)\n",
    "#     df[\"Dosage\"] = dosage  # Add dosage column\n",
    "#     deg_data[dosage] = df\n",
    "\n",
    "# # Combine all DEGs into a single DataFrame\n",
    "# combined_deg_df = pd.concat(deg_data.values(), ignore_index=True)\n",
    "\n",
    "# ### Debugging: Check how many unique genes before filtering ###\n",
    "# print(f\"üîç Total unique genes before filtering: {combined_deg_df['Gene'].nunique()}\")\n",
    "\n",
    "# # Count occurrences of each gene across dosages\n",
    "# gene_counts = combined_deg_df[\"Gene\"].value_counts()\n",
    "# shared_genes = gene_counts[gene_counts >= 3].index  # Adjust threshold (keep genes appearing in at least 3 dosages)\n",
    "\n",
    "# # Filter for shared genes\n",
    "# global_deg_df = combined_deg_df[combined_deg_df[\"Gene\"].isin(shared_genes)]\n",
    "\n",
    "# # Debug: Check total before applying strict filters\n",
    "# print(f\"üîç Total DEGs before strict filtering: {global_deg_df.shape[0]}\")\n",
    "\n",
    "# # Adjust p-values for multiple testing (Benjamini-Hochberg FDR)\n",
    "# global_deg_df[\"Adjusted_P-Value\"] = multipletests(global_deg_df[\"P-Value\"], method=\"fdr_bh\")[1]\n",
    "\n",
    "# # Apply relaxed filtering\n",
    "# filtered_deg_df = global_deg_df[\n",
    "#     (global_deg_df[\"Adjusted_P-Value\"] < 0.05) &  # Less strict p-value\n",
    "#     (abs(global_deg_df[\"Log2FC\"]) > 1.2)  # Relaxed fold change\n",
    "# ]\n",
    "\n",
    "# # Debug: Check total after filtering\n",
    "# print(f\"üîç DEGs remaining after filtering: {filtered_deg_df.shape[0]}\")\n",
    "\n",
    "# # Save the refined Global DEG results inside DEG_Results/\n",
    "# filtered_deg_df.to_csv(os.path.join(deg_folder, \"Filtered_Global_DEGs.csv\"), index=False)\n",
    "\n",
    "# print(\"\\n‚úÖ Updated Global DEG Analysis Completed!\")\n",
    "# print(f\"üîπ Total DEGs After Filtering: {filtered_deg_df.shape[0]} (from original {combined_deg_df.shape[0]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d44940",
   "metadata": {},
   "source": [
    "## Global DEG basd on State for each dosage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a01d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import glob\n",
    "# import os\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# # Define the DEG folder\n",
    "# deg_folder = \"DEG_Results/\"\n",
    "# state_deg_files = glob.glob(os.path.join(deg_folder, \"DEG_*\", \"DEG_*_S*_vs_S*.csv\"))  # Updated pattern\n",
    "\n",
    "# # Dictionary to store state-wise DEGs for each dosage\n",
    "# state_deg_data = {}\n",
    "\n",
    "# # Read all state-wise DEG results\n",
    "# for file in state_deg_files:\n",
    "#     dosage = file.split(\"/\")[-2]  # Extract dosage from folder name\n",
    "#     df = pd.read_csv(file)\n",
    "#     df[\"Dosage\"] = dosage  # Add dosage column\n",
    "#     state_deg_data[dosage] = df\n",
    "\n",
    "# # Combine all state-specific DEGs\n",
    "# combined_state_deg_df = pd.concat(state_deg_data.values(), ignore_index=True)\n",
    "\n",
    "# # Count occurrences of each gene across different states\n",
    "# gene_counts = combined_state_deg_df[\"Gene\"].value_counts()\n",
    "# shared_genes = gene_counts[gene_counts >= 3].index  # Keep genes found in at least 3 different states\n",
    "\n",
    "# # Filter for shared genes across states\n",
    "# global_state_deg_df = combined_state_deg_df[combined_state_deg_df[\"Gene\"].isin(shared_genes)]\n",
    "\n",
    "# # Adjust p-values for multiple testing (Benjamini-Hochberg FDR)\n",
    "# global_state_deg_df[\"Adjusted_P-Value\"] = multipletests(global_state_deg_df[\"P-Value\"], method=\"fdr_bh\")[1]\n",
    "\n",
    "# # Apply stricter filtering\n",
    "# filtered_state_deg_df = global_state_deg_df[\n",
    "#     (global_state_deg_df[\"Adjusted_P-Value\"] < 0.05) &  # Significant genes\n",
    "#     (abs(global_state_deg_df[\"Log2FC\"]) > 1.5)  # Strongly up/downregulated genes\n",
    "# ]\n",
    "\n",
    "# # Save the refined Global State-Specific DEGs\n",
    "# filtered_state_deg_df.to_csv(os.path.join(deg_folder, \"Filtered_State_Global_DEGs.csv\"), index=False)\n",
    "\n",
    "# print(\"\\n‚úÖ Global State-Specific DEG Analysis Completed!\")\n",
    "# print(f\"üîπ Total DEGs After Filtering: {filtered_state_deg_df.shape[0]} (from original {combined_state_deg_df.shape[0]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274b46dc",
   "metadata": {},
   "source": [
    "## See Overlapping Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4620ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load the two DEG files\n",
    "# deg_dosage = pd.read_csv(\"DEG_Results/Filtered_Global_DEGs.csv\")\n",
    "# deg_state = pd.read_csv(\"DEG_Results/Filtered_State_Global_DEGs.csv\")\n",
    "\n",
    "# # Extract unique gene lists\n",
    "# genes_dosage = set(deg_dosage[\"Gene\"])\n",
    "# genes_state = set(deg_state[\"Gene\"])\n",
    "\n",
    "# # Find overlaps and unique genes\n",
    "# common_genes = genes_dosage & genes_state  # Intersection\n",
    "# only_in_dosage = genes_dosage - genes_state  # Unique to dosage-based DEGs\n",
    "# only_in_state = genes_state - genes_dosage  # Unique to state-based DEGs\n",
    "\n",
    "# # Print counts\n",
    "# print(f\"üîπ Total Global Dosage DEGs: {len(genes_dosage)}\")\n",
    "# print(f\"üîπ Total Global State DEGs: {len(genes_state)}\")\n",
    "# print(f\"‚úÖ Overlapping Genes: {len(common_genes)}\")\n",
    "# print(f\"‚ö° Genes only in Dosage DEGs: {len(only_in_dosage)}\")\n",
    "# print(f\"‚ö° Genes only in State DEGs: {len(only_in_state)}\")\n",
    "\n",
    "# # Save results for reference\n",
    "# overlap_df = pd.DataFrame({\"Gene\": list(common_genes)})\n",
    "# overlap_df.to_csv(\"DEG_Results/Overlapping_DEGs.csv\", index=False)\n",
    "\n",
    "# print(\"\\n‚úÖ Overlapping genes saved in 'DEG_Results/Overlapping_DEGs.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220c9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the two DEG files\n",
    "# deg_dosage = pd.read_csv(\"DEG_Results/Filtered_Global_DEGs.csv\")\n",
    "# deg_state = pd.read_csv(\"DEG_Results/Filtered_State_Global_DEGs.csv\")\n",
    "\n",
    "# # Combine both DataFrames\n",
    "# merged_deg_df = pd.concat([deg_dosage, deg_state], ignore_index=True)\n",
    "\n",
    "# # Remove duplicate genes while keeping the most significant row\n",
    "# merged_deg_df = merged_deg_df.sort_values(by=[\"P-Value\"]).drop_duplicates(subset=[\"Gene\"], keep=\"first\")\n",
    "\n",
    "# # Save the final merged DEG list\n",
    "# merged_deg_df.to_csv(\"DEG_Results/Final_Merged_Global_DEGs.csv\", index=False)\n",
    "\n",
    "# # Print summary\n",
    "# print(f\"‚úÖ Final Merged DEG List Created!\")\n",
    "# print(f\"üîπ Total Dosage Global DEGs: {deg_dosage.shape[0]}\")\n",
    "# print(f\"üîπ Total State Global DEGs: {deg_state.shape[0]}\")\n",
    "# print(f\"‚úÖ Final Unique Global DEGs: {merged_deg_df.shape[0]}\")\n",
    "# print(f\"üìÅ File saved at: 'DEG_Results/Final_Merged_Global_DEGs.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbda273",
   "metadata": {},
   "source": [
    "### Plan for Pathway Enrichment & Selecting Relevant Genes for Each Dosage Graph\n",
    "We have several DEG lists from different analyses, and now we need to:\n",
    "\n",
    "1. Find significant pathways involved in these DEGs.\n",
    "   \n",
    "3. Decide what genes to include in each dosage-specific graph while ensuring we capture both dosage-specific and global patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47624299",
   "metadata": {},
   "source": [
    "### Step 1: Pathway Enrichment Analysis\n",
    "\n",
    "We will perform Reactome & GO (Gene Ontology) enrichment analysis for different DEG lists: \n",
    "\n",
    "1Ô∏è‚É£ Final Merged Global DEGs ‚Üí To find pathways consistent across all dosages (core pathways).\n",
    "\n",
    "2Ô∏è‚É£ Each Dosage-Specific DEG ‚Üí To find pathways that are unique to each dosage (dosage adaptation) and stae within the dosage.\n",
    "\n",
    "How?\n",
    "\n",
    "Use Enrichr or gProfiler to perform pathway enrichment.\n",
    "\n",
    "Identify significant pathways (p < 0.05, adjusted for multiple testing).\n",
    "\n",
    "Reactome pathways for biological processes related to drug adaptation.\n",
    "\n",
    "GO pathways for molecular function and cellular processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e457c1a",
   "metadata": {},
   "source": [
    "## Gspeasy Implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6403fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gseapy as gp\n",
    "\n",
    "# Define directories\n",
    "deg_folder = \"DEG_Results\"\n",
    "polygenic_folder = os.path.join(deg_folder, \"Polygenic\")  # NEW: Store GSEAPY results\n",
    "os.makedirs(polygenic_folder, exist_ok=True)\n",
    "\n",
    "# ‚úÖ Matching Gene Sets for Comparison with gProfiler\n",
    "gene_sets = ['GO_Biological_Process_2021', 'Reactome_2022']  # MATCHING gProfiler\n",
    "\n",
    "# Function to perform pathway enrichment using GSEAPY\n",
    "def run_gseapy_enrichment(deg_file, output_name):\n",
    "    \"\"\"Runs GSEAPY enrichment analysis for a given DEG file.\"\"\"\n",
    "    df = pd.read_csv(deg_file)\n",
    "    \n",
    "    if \"Gene\" not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Warning: 'Gene' column not found in {deg_file}. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    genes = list(df[\"Gene\"])  # Extract gene list\n",
    "\n",
    "    if len(genes) > 0:\n",
    "        print(f\"üîπ Running enrichment for {output_name} ({len(genes)} genes)...\")\n",
    "\n",
    "        # Run enrichment analysis\n",
    "        enr = gp.enrichr(gene_list=genes, gene_sets=gene_sets, organism='Human', cutoff=0.05)\n",
    "\n",
    "        if enr is not None:\n",
    "            # Extract relevant columns\n",
    "            enriched_df = enr.results[['Term', 'P-value', 'Adjusted P-value', 'Combined Score', 'Genes']]\n",
    "\n",
    "            # Save results\n",
    "            output_path = os.path.join(polygenic_folder, f\"Polygenic_Enrichment_{output_name}.csv\")\n",
    "            enriched_df.to_csv(output_path, index=False)\n",
    "\n",
    "            print(f\"‚úÖ Saved: {output_path}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No significant pathways found for {output_name}.\")\n",
    "\n",
    "# 1Ô∏è‚É£ **Global DEG Pathway Analysis**\n",
    "global_deg_file = os.path.join(deg_folder, \"Final_Merged_Global_DEGs.csv\")\n",
    "run_gseapy_enrichment(global_deg_file, \"Global\")\n",
    "\n",
    "# 2Ô∏è‚É£ **Dosage-Specific DEG Pathway Analysis**\n",
    "dosage_groups = [d for d in os.listdir(deg_folder) if d.startswith(\"DEG_\") and d != \"Pathway_Results\"]\n",
    "\n",
    "for dosage in dosage_groups:\n",
    "    dosage_file = os.path.join(deg_folder, dosage, f\"{dosage}_vs_Control.csv\")\n",
    "    if os.path.exists(dosage_file):\n",
    "        run_gseapy_enrichment(dosage_file, dosage)\n",
    "\n",
    "    # 3Ô∏è‚É£ **State-Specific DEG Pathway Analysis within Each Dosage**\n",
    "    state_deg_files = [f for f in os.listdir(os.path.join(deg_folder, dosage)) if \"_S\" in f]\n",
    "    for state_file in state_deg_files:\n",
    "        state_file_path = os.path.join(deg_folder, dosage, state_file)\n",
    "        run_gseapy_enrichment(state_file_path, state_file.replace(\".csv\", \"\"))\n",
    "\n",
    "print(\"\\nüéØ **GSEAPY Pathway Enrichment Completed for All DEGs!**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483fd53a",
   "metadata": {},
   "source": [
    "### üîπ Step 3: Assigning Pathways to Each Dosage\n",
    "\n",
    "Extract significant pathways per dosage.\n",
    "\n",
    "Keep shared pathways (from global enrichment) in all graphs.\n",
    "\n",
    "Retain unique pathways (from dosage-specific enrichment) in respective dosage graphs.\n",
    "\n",
    "Genes in these pathways should be included in the final dosage-specific gene list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "polygenic_folder = \"DEG_Results/Polygenic\"\n",
    "final_enrichment_folder = \"DEG_Results/Final_Enrichment\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(final_enrichment_folder, exist_ok=True)\n",
    "\n",
    "# Get all Polygenic enrichment files\n",
    "polygenic_files = [f for f in os.listdir(polygenic_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "# Filtering Criteria\n",
    "ADJUSTED_P_VALUE_THRESHOLD = 0.05  # Adjusted p-value for significance\n",
    "COMBINED_SCORE_THRESHOLD = 1.5  # Retain highly enriched pathways\n",
    "\n",
    "# Process each file\n",
    "for file in polygenic_files:\n",
    "    file_path = os.path.join(polygenic_folder, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure necessary columns exist\n",
    "    if \"Adjusted P-value\" in df.columns and \"Combined Score\" in df.columns:\n",
    "        # Filter pathways using Adjusted P-value instead of raw P-value\n",
    "        filtered_df = df[\n",
    "            (df[\"Adjusted P-value\"] < ADJUSTED_P_VALUE_THRESHOLD) &\n",
    "            (df[\"Combined Score\"] > COMBINED_SCORE_THRESHOLD)\n",
    "        ]\n",
    "        \n",
    "        # Save only if filtered pathways exist\n",
    "        if not filtered_df.empty:\n",
    "            output_path = os.path.join(final_enrichment_folder, file)\n",
    "            filtered_df.to_csv(output_path, index=False)\n",
    "            print(f\"‚úÖ Filtered pathways saved: {output_path}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No significant pathways found in: {file}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Skipping {file}, missing required columns.\")\n",
    "\n",
    "print(\"\\nüéØ **Final Enrichment Filtering Completed!** üîç\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914809b7",
   "metadata": {},
   "source": [
    "### Determining the CoExpression genes for each dosage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define paths\n",
    "deg_folder = \"DEG_Results\"\n",
    "coexp_folder = \"CoExpression_Results\"\n",
    "os.makedirs(coexp_folder, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "# Load the normalized expression data\n",
    "expression_file = \"Dataset/GSE206125/merged_scRNA_metadata_normalized.tsv\"\n",
    "normalized_df = pd.read_csv(expression_file, sep=\"\\t\", index_col=0)\n",
    "\n",
    "# List of dosages\n",
    "dosage_groups = normalized_df[\"orig.ident\"].unique()\n",
    "\n",
    "# Set correlation threshold\n",
    "PCC_THRESHOLD = 0.7  # Modify as needed\n",
    "\n",
    "# Define metadata columns to exclude from correlation analysis\n",
    "metadata_columns = [\"cell\", \"nGene\", \"nUMI\", \"orig.ident\", \"percent.mito\", \"State\"]\n",
    "\n",
    "for dosage in dosage_groups:\n",
    "    print(f\"üîπ Processing Co-Expression for {dosage}\")\n",
    "\n",
    "    # Extract relevant numeric gene expression columns (removing metadata)\n",
    "    dosage_df = normalized_df[normalized_df[\"orig.ident\"] == dosage].drop(columns=metadata_columns, errors=\"ignore\")\n",
    "\n",
    "    # Ensure all columns are numeric before correlation calculation\n",
    "    dosage_df = dosage_df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Compute Pearson correlation matrix\n",
    "    correlation_matrix = dosage_df.corr(method=\"pearson\").fillna(0)  # Handle NaNs\n",
    "\n",
    "    # Keep only the upper triangle to avoid duplicate pairs\n",
    "    mask = np.triu(np.ones(correlation_matrix.shape, dtype=bool), k=1)\n",
    "    upper_tri = correlation_matrix.mask(~mask)\n",
    "\n",
    "    # Convert to long format efficiently\n",
    "    coexp_df = (\n",
    "        upper_tri.stack()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"level_0\": \"Gene1\", \"level_1\": \"Gene2\", 0: \"PCC\"})\n",
    "    )\n",
    "\n",
    "    # Filter for strong correlations dynamically\n",
    "    coexp_df = coexp_df[coexp_df[\"PCC\"].abs() > PCC_THRESHOLD]\n",
    "\n",
    "    # Save to CSV\n",
    "    coexp_file = os.path.join(coexp_folder, f\"CoExpression_{dosage}.csv\")\n",
    "    coexp_df.to_csv(coexp_file, index=False)\n",
    "\n",
    "    print(f\"‚úÖ Saved: {coexp_file}\")\n",
    "\n",
    "print(\"\\nüéØ **Step 1 Completed: Co-Expression Networks Stored in `CoExpression_Results/`!**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7421f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define directories\n",
    "deg_folder = \"DEG_Results\"\n",
    "coexp_folder = \"CoExpression_Results\"\n",
    "\n",
    "# List of dosages (from DEG folder)\n",
    "dosage_folders = [d for d in os.listdir(deg_folder) if d.startswith(\"DEG_\")]\n",
    "\n",
    "# Store results\n",
    "overlap_results = {}\n",
    "\n",
    "for dosage in dosage_folders:\n",
    "    dosage_name = dosage.replace(\"DEG_\", \"\")  # Extract dosage name (e.g., T10)\n",
    "\n",
    "    # Path to DEG file\n",
    "    deg_file = os.path.join(deg_folder, dosage, f\"DEG_{dosage_name}_vs_Control.csv\")\n",
    "    \n",
    "    # Path to CoExpression file\n",
    "    coexp_file = os.path.join(coexp_folder, f\"CoExpression_{dosage_name}.csv\")\n",
    "    \n",
    "    # Skip if either file is missing\n",
    "    if not os.path.exists(deg_file) or not os.path.exists(coexp_file):\n",
    "        print(f\"‚ö†Ô∏è Skipping {dosage_name}: Missing DEG or CoExpression file\")\n",
    "        continue\n",
    "\n",
    "    # Load DEG data\n",
    "    deg_df = pd.read_csv(deg_file)\n",
    "\n",
    "    # Load CoExpression data\n",
    "    coexp_df = pd.read_csv(coexp_file)\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    if \"Gene\" not in deg_df.columns or \"Gene1\" not in coexp_df.columns or \"Gene2\" not in coexp_df.columns:\n",
    "        print(f\"‚ö†Ô∏è Skipping {dosage_name}: Required columns missing\")\n",
    "        continue\n",
    "\n",
    "    # Extract gene sets\n",
    "    deg_genes = set(deg_df[\"Gene\"])\n",
    "    coexp_genes = set(coexp_df[\"Gene1\"]).union(set(coexp_df[\"Gene2\"]))  # Consider both Gene1 and Gene2\n",
    "\n",
    "    # Find overlap\n",
    "    overlap_genes = deg_genes.intersection(coexp_genes)\n",
    "\n",
    "    # Store and print results\n",
    "    overlap_count = len(overlap_genes)\n",
    "    overlap_results[dosage_name] = overlap_count\n",
    "    print(f\"‚úÖ {dosage_name}: {overlap_count} overlapping genes\")\n",
    "\n",
    "print(\"\\nüéØ **Overlap Analysis Completed!**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541114f2",
   "metadata": {},
   "source": [
    "### Merging the State and Dosage data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c94101f",
   "metadata": {},
   "source": [
    "### Aggregating States data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # Path to the DEG_Results directory\n",
    "# deg_results_path = \"DEG_Results\"  # Update this with your actual path\n",
    "\n",
    "# # Iterate only through directories that start with \"DEG_\"\n",
    "# for dosage_folder in os.listdir(deg_results_path):\n",
    "#     if not dosage_folder.startswith(\"DEG_\"):  # Skip unrelated folders\n",
    "#         continue\n",
    "\n",
    "#     dosage_path = os.path.join(deg_results_path, dosage_folder)\n",
    "    \n",
    "#     if not os.path.isdir(dosage_path):  # Ensure it's a directory\n",
    "#         continue\n",
    "    \n",
    "#     # Collect only state comparison files (files with 'vs' but NOT 'Control')\n",
    "#     state_files = [f for f in os.listdir(dosage_path) if 'vs' in f and 'Control' not in f and f.endswith('.csv')]\n",
    "    \n",
    "#     if not state_files:\n",
    "#         continue  # Skip if no state-wise comparison files found\n",
    "\n",
    "#     # List to store individual dataframes\n",
    "#     df_list = []\n",
    "\n",
    "#     for file in state_files:\n",
    "#         file_path = os.path.join(dosage_path, file)\n",
    "#         df = pd.read_csv(file_path)\n",
    "        \n",
    "#         if {\"Gene\", \"P-Value\", \"Log2FC\"}.issubset(df.columns):  # Ensure required columns exist\n",
    "#             df = df[[\"Gene\", \"P-Value\", \"Log2FC\"]]\n",
    "#             df_list.append(df)\n",
    "#         else:\n",
    "#             print(f\"Skipping file {file} due to missing columns.\")\n",
    "\n",
    "#     if df_list:\n",
    "#         # Merge by computing mean Log2FC and minimum P-Value for common genes\n",
    "#         merged_df = pd.concat(df_list).groupby(\"Gene\", as_index=False).agg({\n",
    "#             \"Log2FC\": \"mean\",\n",
    "#             \"P-Value\": \"min\"\n",
    "#         })\n",
    "\n",
    "#         # Save the merged file in the same dosage folder\n",
    "#         merged_filename = f\"{dosage_folder}_State.csv\"\n",
    "#         merged_filepath = os.path.join(dosage_path, merged_filename)\n",
    "#         merged_df.to_csv(merged_filepath, index=False)\n",
    "#         print(f\"Saved: {merged_filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db6d187",
   "metadata": {},
   "source": [
    "## Check Merging of State data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Define file paths for dosage T20\n",
    "# deg_t20_path = \"DEG_Results/DEG_T20\"  # Update with actual path\n",
    "# file_s2_s3 = f\"{deg_t20_path}/DEG_T20_S2_vs_S3.csv\"\n",
    "# file_s3_s4 = f\"{deg_t20_path}/DEG_T20_S3_vs_S4.csv\"\n",
    "# merged_file = f\"{deg_t20_path}/DEG_T20_State.csv\"\n",
    "\n",
    "# # Load the data\n",
    "# df_s2_s3 = pd.read_csv(file_s2_s3)\n",
    "# df_s3_s4 = pd.read_csv(file_s3_s4)\n",
    "# df_merged = pd.read_csv(merged_file)\n",
    "\n",
    "# # Ensure required columns exist\n",
    "# required_cols = {\"Gene\", \"Log2FC\"}\n",
    "# assert required_cols.issubset(df_s2_s3.columns), \"Missing columns in S2_vs_S3 file\"\n",
    "# assert required_cols.issubset(df_s3_s4.columns), \"Missing columns in S3_vs_S4 file\"\n",
    "# assert required_cols.issubset(df_merged.columns), \"Missing columns in merged file\"\n",
    "\n",
    "# # Find intersecting genes\n",
    "# intersecting_genes = set(df_s2_s3[\"Gene\"]).intersection(set(df_s3_s4[\"Gene\"]))\n",
    "# total_intersecting = len(intersecting_genes)\n",
    "\n",
    "# # Find total unique genes across both files\n",
    "# unique_genes = set(df_s2_s3[\"Gene\"]).union(set(df_s3_s4[\"Gene\"]))\n",
    "# total_unique = len(unique_genes)\n",
    "\n",
    "# # Extract Log2FC values for intersecting genes\n",
    "# df_s2_s3_filtered = df_s2_s3[df_s2_s3[\"Gene\"].isin(intersecting_genes)][[\"Gene\", \"Log2FC\"]]\n",
    "# df_s3_s4_filtered = df_s3_s4[df_s3_s4[\"Gene\"].isin(intersecting_genes)][[\"Gene\", \"Log2FC\"]]\n",
    "\n",
    "# # Merge to see individual Log2FC values\n",
    "# df_intersections = df_s2_s3_filtered.merge(df_s3_s4_filtered, on=\"Gene\", suffixes=(\"_S2_vs_S3\", \"_S3_vs_S4\"))\n",
    "\n",
    "# # Get final Log2FC from the merged file\n",
    "# df_final_log2fc = df_merged[df_merged[\"Gene\"].isin(intersecting_genes)][[\"Gene\", \"Log2FC\"]]\n",
    "# df_intersections = df_intersections.merge(df_final_log2fc, on=\"Gene\", suffixes=(\"\", \"_Final\"))\n",
    "\n",
    "# # Display results\n",
    "# print(f\"Total intersecting genes: {total_intersecting}\")\n",
    "# print(f\"Total unique genes: {total_unique}\")\n",
    "# print(\"\\nIntersecting genes with Log2FC values:\")\n",
    "# print(df_intersections)\n",
    "\n",
    "# # Save results to a file for verification\n",
    "# output_file = f\"{deg_t20_path}/DEG_T20_Intersection_Analysis.csv\"\n",
    "# df_intersections.to_csv(output_file, index=False)\n",
    "# print(f\"Results saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937872dc",
   "metadata": {},
   "source": [
    "### Merging the State and dosage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e987893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # Path to DEG_Results directory\n",
    "# deg_results_path = \"DEG_Results\"  # Update this with your actual path\n",
    "\n",
    "# # Iterate through each dosage folder\n",
    "# for dosage_folder in os.listdir(deg_results_path):\n",
    "#     if not dosage_folder.startswith(\"DEG_\"):  # Skip unrelated folders\n",
    "#         continue\n",
    "\n",
    "#     dosage_path = os.path.join(deg_results_path, dosage_folder)\n",
    "\n",
    "#     # Define file paths\n",
    "#     control_file = os.path.join(dosage_path, f\"{dosage_folder}_vs_Control.csv\")\n",
    "#     state_file = os.path.join(dosage_path, f\"{dosage_folder}_State.csv\")\n",
    "#     merged_file = os.path.join(dosage_path, f\"{dosage_folder}_Merged.csv\")\n",
    "\n",
    "#     # Check if both files exist\n",
    "#     if not os.path.exists(control_file) or not os.path.exists(state_file):\n",
    "#         print(f\"Skipping {dosage_folder} - Missing required files.\")\n",
    "#         continue\n",
    "\n",
    "#     # Load the data\n",
    "#     df_control = pd.read_csv(control_file)\n",
    "#     df_state = pd.read_csv(state_file)\n",
    "\n",
    "#     # Ensure required columns exist\n",
    "#     required_cols = {\"Gene\", \"P-Value\", \"Log2FC\"}\n",
    "#     assert required_cols.issubset(df_control.columns), f\"Missing columns in {control_file}\"\n",
    "#     assert required_cols.issubset(df_state.columns), f\"Missing columns in {state_file}\"\n",
    "\n",
    "#     # Merge on \"Gene\" with outer join to retain all genes\n",
    "#     merged_df = pd.merge(df_control, df_state, on=\"Gene\", how=\"outer\", suffixes=(\"_Dosage\", \"_State\"))\n",
    "\n",
    "#     # Compute final Log2FC based on weighting rules\n",
    "#     def calculate_final_logfc(row):\n",
    "#         if pd.notna(row[\"Log2FC_Dosage\"]) and pd.notna(row[\"Log2FC_State\"]):\n",
    "#             return 0.8 * row[\"Log2FC_Dosage\"] + 0.2 * row[\"Log2FC_State\"]\n",
    "#         elif pd.notna(row[\"Log2FC_Dosage\"]):\n",
    "#             return 0.8 * row[\"Log2FC_Dosage\"]\n",
    "#         elif pd.notna(row[\"Log2FC_State\"]):\n",
    "#             return 0.2 * row[\"Log2FC_State\"]\n",
    "#         return None\n",
    "\n",
    "#     merged_df[\"Log2FC\"] = merged_df.apply(calculate_final_logfc, axis=1)\n",
    "\n",
    "#     # Compute final P-Value (take the minimum if present in both)\n",
    "#     merged_df[\"P-Value\"] = merged_df[[\"P-Value_Dosage\", \"P-Value_State\"]].min(axis=1)\n",
    "\n",
    "#     # Keep only necessary columns with correct column names\n",
    "#     final_df = merged_df[[\"Gene\", \"P-Value\", \"Log2FC\"]]\n",
    "\n",
    "#     # Save the final merged file\n",
    "#     final_df.to_csv(merged_file, index=False)\n",
    "#     print(f\"Saved: {merged_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e135e9bf",
   "metadata": {},
   "source": [
    "### Pathway File Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8aa32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to Final Enrichment directory\n",
    "enrichment_path = \"DEG_Results/Final_Enrichment\"  # Update with actual path\n",
    "\n",
    "# Iterate through each dosage folder\n",
    "dosage_files = [f for f in os.listdir(enrichment_path) if f.startswith(\"Polygenic_Enrichment_DEG_\")]\n",
    "\n",
    "# Extract unique dosages that have state comparisons (skip dosage vs. control)\n",
    "dosages_with_states = set()\n",
    "for file in dosage_files:\n",
    "    parts = file.split(\"_\")\n",
    "    if len(parts) > 4 and \"vs\" in file:  # Ensures it's a state-wise comparison file\n",
    "        dosage = parts[3]  # Extract dosage value (e.g., \"T10\")\n",
    "        dosages_with_states.add(dosage)\n",
    "\n",
    "# Process each dosage that has state pathway data\n",
    "for dosage in dosages_with_states:\n",
    "    # Collect all state comparison files for this dosage\n",
    "    state_files = [f for f in dosage_files if f\"DEG_{dosage}_\" in f and \"vs\" in f]\n",
    "\n",
    "    if not state_files:\n",
    "        continue  # Skip if no state pathway files found\n",
    "\n",
    "    # List to store individual dataframes\n",
    "    df_list = []\n",
    "\n",
    "    for file in state_files:\n",
    "        file_path = os.path.join(enrichment_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if {\"Term\", \"Combined Score\", \"Genes\"}.issubset(df.columns):  # Ensure required columns exist\n",
    "            df = df[[\"Term\", \"Combined Score\", \"Genes\"]]\n",
    "            df_list.append(df)\n",
    "        else:\n",
    "            print(f\"Skipping file {file} due to missing columns.\")\n",
    "\n",
    "    if df_list:\n",
    "        # Merge data by taking the union of genes and averaging the combined score\n",
    "        merged_df = pd.concat(df_list)\n",
    "\n",
    "        # Aggregate by pathway term\n",
    "        merged_df = merged_df.groupby(\"Term\").agg({\n",
    "            \"Combined Score\": \"mean\",  # Average combined score\n",
    "            \"Genes\": lambda x: \",\".join(set(\",\".join(x).split(\",\")))  # Union of genes\n",
    "        }).reset_index()\n",
    "\n",
    "        # Save the merged file in the same directory\n",
    "        merged_filename = f\"Polygenic_Enrichment_DEG_{dosage}_State.csv\"\n",
    "        merged_filepath = os.path.join(enrichment_path, merged_filename)\n",
    "        merged_df.to_csv(merged_filepath, index=False)\n",
    "        print(f\"Saved: {merged_filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608b8783",
   "metadata": {},
   "source": [
    "### Merginf the State vs Dosage Enrichment data into One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87317a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to Final Enrichment directory\n",
    "# enrichment_path = \"DEG_Results/Final_Enrichment\"  # Update with actual path\n",
    "\n",
    "# # Get all available enrichment files\n",
    "# enrichment_files = [f for f in os.listdir(enrichment_path) if f.startswith(\"Polygenic_Enrichment_DEG_\")]\n",
    "\n",
    "# # Extract unique dosages that have state files (skip T1, T320, T160)\n",
    "# dosages_with_states = set()\n",
    "# for file in enrichment_files:\n",
    "#     if \"_State.csv\" in file:\n",
    "#         dosage = file.split(\"_\")[3]  # Extract dosage value (e.g., \"T10\")\n",
    "#         dosages_with_states.add(dosage)\n",
    "\n",
    "# # Process each dosage that has state pathway data\n",
    "# for dosage in dosages_with_states:\n",
    "#     # Define file paths\n",
    "#     dosage_file = os.path.join(enrichment_path, f\"Polygenic_Enrichment_DEG_{dosage}.csv\")\n",
    "#     state_file = os.path.join(enrichment_path, f\"Polygenic_Enrichment_DEG_{dosage}_State.csv\")\n",
    "#     merged_file = os.path.join(enrichment_path, f\"Polygenic_Enrichment_DEG_{dosage}_merged.csv\")\n",
    "\n",
    "#     # Check if both files exist\n",
    "#     if not os.path.exists(dosage_file) or not os.path.exists(state_file):\n",
    "#         print(f\"Skipping {dosage} - Missing required files.\")\n",
    "#         continue\n",
    "\n",
    "#     # Load the data\n",
    "#     df_dosage = pd.read_csv(dosage_file)\n",
    "#     df_state = pd.read_csv(state_file)\n",
    "\n",
    "#     # Ensure required columns exist\n",
    "#     required_cols = {\"Term\", \"Combined Score\", \"Genes\"}\n",
    "#     assert required_cols.issubset(df_dosage.columns), f\"Missing columns in {dosage_file}\"\n",
    "#     assert required_cols.issubset(df_state.columns), f\"Missing columns in {state_file}\"\n",
    "\n",
    "#     # Merge on \"Term\" with outer join to retain all pathways\n",
    "#     merged_df = pd.merge(df_dosage, df_state, on=\"Term\", how=\"outer\", suffixes=(\"_Dosage\", \"_State\"))\n",
    "\n",
    "#     # Compute final Combined Score based on weighting rules\n",
    "#     def calculate_final_combined_score(row):\n",
    "#         if pd.notna(row[\"Combined Score_Dosage\"]) and pd.notna(row[\"Combined Score_State\"]):\n",
    "#             return 0.8 * row[\"Combined Score_Dosage\"] + 0.2 * row[\"Combined Score_State\"]\n",
    "#         elif pd.notna(row[\"Combined Score_Dosage\"]):\n",
    "#             return 0.8 * row[\"Combined Score_Dosage\"]\n",
    "#         elif pd.notna(row[\"Combined Score_State\"]):\n",
    "#             return 0.2 * row[\"Combined Score_State\"]\n",
    "#         return None\n",
    "\n",
    "#     merged_df[\"Combined Score\"] = merged_df.apply(calculate_final_combined_score, axis=1)\n",
    "\n",
    "#     merged_df[\"Genes\"] = merged_df[\"Genes_Dosage\"].fillna('') + \";\" + merged_df[\"Genes_State\"].fillna('')\n",
    "#     merged_df[\"Genes\"] = merged_df[\"Genes\"].str.strip(\";\").apply(lambda x: \";\".join(sorted(set(x.split(\";\")))))\n",
    "#     merged_df[\"Genes\"] = merged_df[\"Genes\"].apply(lambda x: \",\".join(set(x.split(\",\"))) if x else '')\n",
    "\n",
    "#     # Keep only necessary columns\n",
    "#     final_df = merged_df[[\"Term\", \"Combined Score\", \"Genes\"]]\n",
    "\n",
    "#     # Save the final merged file\n",
    "#     final_df.to_csv(merged_file, index=False)\n",
    "#     print(f\"Saved: {merged_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Define file paths for T10\n",
    "# enrichment_path = \"DEG_Results/Final_Enrichment\"  # Update with actual path\n",
    "# file_dosage = f\"{enrichment_path}/Polygenic_Enrichment_DEG_T10.csv\"\n",
    "# file_state = f\"{enrichment_path}/Polygenic_Enrichment_DEG_T10_State.csv\"\n",
    "# file_merged = f\"{enrichment_path}/Polygenic_Enrichment_DEG_T10_merged.csv\"\n",
    "\n",
    "# # Load the data\n",
    "# df_dosage = pd.read_csv(file_dosage)\n",
    "# df_state = pd.read_csv(file_state)\n",
    "# df_merged = pd.read_csv(file_merged)\n",
    "\n",
    "# # Find non-overlapping pathways\n",
    "# only_in_dosage = list(set(df_dosage[\"Term\"]) - set(df_state[\"Term\"]))\n",
    "# only_in_state = list(set(df_state[\"Term\"]) - set(df_dosage[\"Term\"]))\n",
    "\n",
    "# # Select a few random pathways for checking\n",
    "# sample_size = 5  # Adjust the number of pathways to check\n",
    "# sample_dosage = only_in_dosage[:sample_size]\n",
    "# sample_state = only_in_state[:sample_size]\n",
    "\n",
    "# # Extract data for sampled pathways\n",
    "# df_dosage_only = df_dosage[df_dosage[\"Term\"].isin(sample_dosage)][[\"Term\", \"Combined Score\", \"Genes\"]]\n",
    "# df_state_only = df_state[df_state[\"Term\"].isin(sample_state)][[\"Term\", \"Combined Score\", \"Genes\"]]\n",
    "\n",
    "# # Get final values from merged file\n",
    "# df_final_dosage = df_merged[df_merged[\"Term\"].isin(sample_dosage)][[\"Term\", \"Combined Score\", \"Genes\"]]\n",
    "# df_final_state = df_merged[df_merged[\"Term\"].isin(sample_state)][[\"Term\", \"Combined Score\", \"Genes\"]]\n",
    "\n",
    "# # Merge to verify correctness\n",
    "# df_dosage_check = df_dosage_only.merge(df_final_dosage, on=\"Term\", suffixes=(\"_Original\", \"_Final\"))\n",
    "# df_state_check = df_state_only.merge(df_final_state, on=\"Term\", suffixes=(\"_Original\", \"_Final\"))\n",
    "\n",
    "# # Check if Combined Score remains unchanged\n",
    "# df_dosage_check[\"Correct_Combined_Score\"] = abs(df_dosage_check[\"Combined Score_Original\"] * 0.8 - df_dosage_check[\"Combined Score_Final\"]) < 1e-6\n",
    "# df_state_check[\"Correct_Combined_Score\"] = abs(df_state_check[\"Combined Score_Original\"] * 0.2 - df_state_check[\"Combined Score_Final\"]) < 1e-6\n",
    "\n",
    "# # Check if Genes remain unchanged\n",
    "# df_dosage_check[\"Expected_Genes\"] = df_dosage_check[\"Genes_Original\"].apply(lambda x: \";\".join(sorted(set(x.split(\";\")))))\n",
    "# df_state_check[\"Expected_Genes\"] = df_state_check[\"Genes_Original\"].apply(lambda x: \";\".join(sorted(set(x.split(\";\")))))\n",
    "\n",
    "# df_dosage_check[\"Correct_Genes\"] = df_dosage_check[\"Genes_Final\"] == df_dosage_check[\"Expected_Genes\"]\n",
    "# df_state_check[\"Correct_Genes\"] = df_state_check[\"Genes_Final\"] == df_state_check[\"Expected_Genes\"]\n",
    "\n",
    "# # Display sample results\n",
    "# print(f\"Sample verification for pathways only in dosage ({sample_size} pathways):\")\n",
    "# print(df_dosage_check)\n",
    "\n",
    "# print(f\"\\nSample verification for pathways only in state ({sample_size} pathways):\")\n",
    "# print(df_state_check)\n",
    "\n",
    "# # Save results for further checking\n",
    "# df_dosage_check.to_csv(f\"{enrichment_path}/Polygenic_Enrichment_DEG_T10_NonIntersecting_Dosage_Verification.csv\", index=False)\n",
    "# df_state_check.to_csv(f\"{enrichment_path}/Polygenic_Enrichment_DEG_T10_NonIntersecting_State_Verification.csv\", index=False)\n",
    "# print(\"Results saved for further checking.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c371e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Define file paths for T10\n",
    "# enrichment_path = \"DEG_Results/Final_Enrichment\"  # Update with actual path\n",
    "# file_dosage = f\"{enrichment_path}/Polygenic_Enrichment_DEG_T10.csv\"\n",
    "# file_state = f\"{enrichment_path}/Polygenic_Enrichment_DEG_T10_State.csv\"\n",
    "# file_merged = f\"{enrichment_path}/Polygenic_Enrichment_DEG_T10_merged.csv\"\n",
    "\n",
    "# # Load the data\n",
    "# df_dosage = pd.read_csv(file_dosage)\n",
    "# df_state = pd.read_csv(file_state)\n",
    "# df_merged = pd.read_csv(file_merged)\n",
    "\n",
    "# # Ensure required columns exist\n",
    "# required_cols = {\"Term\", \"Combined Score\", \"Genes\"}\n",
    "# assert required_cols.issubset(df_dosage.columns), \"Missing columns in Dosage file\"\n",
    "# assert required_cols.issubset(df_state.columns), \"Missing columns in State file\"\n",
    "# assert required_cols.issubset(df_merged.columns), \"Missing columns in Merged file\"\n",
    "\n",
    "# # Find overlapping pathways\n",
    "# overlapping_pathways = set(df_dosage[\"Term\"]).intersection(set(df_state[\"Term\"]))\n",
    "# total_overlapping = len(overlapping_pathways)\n",
    "\n",
    "# # Find total unique pathways across both files\n",
    "# unique_pathways = set(df_dosage[\"Term\"]).union(set(df_state[\"Term\"]))\n",
    "# total_unique = len(unique_pathways)\n",
    "\n",
    "# # Extract Combined Score values for overlapping pathways\n",
    "# df_dosage_filtered = df_dosage[df_dosage[\"Term\"].isin(overlapping_pathways)][[\"Term\", \"Combined Score\", \"Genes\"]]\n",
    "# df_state_filtered = df_state[df_state[\"Term\"].isin(overlapping_pathways)][[\"Term\", \"Combined Score\", \"Genes\"]]\n",
    "\n",
    "# # Merge to compare Combined Score values\n",
    "# df_intersections = df_dosage_filtered.merge(df_state_filtered, on=\"Term\", suffixes=(\"_Dosage\", \"_State\"))\n",
    "\n",
    "# # Get final Combined Score from the merged file\n",
    "# df_final_score = df_merged[df_merged[\"Term\"].isin(overlapping_pathways)][[\"Term\", \"Combined Score\", \"Genes\"]]\n",
    "# df_intersections = df_intersections.merge(df_final_score, on=\"Term\")\n",
    "\n",
    "# # Compute expected Combined Score based on weighting\n",
    "# df_intersections[\"Expected_Combined_Score\"] = (\n",
    "#     0.8 * df_intersections[\"Combined Score_Dosage\"] + 0.2 * df_intersections[\"Combined Score_State\"]\n",
    "# )\n",
    "\n",
    "# # Verify if averaging was done correctly\n",
    "# df_intersections[\"Correct_Combined_Score\"] = (\n",
    "#     abs(df_intersections[\"Combined Score\"] - df_intersections[\"Expected_Combined_Score\"]) < 1e-6\n",
    "# )\n",
    "\n",
    "# # Verify if the union of genes is correctly applied\n",
    "# df_intersections[\"Expected_Genes\"] = df_intersections[\"Genes_Dosage\"] + \",\" + df_intersections[\"Genes_State\"]\n",
    "# df_intersections[\"Expected_Genes\"] = df_intersections[\"Expected_Genes\"].apply(lambda x: \",\".join(set(x.split(\",\"))))  # Unique gene list\n",
    "\n",
    "# df_intersections[\"Correct_Genes\"] = df_intersections[\"Genes\"] == df_intersections[\"Expected_Genes\"]\n",
    "\n",
    "# # Display results\n",
    "# print(f\"Total overlapping pathways: {total_overlapping}\")\n",
    "# print(f\"Total unique pathways: {total_unique}\")\n",
    "# print(\"\\nOverlapping pathways with Combined Score values and correctness verification:\")\n",
    "# print(df_intersections)\n",
    "\n",
    "# # Save results for further verification\n",
    "# output_file = f\"{enrichment_path}/Polygenic_Enrichment_DEG_T10_Merged_Verification.csv\"\n",
    "# df_intersections.to_csv(output_file, index=False)\n",
    "# print(f\"Results saved to: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "pyg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
