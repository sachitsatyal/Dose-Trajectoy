{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e093c02",
   "metadata": {},
   "source": [
    "### Encode Node Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340a3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv, global_mean_pool \n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GlobalAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ea087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the hetero graph\n",
    "data = torch.load(\"Graph_Results/HeteroGraphs_ScaledFinal/HeteroGraph_T1.pt\")\n",
    "\n",
    "# Print node types and sizes\n",
    "print(\"Node Types and Features:\")\n",
    "for ntype in data.node_types:\n",
    "    print(f\"  {ntype}: {data[ntype].x.shape}\")\n",
    "\n",
    "# Print edge types and count\n",
    "print(\"\\nEdge Types:\")\n",
    "for etype in data.edge_types:\n",
    "    edge_index = data[etype].edge_index\n",
    "    print(f\"  {etype}: {edge_index.shape[1]} edges\")\n",
    "\n",
    "# Check a few values from cell node features\n",
    "print(\"\\nSample cell node features (first 5 rows):\")\n",
    "print(data[\"cell\"].x[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c2ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NodeFeatureEncoders(nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cell_encoder = nn.Sequential(\n",
    "            nn.Linear(7, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),  # üîÅ Replaced BatchNorm1d\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.gene_encoder = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),  # üîÅ Replaced BatchNorm1d\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pathway_encoder = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),  # üîÅ Replaced BatchNorm1d\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, cell_x, gene_x, pathway_x):\n",
    "        h_cell = self.cell_encoder(cell_x)\n",
    "        h_gene = self.gene_encoder(gene_x)\n",
    "        h_pathway = self.pathway_encoder(pathway_x)\n",
    "        return h_cell, h_gene, h_pathway\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffc609",
   "metadata": {},
   "source": [
    "###  Shared Hierarchical Encoder with Virtual Node Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GlobalAttention\n",
    "\n",
    "class GlobalAttentionWithWeights(GlobalAttention):\n",
    "    def forward(self, x, index, ptr=None, dim_size=None, dim=0):\n",
    "        \"\"\"\n",
    "        x: Node embeddings\n",
    "        index: Index tensor (typically the batch vector)\n",
    "        \"\"\"\n",
    "        gate = self.gate_nn(x).squeeze(-1)      # [N]\n",
    "        gate = torch.sigmoid(gate)              # attention weights\n",
    "        x_weighted = x * gate.unsqueeze(-1)     # [N, F]\n",
    "\n",
    "        # Perform aggregation (mean by default)\n",
    "        out = torch.zeros(dim_size or int(index.max()) + 1, x.size(-1), device=x.device)\n",
    "        out = out.index_add(dim, index, x_weighted)\n",
    "\n",
    "        return out, gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e350ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import NNConv\n",
    "\n",
    "class SharedHierarchicalEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_dosages=9, num_aux_outputs=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.node_encoders = NodeFeatureEncoders(hidden_dim)\n",
    "\n",
    "        self.dosage_embeddings = nn.Embedding(num_dosages, hidden_dim)\n",
    "        self.virtual_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.dosage_lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        self.fuse_cell_virtual = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.fuse_gene_virtual = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.fuse_pathway_virtual = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.edge_mlp_cell_gene = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        self.edge_mlp_gene_pathway = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.cell_to_gene_conv = NNConv(hidden_dim, hidden_dim, self.edge_mlp_cell_gene, aggr='mean')\n",
    "        self.gene_to_pathway_conv = NNConv(hidden_dim, hidden_dim, self.edge_mlp_gene_pathway, aggr='mean')\n",
    "\n",
    "        self.att_pool = GlobalAttentionWithWeights(gate_nn=nn.Linear(hidden_dim, 1))\n",
    "\n",
    "        self.fuse_global = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_aux_outputs)\n",
    "        )\n",
    "\n",
    "    def refine_virtuals_with_lstm(self):\n",
    "        raw_dosage_embeddings = self.dosage_embeddings.weight.unsqueeze(0)\n",
    "        lstm_out, _ = self.dosage_lstm(raw_dosage_embeddings)\n",
    "        return self.virtual_norm(lstm_out.squeeze(0))\n",
    "\n",
    "    def forward(self, data, dosage_idx):\n",
    "        cell_x, gene_x, pathway_x = data[\"cell\"].x, data[\"gene\"].x, data[\"pathway\"].x\n",
    "        h_cell, h_gene, h_pathway = self.node_encoders(cell_x, gene_x, pathway_x)\n",
    "\n",
    "        refined_dosage_virtuals = self.refine_virtuals_with_lstm()\n",
    "        dosage_virtual = refined_dosage_virtuals[dosage_idx]\n",
    "\n",
    "        # Inject dosage virtual into cell nodes\n",
    "        num_cells = h_cell.size(0)\n",
    "        h_cell = self.fuse_cell_virtual(torch.cat([\n",
    "            h_cell,\n",
    "            dosage_virtual.unsqueeze(0).expand(num_cells, -1)\n",
    "        ], dim=1))\n",
    "\n",
    "        # Inject dosage virtual into gene nodes\n",
    "        num_genes = h_gene.size(0)\n",
    "        h_gene = self.fuse_gene_virtual(torch.cat([\n",
    "            h_gene,\n",
    "            dosage_virtual.unsqueeze(0).expand(num_genes, -1)\n",
    "        ], dim=1))\n",
    "\n",
    "        edge_index_cg = data[\"cell\", \"expresses\", \"gene\"].edge_index\n",
    "        edge_attr_cg = data[\"cell\", \"expresses\", \"gene\"].edge_attr\n",
    "        h_gene_updated = self.cell_to_gene_conv((h_cell, h_gene), edge_index_cg, edge_attr_cg)\n",
    "\n",
    "        # Inject dosage virtual into pathway nodes\n",
    "        num_pathways = h_pathway.size(0)\n",
    "        h_pathway = self.fuse_pathway_virtual(torch.cat([\n",
    "            h_pathway,\n",
    "            dosage_virtual.unsqueeze(0).expand(num_pathways, -1)\n",
    "        ], dim=1))\n",
    "\n",
    "        edge_index_gp = data[\"gene\", \"involved_in\", \"pathway\"].edge_index\n",
    "        edge_attr_gp = data[\"gene\", \"involved_in\", \"pathway\"].edge_attr\n",
    "        h_pathway_updated = self.gene_to_pathway_conv((h_gene_updated, h_pathway), edge_index_gp, edge_attr_gp)\n",
    "\n",
    "        pooled_pathway, pathway_attention_weights = self.att_pool(h_pathway_updated, data['pathway'].batch)\n",
    "\n",
    "        graph_embedding = self.fuse_global(torch.cat([\n",
    "            pooled_pathway,\n",
    "            dosage_virtual.unsqueeze(0)\n",
    "        ], dim=1))\n",
    "\n",
    "        aux_output = self.aux_head(graph_embedding)\n",
    "\n",
    "        # ‚úÖ Normalize node embeddings before output\n",
    "        h_cell = F.normalize(h_cell, p=2, dim=-1)\n",
    "        h_gene_updated = F.normalize(h_gene_updated, p=2, dim=-1)\n",
    "        h_pathway_updated = F.normalize(h_pathway_updated, p=2, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"h_cell\": h_cell,\n",
    "            \"h_gene\": h_gene_updated,\n",
    "            \"h_pathway\": h_pathway_updated,\n",
    "            \"dosage_virtual\": dosage_virtual,\n",
    "            \"graph_embedding\": graph_embedding,\n",
    "            \"aux_output\": aux_output.squeeze(),\n",
    "            \"pathway_attention_weights\": pathway_attention_weights\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b85ec",
   "metadata": {},
   "source": [
    "## Decoder Architecture Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca49cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HierarchicalDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, cell_feature_dim=7):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.cell_feature_dim = cell_feature_dim\n",
    "\n",
    "        self.gene_query_bias = nn.Parameter(torch.randn(1, hidden_dim))\n",
    "        self.cell_query_bias = nn.Parameter(torch.randn(1, hidden_dim))\n",
    "\n",
    "        self.decode_to_pathways_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "        )\n",
    "        self.decode_to_pathways_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.pathway_to_gene_attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=2,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.gene_to_cell_attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=2,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        self.decode_to_cells = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, cell_feature_dim)\n",
    "        )\n",
    "\n",
    "        self.aux_pathway_score_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "        self.aux_resistance_predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, h_pathway_updated, h_gene_updated, graph_embedding, dosage_virtual, num_genes, num_cells,\n",
    "                gene_mask=None, cell_mask=None):\n",
    "        # üîÅ Updated to handle non-batch input\n",
    "        num_pathways, _ = h_pathway_updated.size()\n",
    "        B = 1\n",
    "\n",
    "        if graph_embedding.dim() == 3:\n",
    "            graph_embedding = graph_embedding.squeeze(1)  # [1, 1, 64] ‚Üí [1, 64]\n",
    "        graph_expanded = graph_embedding.unsqueeze(1).expand(B, num_pathways, -1)\n",
    "        h_pathway_expanded = h_pathway_updated.unsqueeze(0)  # [1, P, 64]\n",
    "\n",
    "        combined_input = torch.cat([h_pathway_expanded, graph_expanded], dim=2)\n",
    "        base_pathway_repr = self.decode_to_pathways_fc(combined_input)\n",
    "        pathway_recon = self.decode_to_pathways_proj(base_pathway_repr)\n",
    "\n",
    "        gene_seed = h_pathway_updated.mean(dim=0)  # [64]\n",
    "        gene_query = gene_seed.unsqueeze(0).unsqueeze(1).expand(B, num_genes, -1) + self.gene_query_bias\n",
    "\n",
    "        gene_recon_raw, attn_pathway_gene = self.pathway_to_gene_attn(\n",
    "            gene_query, pathway_recon, pathway_recon, key_padding_mask=gene_mask\n",
    "        )\n",
    "        gene_recon_raw = self.dropout(gene_recon_raw)\n",
    "        gene_recon = gene_recon_raw + gene_query\n",
    "\n",
    "        cell_seed = h_gene_updated.mean(dim=0)\n",
    "        cell_query = cell_seed.unsqueeze(0).unsqueeze(1).expand(B, num_cells, -1) + self.cell_query_bias\n",
    "\n",
    "        cell_recon_raw, attn_gene_cell = self.gene_to_cell_attn(\n",
    "            cell_query, gene_recon, gene_recon, key_padding_mask=cell_mask\n",
    "        )\n",
    "        cell_recon_raw = self.dropout(cell_recon_raw)\n",
    "        cell_embedding_for_resistance = cell_recon_raw + cell_query  # üîÅ use this\n",
    "        cell_recon = self.decode_to_cells(cell_embedding_for_resistance)\n",
    "        \n",
    "        aux_pathway_scores = self.aux_pathway_score_head(pathway_recon).squeeze(-1)\n",
    "        aux_resistance_score = self.aux_resistance_predictor(cell_embedding_for_resistance).squeeze(-1)  # üîÅ fix here\n",
    "\n",
    "        return {\n",
    "            \"reconstructed_pathways\": pathway_recon.squeeze(0),\n",
    "            \"reconstructed_genes\": gene_recon.squeeze(0),\n",
    "            \"reconstructed_cells\": cell_recon.squeeze(0),\n",
    "            \"aux_pathway_scores\": aux_pathway_scores.squeeze(0),\n",
    "            \"aux_resistance_score\": aux_resistance_score,  # shape: [num_cells]\n",
    "            \"attention_pathway_to_gene\": attn_pathway_gene,\n",
    "            \"attention_gene_to_cell\": attn_gene_cell\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e3ea9a",
   "metadata": {},
   "source": [
    "## Test Loaded Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# Load one example graph (change path if needed)\n",
    "graph_path = 'Graph_Results/HeteroGraphs_ScaledFinal/HeteroGraph_T1.pt'\n",
    "data = torch.load(graph_path)\n",
    "\n",
    "print(f\"Inspecting graph at: {graph_path}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Node types\n",
    "print(\"\\nüì¶ Node Types and Feature Shapes:\")\n",
    "for node_type in data.node_types:\n",
    "    x = data[node_type].x\n",
    "    print(f\"- {node_type}: {x.shape} features, dtype: {x.dtype}\")\n",
    "    if hasattr(data[node_type], 'batch'):\n",
    "        print(f\"  Batch attribute: {data[node_type].batch.shape}\")\n",
    "    print(f\"  Feature stats: min {x.min().item()}, max {x.max().item()}, mean {x.mean().item()}\")\n",
    "\n",
    "# Edge types\n",
    "print(\"\\nüîó Edge Types and Attributes:\")\n",
    "for edge_type in data.edge_types:\n",
    "    edge_index = data[edge_type].edge_index\n",
    "    edge_attr = data[edge_type].edge_attr\n",
    "    print(f\"- {edge_type}: {edge_index.shape[1]} edges, edge_attr shape: {edge_attr.shape}\")\n",
    "    print(f\"  Edge attr stats: min {edge_attr.min().item()}, max {edge_attr.max().item()}, mean {edge_attr.mean().item()}\")\n",
    "\n",
    "# Summary counts\n",
    "print(\"\\nüìä Summary:\")\n",
    "print(f\"- Total node types: {len(data.node_types)}\")\n",
    "print(f\"- Total edge types: {len(data.edge_types)}\")\n",
    "total_nodes = sum(data[node_type].num_nodes for node_type in data.node_types)\n",
    "print(f\"- Total nodes: {total_nodes}\")\n",
    "total_edges = sum(data[edge_type].edge_index.shape[1] for edge_type in data.edge_types)\n",
    "print(f\"- Total edges: {total_edges}\")\n",
    "\n",
    "# Optional: inspect one example feature vector\n",
    "for node_type in data.node_types:\n",
    "    print(f\"\\nExample {node_type} feature vector (first node):\")\n",
    "    print(data[node_type].x[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee9089e",
   "metadata": {},
   "source": [
    "## Loss desgin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cedf332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HierarchicalLoss(nn.Module):\n",
    "    def __init__(self, \n",
    "                  lambda_pathway=2.0,     # üî∫ Highest priority\n",
    "                 lambda_gene=1.0,        # üî∏ Medium priority\n",
    "                 lambda_cell=0.5,        # üîª Lowest priority\n",
    "                 lambda_resistance=0.1, \n",
    "                 lambda_attention=0.01,\n",
    "                 use_resistance=True,\n",
    "                 use_attention_reg=True):\n",
    "        super().__init__()\n",
    "        self.lambda_pathway = lambda_pathway\n",
    "        self.lambda_gene = lambda_gene\n",
    "        self.lambda_cell = lambda_cell\n",
    "        self.lambda_resistance = lambda_resistance\n",
    "        self.lambda_attention = lambda_attention\n",
    "        self.use_resistance = use_resistance\n",
    "        self.use_attention_reg = use_attention_reg\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        \"\"\"\n",
    "        outputs: dict from decoder\n",
    "        targets: dict from encoder and ground truth features:\n",
    "            - h_pathway\n",
    "            - h_gene\n",
    "            - cell_features\n",
    "            - resistance_label (optional)\n",
    "        \"\"\"\n",
    "\n",
    "        # 1Ô∏è‚É£ Pathway-level reconstruction\n",
    "        L_pathway = F.mse_loss(outputs[\"reconstructed_pathways\"], targets[\"h_pathway\"])\n",
    "\n",
    "        # 2Ô∏è‚É£ Gene-level reconstruction\n",
    "        L_gene = F.mse_loss(outputs[\"reconstructed_genes\"], targets[\"h_gene\"])\n",
    "\n",
    "        # 3Ô∏è‚É£ Cell-level reconstruction\n",
    "        L_cell = F.mse_loss(outputs[\"reconstructed_cells\"], targets[\"cell_features\"])\n",
    "\n",
    "        # 4Ô∏è‚É£ Resistance prediction (if available)\n",
    "        # 4Ô∏è‚É£ Resistance prediction (if available)\n",
    "        if self.use_resistance and \"resistance_label\" in targets:\n",
    "            L_resistance = F.mse_loss(outputs[\"aux_resistance_score\"].squeeze(0), targets[\"resistance_label\"])\n",
    "        else:\n",
    "            L_resistance = torch.tensor(0.0, device=L_cell.device)\n",
    "\n",
    "\n",
    "        # 5Ô∏è‚É£ Attention entropy regularization (optional)\n",
    "        if self.use_attention_reg:\n",
    "            attn_weights = outputs[\"attention_pathway_to_gene\"]\n",
    "            attn_weights = torch.clamp(attn_weights, min=1e-6)\n",
    "            L_attention = -(attn_weights * torch.log(attn_weights)).sum(dim=-1).mean()\n",
    "        else:\n",
    "            L_attention = torch.tensor(0.0, device=L_cell.device)\n",
    "\n",
    "        # ‚úÖ Total Loss\n",
    "        total_loss = (\n",
    "            self.lambda_pathway * L_pathway +\n",
    "            self.lambda_gene * L_gene +\n",
    "            self.lambda_cell * L_cell +\n",
    "            self.lambda_resistance * L_resistance +\n",
    "            self.lambda_attention * L_attention\n",
    "        )\n",
    "\n",
    "        # üîç Log individual loss components\n",
    "        loss_dict = {\n",
    "            \"total_loss\": total_loss.item(),\n",
    "            \"pathway_loss\": L_pathway.item(),\n",
    "            \"gene_loss\": L_gene.item(),\n",
    "            \"cell_loss\": L_cell.item(),\n",
    "            \"resistance_loss\": L_resistance.item(),\n",
    "            \"attention_reg_loss\": L_attention.item()\n",
    "        }\n",
    "\n",
    "        return total_loss, loss_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.optim import Adam\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def train_encoder_decoder_model(\n",
    "#     encoder, decoder, graphs, dosage_to_idx, optimizer=None, device='cuda',\n",
    "#     epochs=100, loss_weights=None, save_path=None\n",
    "# ):\n",
    "#     if loss_weights is None:\n",
    "#         # Updated weight priority: pathway > gene > cell\n",
    "#         loss_weights = {\n",
    "#             'lambda_pathway': 2.0,\n",
    "#             'lambda_gene': 1.0,\n",
    "#             'lambda_cell': 0.3,\n",
    "#             'lambda_resistance': 0.1,\n",
    "#             'lambda_attention': 0.01\n",
    "#         }\n",
    "\n",
    "#     encoder = encoder.to(device)\n",
    "#     decoder = decoder.to(device)\n",
    "\n",
    "#     # ‚úÖ Unpack weights into the HierarchicalLoss class\n",
    "#     criterion = HierarchicalLoss(**loss_weights).to(device)\n",
    "\n",
    "#     if optimizer is None:\n",
    "#         optimizer = Adam(\n",
    "#             list(encoder.parameters()) + list(decoder.parameters()),\n",
    "#             lr=1e-3,\n",
    "#             weight_decay=1e-5\n",
    "#         )\n",
    "\n",
    "#     loss_log = []\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         encoder.train()\n",
    "#         decoder.train()\n",
    "#         total_loss = 0.0\n",
    "#         epoch_loss_dict = {\n",
    "#             'pathway_loss': 0.0,\n",
    "#             'gene_loss': 0.0,\n",
    "#             'cell_loss': 0.0,\n",
    "#             'resistance_loss': 0.0,\n",
    "#             'attention_reg_loss': 0.0,\n",
    "#             'total_loss': 0.0\n",
    "#         }\n",
    "\n",
    "#         for dosage_name, graph in graphs.items():\n",
    "#             data = graph.to(device)\n",
    "#             dosage_idx = dosage_to_idx[dosage_name]  # E.g., T10 ‚Üí 10\n",
    "#             if not hasattr(data['pathway'], 'batch'):\n",
    "#                 data['pathway'].batch = torch.zeros(data['pathway'].num_nodes, dtype=torch.long, device=data['pathway'].x.device)\n",
    "\n",
    "#                # -------- Forward -------- #\n",
    "#             encoder_out = encoder(data, dosage_idx)\n",
    "#             decoder_out = decoder(\n",
    "#                 h_pathway_updated=encoder_out['h_pathway'],  # [P, 64]\n",
    "#                 h_gene_updated=encoder_out['h_gene'],        # [G, 64]\n",
    "#                 graph_embedding=encoder_out['graph_embedding'].unsqueeze(0),  # keep batch dimension\n",
    "#                 dosage_virtual=encoder_out['dosage_virtual'].unsqueeze(0),    # keep batch dimension\n",
    "#                 num_genes=encoder_out['h_gene'].shape[0],\n",
    "#                 num_cells=encoder_out['h_cell'].shape[0]\n",
    "#             )\n",
    "\n",
    "#             # -------- Targets -------- #\n",
    "#             targets = {\n",
    "#                 'h_pathway': encoder_out['h_pathway'].detach(),  # Ground truth: original encoder output\n",
    "#                 'h_gene': encoder_out['h_gene'].detach(),\n",
    "#                 'cell_features': data['cell'].x,\n",
    "#                 'resistance_label': data['cell'].x[:, 2]  # Assumes resistance encoded at index 2\n",
    "#             }\n",
    "\n",
    "#             # -------- Loss -------- #\n",
    "#             loss, loss_components = criterion(decoder_out, targets)\n",
    "#             total_loss += loss.item()\n",
    "#             for key in epoch_loss_dict:\n",
    "#                 epoch_loss_dict[key] += loss_components[key]\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         # Average losses\n",
    "#         num_graphs = len(graphs)\n",
    "#         avg_loss_dict = {k: v / num_graphs for k, v in epoch_loss_dict.items()}\n",
    "#         loss_log.append(avg_loss_dict)\n",
    "\n",
    "#         print(f\"Epoch {epoch+1:03d} | \"\n",
    "#               f\"Total: {avg_loss_dict['total_loss']:.4f} | \"\n",
    "#               f\"P: {avg_loss_dict['pathway_loss']:.4f}, \"\n",
    "#               f\"G: {avg_loss_dict['gene_loss']:.4f}, \"\n",
    "#               f\"C: {avg_loss_dict['cell_loss']:.4f}, \"\n",
    "#               f\"R: {avg_loss_dict['resistance_loss']:.4f}, \"\n",
    "#               f\"A: {avg_loss_dict['attention_reg_loss']:.4f}\")\n",
    "\n",
    "#     # Optional model saving\n",
    "#     if save_path:\n",
    "#         torch.save({'encoder': encoder.state_dict(),\n",
    "#                     'decoder': decoder.state_dict()}, save_path)\n",
    "#         print(f\"‚úÖ Model saved to {save_path}\")\n",
    "\n",
    "#     return encoder, decoder, loss_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dac945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def train_encoder_decoder_model(\n",
    "    encoder, decoder, graphs, dosage_to_idx, optimizer=None, device='cuda',\n",
    "    epochs=100, loss_weights=None, save_path=None,\n",
    "    attention_lambda_warmup_epochs=10,\n",
    "    early_stop_patience=10\n",
    "):\n",
    "    if loss_weights is None:\n",
    "        loss_weights = {\n",
    "            'lambda_pathway': 2.0,\n",
    "            'lambda_gene': 1.0,\n",
    "            'lambda_cell': 0.3,\n",
    "            'lambda_resistance': 0.1,\n",
    "            'lambda_attention': 0.01,\n",
    "            'use_attention_reg': True\n",
    "        }\n",
    "\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    # Initial loss object (will re-init if lambda_attention changes)\n",
    "    criterion = HierarchicalLoss(**loss_weights).to(device)\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = Adam(\n",
    "            list(encoder.parameters()) + list(decoder.parameters()),\n",
    "            lr=1e-3,\n",
    "            weight_decay=1e-5\n",
    "        )\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True, min_lr=1e-5)\n",
    "    best_loss = float('inf')\n",
    "    no_improvement_epochs = 0\n",
    "    loss_log = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # üîÅ Warm-up: gradually increase lambda_attention\n",
    "        if loss_weights[\"use_attention_reg\"] and epoch < attention_lambda_warmup_epochs:\n",
    "            warmup_lambda = (epoch + 1) / attention_lambda_warmup_epochs * 0.01  # final lambda_attention target\n",
    "            loss_weights[\"lambda_attention\"] = warmup_lambda\n",
    "            criterion = HierarchicalLoss(**loss_weights).to(device)\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        epoch_loss_dict = {\n",
    "            'pathway_loss': 0.0,\n",
    "            'gene_loss': 0.0,\n",
    "            'cell_loss': 0.0,\n",
    "            'resistance_loss': 0.0,\n",
    "            'attention_reg_loss': 0.0,\n",
    "            'total_loss': 0.0\n",
    "        }\n",
    "\n",
    "        for dosage_name, graph in graphs.items():\n",
    "            data = graph.to(device)\n",
    "            dosage_idx = dosage_to_idx[dosage_name]\n",
    "\n",
    "            if not hasattr(data['pathway'], 'batch'):\n",
    "                data['pathway'].batch = torch.zeros(data['pathway'].num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "            encoder_out = encoder(data, dosage_idx)\n",
    "            decoder_out = decoder(\n",
    "                h_pathway_updated=encoder_out['h_pathway'],\n",
    "                h_gene_updated=encoder_out['h_gene'],\n",
    "                graph_embedding=encoder_out['graph_embedding'].unsqueeze(0),\n",
    "                dosage_virtual=encoder_out['dosage_virtual'].unsqueeze(0),\n",
    "                num_genes=encoder_out['h_gene'].shape[0],\n",
    "                num_cells=encoder_out['h_cell'].shape[0]\n",
    "            )\n",
    "\n",
    "            targets = {\n",
    "                'h_pathway': encoder_out['h_pathway'].detach(),\n",
    "                'h_gene': encoder_out['h_gene'].detach(),\n",
    "                'cell_features': data['cell'].x,\n",
    "                'resistance_label': data['cell'].x[:, 2]\n",
    "            }\n",
    "\n",
    "            loss, loss_components = criterion(decoder_out, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            for key in epoch_loss_dict:\n",
    "                epoch_loss_dict[key] += loss_components[key]\n",
    "\n",
    "        # Average loss across all graphs\n",
    "        num_graphs = len(graphs)\n",
    "        avg_loss_dict = {k: v / num_graphs for k, v in epoch_loss_dict.items()}\n",
    "        loss_log.append(avg_loss_dict)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:03d} | Total: {avg_loss_dict['total_loss']:.4f} | \"\n",
    "              f\"P: {avg_loss_dict['pathway_loss']:.4f}, \"\n",
    "              f\"G: {avg_loss_dict['gene_loss']:.4f}, \"\n",
    "              f\"C: {avg_loss_dict['cell_loss']:.4f}, \"\n",
    "              f\"R: {avg_loss_dict['resistance_loss']:.4f}, \"\n",
    "              f\"A: {avg_loss_dict['attention_reg_loss']:.6f}\")\n",
    "\n",
    "        # Monitor loss for scheduler and early stopping\n",
    "        monitored = avg_loss_dict['total_loss']\n",
    "        scheduler.step(monitored)\n",
    "\n",
    "        if monitored < best_loss - 1e-4:\n",
    "            best_loss = monitored\n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "\n",
    "        if no_improvement_epochs >= early_stop_patience:\n",
    "            print(f\"üõë Early stopping at epoch {epoch+1}, no improvement in {early_stop_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "    # Save model and logs\n",
    "    if save_path:\n",
    "        torch.save({'encoder': encoder.state_dict(), 'decoder': decoder.state_dict()}, save_path)\n",
    "        print(f\"‚úÖ Model saved to {save_path}\")\n",
    "        with open(save_path.replace('.pth', '_loss_log.json'), 'w') as f:\n",
    "            json.dump(loss_log, f, indent=2)\n",
    "        print(f\"üìâ Loss log saved to {save_path.replace('.pth', '_loss_log.json')}\")\n",
    "\n",
    "    return encoder, decoder, loss_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def load_all_dosage_graphs(graph_dir, pattern_prefix=\"HeteroGraph_T\"):\n",
    "    \"\"\"\n",
    "    Loads all dosage-specific heterographs from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        graph_dir (str): Path to directory containing dosage graphs.\n",
    "        pattern_prefix (str): File prefix to identify graph files (e.g., \"HeteroGraph_T\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary { \"T1\": data_obj, \"T10\": data_obj, ... }\n",
    "    \"\"\"\n",
    "    graphs = {}\n",
    "    for fname in os.listdir(graph_dir):\n",
    "        if fname.startswith(pattern_prefix) and fname.endswith(\".pt\"):\n",
    "            dosage_key = fname.replace(\".pt\", \"\").replace(pattern_prefix, \"T\")\n",
    "            path = os.path.join(graph_dir, fname)\n",
    "            data = torch.load(path)\n",
    "            graphs[dosage_key] = data\n",
    "    return graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8276cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load graphs\n",
    "graph_dir = \"Graph_Results/HeteroGraphs_ScaledFinal\"\n",
    "graphs = load_all_dosage_graphs(graph_dir)\n",
    "\n",
    "# üîÅ Map 'T2.5', 'T10', etc. to integer indices\n",
    "dosage_levels = sorted([float(k.replace('T', '')) for k in graphs.keys()])\n",
    "dosage_to_idx = {f\"T{int(d) if d.is_integer() else d}\": i for i, d in enumerate(dosage_levels)}\n",
    "\n",
    "# Load model\n",
    "encoder = SharedHierarchicalEncoder(hidden_dim=64, num_dosages=len(dosage_to_idx))\n",
    "decoder = HierarchicalDecoder(hidden_dim=64, cell_feature_dim=7)\n",
    "\n",
    "# Train\n",
    "trained_encoder, trained_decoder, loss_log = train_encoder_decoder_model(\n",
    "    encoder, decoder, graphs, dosage_to_idx=dosage_to_idx,\n",
    "    device='cpu', epochs=100, save_path=\"trained_model12.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967be4da",
   "metadata": {},
   "source": [
    "### Loss Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7beafb4",
   "metadata": {},
   "source": [
    "## Represesntation of the Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec33e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with correct dosage count used during training\n",
    "encoder = SharedHierarchicalEncoder(hidden_dim=64, num_dosages=9)\n",
    "decoder = HierarchicalDecoder(hidden_dim=64, cell_feature_dim=7)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"trained_model12.pth\", map_location='cpu')\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "decoder.load_state_dict(checkpoint['decoder'])\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30933be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = \"Graph_Results/HeteroGraphs_ScaledFinal\"\n",
    "graphs = load_all_dosage_graphs(graph_dir)\n",
    "\n",
    "# Also ensure you have dosage_to_idx mapping\n",
    "dosage_to_idx = {k: i for i, k in enumerate(sorted(graphs.keys(), key=lambda x: float(x[1:])))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = {}\n",
    "device = torch.device('cpu')\n",
    "\n",
    "for dosage_name, data in graphs.items():\n",
    "    data = data.to(device)\n",
    "    dosage_idx = dosage_to_idx[dosage_name]\n",
    "\n",
    "    # ‚úÖ Inject dummy batch for pathway\n",
    "    if not hasattr(data['pathway'], 'batch'):\n",
    "        data['pathway'].batch = torch.zeros(data['pathway'].num_nodes, dtype=torch.long, device=data['pathway'].x.device)\n",
    "\n",
    "    # Encoder\n",
    "    with torch.no_grad():\n",
    "        encoder_out = encoder(data, dosage_idx)\n",
    "        decoder_out = decoder(\n",
    "            h_pathway_updated=encoder_out['h_pathway'],   # [1, P, 64]\n",
    "            h_gene_updated=encoder_out['h_gene'],         # [1, G, 64]\n",
    "            graph_embedding=encoder_out['graph_embedding'].unsqueeze(0).squeeze(1),  # [1, 64]\n",
    "            dosage_virtual=encoder_out['dosage_virtual'].unsqueeze(0),\n",
    "            num_genes=encoder_out['h_gene'].shape[0],\n",
    "            num_cells=encoder_out['h_cell'].shape[0]\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    all_outputs[dosage_name] = {\n",
    "        \"encoder\": encoder_out,\n",
    "        \"decoder\": decoder_out\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9197f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Path to graph mappings\n",
    "graph_mapping_dir = \"Graph_Results/Graph_Mappings\"\n",
    "embedding_records = []\n",
    "\n",
    "# Extract embeddings\n",
    "for dosage_name, output in all_outputs.items():\n",
    "    mapping_path = os.path.join(graph_mapping_dir, f\"Graph_Mapping_{dosage_name}.json\")\n",
    "    if not os.path.exists(mapping_path):\n",
    "        continue\n",
    "\n",
    "    with open(mapping_path, 'r') as f:\n",
    "        mapping = json.load(f)\n",
    "\n",
    "    h_gene = output[\"encoder\"][\"h_gene\"]\n",
    "    h_pathway = output[\"encoder\"][\"h_pathway\"]\n",
    "\n",
    "    for gene, idx in mapping[\"gene_to_index\"].items():\n",
    "        embedding_records.append({\n",
    "            \"type\": \"gene\",\n",
    "            \"name\": gene,\n",
    "            \"dosage\": dosage_name,\n",
    "            \"embedding\": h_gene[idx].tolist()\n",
    "        })\n",
    "\n",
    "    for pathway, idx in mapping[\"pathway_to_index\"].items():\n",
    "        embedding_records.append({\n",
    "            \"type\": \"pathway\",\n",
    "            \"name\": pathway,\n",
    "            \"dosage\": dosage_name,\n",
    "            \"embedding\": h_pathway[idx].tolist()\n",
    "        })\n",
    "\n",
    "# Prepare data\n",
    "df_embed = pd.DataFrame(embedding_records)\n",
    "embedding_matrix = np.vstack(df_embed[\"embedding\"].values)\n",
    "\n",
    "# Run t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, init='pca')\n",
    "tsne_result = tsne.fit_transform(embedding_matrix)\n",
    "\n",
    "df_embed[\"tsne-1\"] = tsne_result[:, 0]\n",
    "df_embed[\"tsne-2\"] = tsne_result[:, 1]\n",
    "\n",
    "# Save embeddings\n",
    "df_embed.to_csv(\"tSNE_Embeddings_All_original.csv\", index=False)\n",
    "\n",
    "# Set global font size (optional)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Plot gene embeddings\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_embed[df_embed[\"type\"] == \"gene\"],\n",
    "    x=\"tsne-1\", y=\"tsne-2\", hue=\"dosage\", palette=\"tab10\"\n",
    ")\n",
    "plt.title(\"t-SNE: Gene Embeddings by Dose\", fontsize=16)\n",
    "plt.xlabel(\"tSNE-1\", fontsize=14)\n",
    "plt.ylabel(\"tSNE-2\", fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Dosage\", fontsize=10, title_fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tSNE_Gene_Embeddings_original.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot pathway embeddings\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_embed[df_embed[\"type\"] == \"pathway\"],\n",
    "    x=\"tsne-1\", y=\"tsne-2\", hue=\"dosage\", palette=\"tab10\"\n",
    ")\n",
    "plt.title(\"t-SNE: Pathway Embeddings by Dose\", fontsize=16)\n",
    "plt.xlabel(\"tSNE-1\", fontsize=14)\n",
    "plt.ylabel(\"tSNE-2\", fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Dosage\", fontsize=10, title_fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tSNE_Pathway_Embeddings_original.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612bfb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the t-SNE embedding file\n",
    "df_embed = pd.read_csv(\"tSNE_Embeddings_All_original.csv\")\n",
    "\n",
    "# Step 1: Group embeddings\n",
    "grouped_embeddings = defaultdict(lambda: defaultdict(list))\n",
    "for _, row in df_embed.iterrows():\n",
    "    entity_type = row[\"type\"]\n",
    "    name = row[\"name\"]\n",
    "    dosage = row[\"dosage\"]\n",
    "    emb = np.array(row[\"embedding\"].strip('[]').split(','), dtype=float) if isinstance(row[\"embedding\"], str) else row[\"embedding\"]\n",
    "    grouped_embeddings[entity_type][name].append((dosage, emb))\n",
    "\n",
    "# Step 2: Define dosage order (make sure to sort properly based on true dosage value)\n",
    "dosage_order = ['T1', 'T2.5', 'T5', 'T10', 'T20', 'T40', 'T80', 'T160', 'T320']\n",
    "dosage_to_index = {d: i for i, d in enumerate(dosage_order)}\n",
    "\n",
    "def compute_cosine_drift(embedding_dict):\n",
    "    drift_dict = {}\n",
    "    for name, entries in embedding_dict.items():\n",
    "        # Filter valid entries by dosage order\n",
    "        entries_sorted = sorted(entries, key=lambda x: dosage_to_index.get(x[0], -1))\n",
    "        drifts = []\n",
    "        for (d1, v1), (d2, v2) in zip(entries_sorted[:-1], entries_sorted[1:]):\n",
    "            sim = cosine_similarity([v1], [v2])[0, 0]\n",
    "            drift = 1 - sim\n",
    "            drifts.append(drift)\n",
    "        if drifts:\n",
    "            drift_dict[name] = {\n",
    "                \"drifts\": drifts,\n",
    "                \"mean_drift\": np.mean(drifts),\n",
    "                \"num_pairs\": len(drifts)\n",
    "            }\n",
    "    return drift_dict\n",
    "\n",
    "# Step 3: Compute drifts\n",
    "gene_drift = compute_cosine_drift(grouped_embeddings['gene'])\n",
    "pathway_drift = compute_cosine_drift(grouped_embeddings['pathway'])\n",
    "\n",
    "# Step 4: Compute overall mean drift\n",
    "mean_gene_drift = np.mean([v[\"mean_drift\"] for v in gene_drift.values()])\n",
    "mean_pathway_drift = np.mean([v[\"mean_drift\"] for v in pathway_drift.values()])\n",
    "\n",
    "print(f\"üìä Average Gene Drift Across Dosages: {mean_gene_drift:.4f}\")\n",
    "print(f\"üìä Average Pathway Drift Across Dosages: {mean_pathway_drift:.4f}\")\n",
    "\n",
    "# Step 5: Save detailed drift information\n",
    "pd.DataFrame([\n",
    "    {\"Gene\": k, \"MeanDrift\": v[\"mean_drift\"], \"Pairs\": v[\"num_pairs\"]}\n",
    "    for k, v in gene_drift.items()\n",
    "]).to_csv(\"Gene_Cosine_Drift.csv\", index=False)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\"Pathway\": k, \"MeanDrift\": v[\"mean_drift\"], \"Pairs\": v[\"num_pairs\"]}\n",
    "    for k, v in pathway_drift.items()\n",
    "]).to_csv(\"Pathway_Cosine_Drift.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da71aef",
   "metadata": {},
   "source": [
    "### Figure 1: Gene Embeddings by Dosage (t-SNE)\n",
    "\n",
    "Clear Separation: Each dosage group (T1 to T320) forms a distinct cluster. This means the model has successfully learned distinct gene-level representations per dosage.\n",
    "\n",
    "Smooth Transitions: The relative positions of T1 ‚Üí T2.5 ‚Üí T5 ‚Üí T10 ‚Üí T20 ‚Üí T40 ‚Üí T80 ‚Üí T160 ‚Üí T320 show a smooth progression, indicating that gene embeddings evolve gradually with increasing drug pressure.\n",
    "\n",
    "Biological Insight:\n",
    "\n",
    "This supports your hypothesis of adaptive reprogramming: genes shift in embedding space as resistance increases.\n",
    "\n",
    "Potential to quantify embedding drift between adjacent dosages.\n",
    "\n",
    "###  Figure 2: Pathway Embeddings by Dosage (t-SNE)\n",
    "Distinct Clusters with Overlaps:\n",
    "\n",
    "Like genes, pathways also form distinct clusters per dosage, indicating condition-specific pathway activation.\n",
    "\n",
    "Some overlap (e.g., T10 and T20 clusters slightly closer) suggests shared pathways or transition zones.\n",
    "\n",
    "Elongated Clusters:\n",
    "\n",
    "The shape and orientation may indicate heterogeneity within each dosage‚Äîespecially under partial resistance conditions (e.g., T80 or T160).\n",
    "\n",
    "Good candidate for analyzing which pathways change activation most drastically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07687dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "# Define dosage order\n",
    "dosage_order = [\"T1\", \"T2.5\", \"T5\", \"T10\", \"T20\", \"T40\", \"T80\", \"T160\", \"T320\"]\n",
    "\n",
    "# Lists to store drift values\n",
    "gene_drift, pathway_drift, transitions = [], [], []\n",
    "\n",
    "# Compute cosine drift between adjacent dosages\n",
    "for i in range(len(dosage_order) - 1):\n",
    "    d1, d2 = dosage_order[i], dosage_order[i + 1]\n",
    "    transitions.append(f\"{d1}‚Üí{d2}\")\n",
    "\n",
    "    h_gene_1 = all_outputs[d1]['encoder']['h_gene']\n",
    "    h_gene_2 = all_outputs[d2]['encoder']['h_gene']\n",
    "    h_pathway_1 = all_outputs[d1]['encoder']['h_pathway']\n",
    "    h_pathway_2 = all_outputs[d2]['encoder']['h_pathway']\n",
    "\n",
    "    # Align dimensions\n",
    "    min_gene = min(h_gene_1.shape[0], h_gene_2.shape[0])\n",
    "    min_pathway = min(h_pathway_1.shape[0], h_pathway_2.shape[0])\n",
    "    h_gene_1, h_gene_2 = h_gene_1[:min_gene], h_gene_2[:min_gene]\n",
    "    h_pathway_1, h_pathway_2 = h_pathway_1[:min_pathway], h_pathway_2[:min_pathway]\n",
    "\n",
    "    # Compute mean cosine distances\n",
    "    gene_distance = cosine_distances(h_gene_1.numpy(), h_gene_2.numpy()).mean()\n",
    "    pathway_distance = cosine_distances(h_pathway_1.numpy(), h_pathway_2.numpy()).mean()\n",
    "\n",
    "    gene_drift.append(gene_distance)\n",
    "    pathway_drift.append(pathway_distance)\n",
    "\n",
    "# --- Plot Gene Drift ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(transitions, gene_drift, marker='o', color='blue')\n",
    "plt.title(\"Gene Embedding Drift\", fontsize=16)\n",
    "plt.xlabel(\"Dosage Transition\", fontsize=14)\n",
    "plt.ylabel(\"Mean Cosine Distance\", fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"gene_embedding_drift.png\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# --- Plot Pathway Drift ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(transitions, pathway_drift, marker='o', color='green')\n",
    "plt.title(\"Pathway Embedding Drift\", fontsize=16)\n",
    "plt.xlabel(\"Dosage Transition\", fontsize=14)\n",
    "plt.ylabel(\"Mean Cosine Distance\", fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pathway_embedding_drift.png\", dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f32e8",
   "metadata": {},
   "source": [
    "###  Gene Embedding Drift (Left Plot)\n",
    "T1 ‚Üí T2.5 ‚Üí T5 ‚Üí T10 ‚Üí T20 shows progressively increasing drift, peaking at T20, suggesting:\n",
    "\n",
    "Significant molecular reprogramming is happening in this early-to-mid dosage range.\n",
    "\n",
    "Cells are likely undergoing transcriptional rewiring under increasing drug stress.\n",
    "\n",
    "T20 ‚Üí T40 drops sharply, then jumps at T80.\n",
    "\n",
    "This dip may indicate temporary stabilization or selection of resistant subpopulations.\n",
    "\n",
    "T80 still shows a high drift, suggesting further adaptation or new resistance mechanisms.\n",
    "\n",
    "### Pathway Embedding Drift (Right Plot)\n",
    "A similar trend:\n",
    "\n",
    "Low drift from T1‚ÄìT5,\n",
    "\n",
    "Peak drift at T20, suggesting pathway reorganization happens most intensely here.\n",
    "\n",
    "T20 ‚Üí T40 again shows a drop, confirming a potential \"rewiring event\" that stabilizes after the system reorients.\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "525692d6-0a0f-4ed5-9f63-a3385f1c65f3.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "19a08fc9",
   "metadata": {},
   "source": [
    "### Gene Embedding Drift Plot (Left)\n",
    "What It Shows:\n",
    "The cosine distance between gene embeddings of consecutive dosages reflects how much the overall regulatory behavior of genes changes.\n",
    "\n",
    "Biological Interpretation:\n",
    "T1 ‚Üí T2.5 ‚Üí T10 ‚Üí T20:\n",
    "\n",
    "Increasing distance means that more genes are changing their roles, activation levels, or co-expression relationships.\n",
    "\n",
    "This suggests gradual transcriptional adaptation to increasing drug pressure.\n",
    "\n",
    "T20 has peak drift:\n",
    "\n",
    "Indicates a critical threshold where the cell overhauls its transcriptional program ‚Äî possibly switching to alternative survival mechanisms or activating stress-response modules.\n",
    "\n",
    "Could involve:\n",
    "\n",
    "Downregulation of apoptosis genes\n",
    "\n",
    "Upregulation of DNA repair, efflux pumps, or metabolic shift genes\n",
    "\n",
    "T20 ‚Üí T40: Sharp drop\n",
    "\n",
    "Suggests the cell has found a stable resistant state ‚Äî no longer needing to adapt drastically.\n",
    "\n",
    "Biological rewiring may have completed here, forming a resistant phenotype.\n",
    "\n",
    "T40 ‚Üí T80: rise again\n",
    "\n",
    "Indicates secondary rewiring ‚Äî possibly due to new drug toxicity or further resistance layer building.\n",
    "\n",
    "### Pathway Embedding Drift Plot (Right)\n",
    "T1 to T20: gradual then steep drift ‚Äî shows pathway-level coordination changes.\n",
    "\n",
    "Pathway rewiring means:\n",
    "\n",
    "Activation/inhibition of entire biological processes, not just individual genes.\n",
    "\n",
    "E.g., switching from p53 signaling to PI3K/AKT survival pathways, or activating autophagy.\n",
    "\n",
    "T20 to T40 drop: implies the cell stabilizes around certain survival pathways.\n",
    "\n",
    "T80 jump: maybe a new set of pathways activated for sustained resistance or metabolic compensation.\n",
    "![image.png](attachment:525692d6-0a0f-4ed5-9f63-a3385f1c65f3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451006a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "# --- Extract standardized pathway identifiers ---\n",
    "def extract_pathway_identifier(name):\n",
    "    \"\"\"\n",
    "    Extracts a Reactome ID (R-HSA: or r-hsa-) or GO ID (GO:) from a pathway name.\n",
    "    Returns the matched identifier in standard form (uppercase), or None if not found.\n",
    "    \"\"\"\n",
    "    # Match Reactome (r-hsa:123456 or R-HSA-123456)\n",
    "    match_reactome = re.search(r\"(r-hsa[-:]\\d+)\", name, flags=re.IGNORECASE)\n",
    "    if match_reactome:\n",
    "        return match_reactome.group(1).upper().replace(\":\", \"-\")\n",
    "\n",
    "    # Match GO term (GO:0000000)\n",
    "    match_go = re.search(r\"(GO:\\d+)\", name, flags=re.IGNORECASE)\n",
    "    if match_go:\n",
    "        return match_go.group(1).upper()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# --- Load mappings and encoder outputs ---\n",
    "def load_embeddings_and_mappings(dosage_names, encoder_outputs, mapping_dir):\n",
    "    gene_embeddings_by_dosage = {}\n",
    "    pathway_embeddings_by_dosage = {}\n",
    "    gene_id_sets = []\n",
    "\n",
    "    for dosage_name in dosage_names:\n",
    "        with open(os.path.join(mapping_dir, f\"Graph_Mapping_{dosage_name}.json\")) as f:\n",
    "            mapping = json.load(f)\n",
    "\n",
    "        gene_map = mapping[\"gene_to_index\"]\n",
    "        pathway_map = mapping[\"pathway_to_index\"]\n",
    "\n",
    "        inv_gene_map = {v: k for k, v in gene_map.items()}\n",
    "\n",
    "        # Extract and clean pathway IDs\n",
    "        inv_pathway_map_raw = {v: extract_pathway_identifier(k) for k, v in pathway_map.items()}\n",
    "        inv_pathway_map = {k: v for k, v in inv_pathway_map_raw.items() if v is not None}\n",
    "\n",
    "        h_gene = encoder_outputs[dosage_name][\"encoder\"][\"h_gene\"]\n",
    "        h_pathway = encoder_outputs[dosage_name][\"encoder\"][\"h_pathway\"]\n",
    "\n",
    "        gene_embeddings_by_dosage[dosage_name] = {\n",
    "            inv_gene_map[i]: h_gene[i].cpu().numpy() for i in range(len(h_gene))\n",
    "        }\n",
    "        pathway_embeddings_by_dosage[dosage_name] = {\n",
    "            inv_pathway_map[i]: h_pathway[i].cpu().numpy() for i in range(len(h_pathway))\n",
    "            if i in inv_pathway_map\n",
    "        }\n",
    "\n",
    "        gene_id_sets.append(set(gene_map.keys()))\n",
    "\n",
    "    return gene_embeddings_by_dosage, pathway_embeddings_by_dosage\n",
    "\n",
    "\n",
    "# --- Compute cosine drift across consecutive dosages ---\n",
    "def compute_pairwise_drift(entity_dict, dosage_order):\n",
    "    \"\"\"\n",
    "    Computes total pairwise cosine drift across consecutive dosages for each entity.\n",
    "    Returns DataFrame with index=entity, column=\"Total_Drift\".\n",
    "    \"\"\"\n",
    "    entity_ids = set.intersection(*[set(entity_dict[d].keys()) for d in dosage_order])\n",
    "    drift_scores = {}\n",
    "\n",
    "    for entity in entity_ids:\n",
    "        vectors = [entity_dict[d][entity] for d in dosage_order]\n",
    "        total_drift = 0.0\n",
    "        for i in range(len(vectors) - 1):\n",
    "            v1 = vectors[i].reshape(1, -1)\n",
    "            v2 = vectors[i + 1].reshape(1, -1)\n",
    "            drift = cosine_distances(v1, v2)[0][0]\n",
    "            total_drift += drift\n",
    "        drift_scores[entity] = total_drift\n",
    "\n",
    "    return pd.DataFrame.from_dict(drift_scores, orient=\"index\", columns=[\"Total_Drift\"])\n",
    "\n",
    "\n",
    "# --- Plot top rewired genes/pathways ---\n",
    "def plot_top_rewiring(drift_df, top_n=50, title=\"\", entity_type=\"Gene\", save_path=None):\n",
    "    \"\"\"\n",
    "    Plots top-N rewired entities (genes or pathways) based on total cosine drift.\n",
    "    \"\"\"\n",
    "    top_drift = drift_df.sort_values(\"Total_Drift\", ascending=False).head(top_n)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(max(8, top_n * 0.25), 6))  # dynamic width\n",
    "    bars = ax.bar(top_drift.index, top_drift[\"Total_Drift\"], color=\"slateblue\")\n",
    "\n",
    "    ax.set_xticks(range(len(top_drift)))\n",
    "    ax.set_xticklabels(top_drift.index, rotation=90)\n",
    "    ax.set_ylabel(\"Total Cosine Drift\")\n",
    "    ax.set_title(title or f\"Top {top_n} Rewired {entity_type}s Across Dosage\")\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.3)  # extra margin for long labels\n",
    "\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path, dpi=600, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "mapping_dir = \"Graph_Results/Graph_Mappings\"\n",
    "dosage_names = sorted(all_outputs.keys(), key=lambda x: float(x[1:]))  # works with T2.5, T10, etc.\n",
    "\n",
    "\n",
    "gene_dict, pathway_dict = load_embeddings_and_mappings(dosage_names, all_outputs, mapping_dir)\n",
    "\n",
    "# Drift\n",
    "gene_drift = compute_pairwise_drift(gene_dict, dosage_names)\n",
    "pathway_drift = compute_pairwise_drift(pathway_dict, dosage_names)\n",
    "\n",
    "plot_top_rewiring(\n",
    "    gene_drift,\n",
    "    top_n=30,\n",
    "    title=\"Top 30 Rewired Genes Across Dosage\",\n",
    "    entity_type=\"Gene\",\n",
    "    save_path=\"Plots/Gene_Rewired_Top30.png\"\n",
    ")\n",
    "\n",
    "plot_top_rewiring(\n",
    "    pathway_drift,\n",
    "    top_n=30,\n",
    "    title=\"Top 30 Rewired Pathways Across Dosage\",\n",
    "    entity_type=\"Pathway\",\n",
    "    save_path=\"Plots/Pathway_Rewired_Top30.png\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7109682",
   "metadata": {},
   "source": [
    "### Intra Dosage state analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique state labels present in T10\n",
    "import torch\n",
    "\n",
    "state_labels = graphs[\"T10\"][\"cell\"].x[:, 2]\n",
    "print(\"Unique resistance states in T10:\", torch.unique(state_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "# Extract cell embeddings and state labels from T10\n",
    "h_cell = all_outputs[\"T10\"][\"encoder\"][\"h_cell\"]  # [N_cells, 64]\n",
    "state_feats = graphs[\"T10\"][\"cell\"].x[:, 2:]       # One-hot resistance state\n",
    "\n",
    "# Determine state label per cell (0-indexed: State_1 ‚Üí label 0, etc.)\n",
    "state_labels = state_feats.argmax(dim=1)\n",
    "\n",
    "# Filter for State 2 (label 1), State 3 (label 2), State 4 (label 3)\n",
    "state2_cells = h_cell[state_labels == 1]\n",
    "state3_cells = h_cell[state_labels == 2]\n",
    "state4_cells = h_cell[state_labels == 3]\n",
    "\n",
    "# Combine and create labels\n",
    "combined = torch.cat([state2_cells, state3_cells, state4_cells], dim=0).cpu().numpy()\n",
    "labels = (\n",
    "    [\"State 2\"] * state2_cells.shape[0] +\n",
    "    [\"State 3\"] * state3_cells.shape[0] +\n",
    "    [\"State 4\"] * state4_cells.shape[0]\n",
    ")\n",
    "\n",
    "# UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "umap_result = reducer.fit_transform(combined)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = {\"State 2\": \"skyblue\", \"State 3\": \"salmon\", \"State 4\": \"orchid\"}\n",
    "\n",
    "for label in set(labels):\n",
    "    idx = [i for i, l in enumerate(labels) if l == label]\n",
    "    plt.scatter(umap_result[idx, 0], umap_result[idx, 1], label=label, alpha=0.6, s=50, color=colors[label])\n",
    "\n",
    "plt.title(\"UMAP of Cell Embeddings in T10: State 2 vs State 3 vs State 4\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Plots/T10_State2_vs_3_vs_4_umap.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Cosine distances between means\n",
    "mean_2 = state2_cells.mean(dim=0).unsqueeze(0)\n",
    "mean_3 = state3_cells.mean(dim=0).unsqueeze(0)\n",
    "mean_4 = state4_cells.mean(dim=0).unsqueeze(0)\n",
    "\n",
    "print(\"Cosine Distances Between Mean Embeddings:\")\n",
    "print(f\"State 2 vs State 3: {cosine_distances(mean_2, mean_3)[0][0]:.4f}\")\n",
    "print(f\"State 3 vs State 4: {cosine_distances(mean_3, mean_4)[0][0]:.4f}\")\n",
    "print(f\"State 2 vs State 4: {cosine_distances(mean_2, mean_4)[0][0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505227f8",
   "metadata": {},
   "source": [
    "# Predict Future Dosage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SharedHierarchicalEncoder(hidden_dim=64, num_dosages=9)\n",
    "checkpoint = torch.load(\"trained_model.pth\", map_location='cpu')\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "encoder.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559549dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "def train_lstm_to_predict_embedding(\n",
    "    encoder, graphs, dosage_to_idx,\n",
    "    target_dosage='T320', device='cpu',\n",
    "    epochs=100, lr=1e-3\n",
    "):\n",
    "    encoder = encoder.to(device)\n",
    "    encoder.eval()\n",
    "\n",
    "    optimizer = Adam(encoder.dosage_lstm.parameters(), lr=lr)\n",
    "    loss_log = []\n",
    "\n",
    "    data_target = graphs[target_dosage].to(device)\n",
    "    if not hasattr(data_target['pathway'], 'batch'):\n",
    "        data_target['pathway'].batch = torch.zeros(data_target['pathway'].num_nodes, dtype=torch.long)\n",
    "\n",
    "    idx_target = dosage_to_idx[target_dosage]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Manually compute dosage embeddings via LSTM\n",
    "        raw_embeddings = encoder.dosage_embeddings.weight.unsqueeze(0)\n",
    "        lstm_out, _ = encoder.dosage_lstm(raw_embeddings)\n",
    "        refined_virtuals = encoder.virtual_norm(lstm_out.squeeze(0))\n",
    "        predicted_embedding = refined_virtuals[idx_target]\n",
    "\n",
    "        # Get actual graph embedding for T320\n",
    "        with torch.no_grad():\n",
    "            encoder.eval()\n",
    "            true_embedding = encoder(data_target, dosage_idx=idx_target)['graph_embedding'].detach().squeeze()\n",
    "\n",
    "        # Loss and update\n",
    "        loss = F.mse_loss(predicted_embedding, true_embedding)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_log.append(loss.item())\n",
    "        print(f\"Epoch {epoch+1:03d} | MSE to {target_dosage}: {loss.item():.6f}\")\n",
    "\n",
    "    return encoder, loss_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dbb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, loss_log = train_lstm_to_predict_embedding(\n",
    "    encoder=encoder,\n",
    "    graphs=graphs,  # your loaded graph dictionary\n",
    "    dosage_to_idx=dosage_to_idx,\n",
    "    target_dosage='T320',\n",
    "    device='cpu'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79334e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    raw_embeddings = encoder.dosage_embeddings.weight.unsqueeze(0)\n",
    "    lstm_out, _ = encoder.dosage_lstm(raw_embeddings)\n",
    "    refined_virtuals = encoder.virtual_norm(lstm_out.squeeze(0))\n",
    "    predicted_T320_embedding = refined_virtuals[dosage_to_idx['T320']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_T320_embedding = encoder(graphs['T320'], dosage_idx=dosage_to_idx['T320'])['graph_embedding'].squeeze()\n",
    "\n",
    "cos_sim = F.cosine_similarity(predicted_T320_embedding, true_T320_embedding, dim=0)\n",
    "mse = F.mse_loss(predicted_T320_embedding, true_T320_embedding)\n",
    "\n",
    "print(f\"Cosine Similarity: {cos_sim.item():.4f}\")\n",
    "print(f\"MSE: {mse.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d463ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Dosage order\n",
    "dosage_range = ['T1', 'T2.5', 'T5', 'T10', 'T20', 'T40', 'T80', 'T160', 'T320']\n",
    "\n",
    "# Step 1: Collect real graph embeddings\n",
    "real_embeddings = {}\n",
    "for dose in dosage_range:\n",
    "    data = graphs[dose]\n",
    "    if not hasattr(data['pathway'], 'batch'):\n",
    "        data['pathway'].batch = torch.zeros(data['pathway'].num_nodes, dtype=torch.long)\n",
    "    real_embeddings[dose] = encoder(data, dosage_idx=dosage_to_idx[dose])['graph_embedding'].detach().squeeze()\n",
    "\n",
    "# Step 2: Compute real cosine drift between consecutive dosages\n",
    "transitions = []\n",
    "real_drift = []\n",
    "\n",
    "for i in range(1, len(dosage_range)):\n",
    "    d1, d2 = dosage_range[i-1], dosage_range[i]\n",
    "    transitions.append(f\"{d1}‚Üí{d2}\")\n",
    "    drift = 1 - F.cosine_similarity(real_embeddings[d1], real_embeddings[d2], dim=0).item()\n",
    "    real_drift.append(drift)\n",
    "\n",
    "# Step 3: Get predicted T320 embedding (from LSTM)\n",
    "with torch.no_grad():\n",
    "    raw_embeddings = encoder.dosage_embeddings.weight.unsqueeze(0)\n",
    "    lstm_out, _ = encoder.dosage_lstm(raw_embeddings)\n",
    "    refined_virtuals = encoder.virtual_norm(lstm_out.squeeze(0))\n",
    "    predicted_T320 = refined_virtuals[dosage_to_idx['T320']]\n",
    "\n",
    "# Step 4: Compute predicted drift from T160\n",
    "real_T160 = real_embeddings[\"T160\"]\n",
    "real_T320 = real_embeddings[\"T320\"]\n",
    "\n",
    "predicted_drift = 1 - F.cosine_similarity(real_T160, predicted_T320, dim=0).item()\n",
    "real_drift_T320 = 1 - F.cosine_similarity(real_T160, real_T320, dim=0).item()\n",
    "\n",
    "# Step 5: Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(transitions, real_drift, color='blue', marker='o', linewidth=2, label='Real Embedding Drift')\n",
    "\n",
    "# Highlight predicted and true T320 drift vs T160\n",
    "offset = 0.0015\n",
    "plt.axhline(predicted_drift + offset, color='red', linestyle='--', linewidth=1.5,\n",
    "            label=f'Predicted T320 vs T160 ({predicted_drift:.2f})')\n",
    "plt.axhline(real_drift_T320 - offset, color='green', linestyle='--', linewidth=1.5,\n",
    "            label=f'Real T320 vs T160 ({real_drift_T320:.2f})')\n",
    "\n",
    "# Styling\n",
    "plt.title(\"Gene Embedding Drift with Predicted T320\", fontsize=16, weight='bold')\n",
    "plt.xlabel(\"Dosage Transition\", fontsize=13)\n",
    "plt.ylabel(\"Mean Cosine Distance\", fontsize=13)\n",
    "plt.xticks(rotation=45, fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=10, loc='upper left', frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Step 1: Create a new encoder with 10 dosage slots (T1‚ÄìT320 + T640)\n",
    "encoder = SharedHierarchicalEncoder(hidden_dim=64, num_dosages=10)\n",
    "\n",
    "# Step 2: Load the checkpoint\n",
    "checkpoint = torch.load(\"trained_model.pth\", map_location='cpu')\n",
    "state_dict = checkpoint['encoder']\n",
    "\n",
    "# Step 3: Fix dosage_embeddings to match new size\n",
    "old_dosage_embeddings = state_dict['dosage_embeddings.weight']  # shape: [9, 64]\n",
    "new_dosage_embeddings = torch.zeros(10, 64)                      # shape: [10, 64]\n",
    "new_dosage_embeddings[:9] = old_dosage_embeddings               # copy old weights\n",
    "\n",
    "# Step 4: Update the state dict and load it\n",
    "state_dict['dosage_embeddings.weight'] = new_dosage_embeddings\n",
    "encoder.load_state_dict(state_dict, strict=False)\n",
    "encoder.eval()\n",
    "\n",
    "# Step 5: Extrapolate to T640 (index 9)\n",
    "with torch.no_grad():\n",
    "    extrapolated_virtuals = encoder.refine_virtuals_with_lstm()\n",
    "    pred_T640_embedding = extrapolated_virtuals[9]  # index 9 = T640\n",
    "\n",
    "print(\"‚úÖ Extrapolated T640 embedding vector:\")\n",
    "print(pred_T640_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b75b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Get extrapolated virtuals for T1‚ÄìT640 (T640 at index 9)\n",
    "with torch.no_grad():\n",
    "    all_virtuals = encoder.refine_virtuals_with_lstm().cpu()  # shape: [10, 64]\n",
    "\n",
    "# Step 2: PCA to 2D\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(all_virtuals.numpy())\n",
    "\n",
    "# Step 3: Dosage labels\n",
    "dosage_labels = ['T1', 'T2.5', 'T5', 'T10', 'T20', 'T40', 'T80', 'T160', 'T320', 'T640']\n",
    "colors = ['gray'] * 9 + ['red']  # mark T640 in red\n",
    "\n",
    "# Step 4: Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, label in enumerate(dosage_labels):\n",
    "    plt.scatter(coords[i, 0], coords[i, 1], color=colors[i], s=100, label=label)\n",
    "    plt.text(coords[i, 0]+0.02, coords[i, 1], label, fontsize=10)\n",
    "\n",
    "# Draw arrows to show dosage progression\n",
    "for i in range(9):  # T1 to T320\n",
    "    plt.arrow(coords[i, 0], coords[i, 1],\n",
    "              coords[i+1, 0] - coords[i, 0],\n",
    "              coords[i+1, 1] - coords[i, 1],\n",
    "              head_width=0.02, head_length=0.03, fc='blue', ec='blue')\n",
    "\n",
    "plt.title(\"üìà Dosage Progression: T1 ‚Üí T640 (Extrapolated in Red)\")\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "pyg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
