{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv, global_mean_pool \n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GlobalAttention\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdeb476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the hetero graph (safe if you trust the source)\n",
    "data = torch.load(\"Graph_Results/HeteroGraphs_ScaledFinal/HeteroGraph_T1.pt\", weights_only=False)\n",
    "\n",
    "# Print node types and sizes\n",
    "print(\"Node Types and Features:\")\n",
    "for ntype in data.node_types:\n",
    "    print(f\"  {ntype}: {data[ntype].x.shape}\")\n",
    "\n",
    "# Print edge types and count\n",
    "print(\"\\nEdge Types:\")\n",
    "for etype in data.edge_types:\n",
    "    edge_index = data[etype].edge_index\n",
    "    print(f\"  {etype}: {edge_index.shape[1]} edges\")\n",
    "\n",
    "# Check a few values from cell node features\n",
    "print(\"\\nSample cell node features (first 5 rows):\")\n",
    "print(data[\"cell\"].x[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NodeFeatureEncoders(nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cell_encoder = nn.Sequential(\n",
    "            nn.Linear(7, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.gene_encoder = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, cell_x, gene_x):\n",
    "        h_cell = self.cell_encoder(cell_x)\n",
    "        h_gene = self.gene_encoder(gene_x)\n",
    "        return h_cell, h_gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAttentionWithWeights(GlobalAttention):\n",
    "    def forward(self, x, index, ptr=None, dim_size=None, dim=0):\n",
    "        \"\"\"\n",
    "        x: Node embeddings\n",
    "        index: Index tensor (typically the batch vector)\n",
    "        \"\"\"\n",
    "        gate = self.gate_nn(x).squeeze(-1)      # [N]\n",
    "        gate = torch.sigmoid(gate)              # attention weights\n",
    "        x_weighted = x * gate.unsqueeze(-1)     # [N, F]\n",
    "\n",
    "        # Perform aggregation (mean by default)\n",
    "        out = torch.zeros(dim_size or int(index.max()) + 1, x.size(-1), device=x.device)\n",
    "        out = out.index_add(dim, index, x_weighted)\n",
    "\n",
    "        return out, gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a009ad04",
   "metadata": {},
   "source": [
    "## NO Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbdad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import NNConv, global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "\n",
    "class SharedHierarchicalEncoder_NoAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, lstm_hidden_dim=None, num_dosages=9, num_aux_outputs=1,\n",
    "                 dropout=0.1, use_virtual_node=True):\n",
    "        super().__init__()\n",
    "        self.use_virtual_node = use_virtual_node\n",
    "        self.hidden_dim = hidden_dim             \n",
    "\n",
    "        # === Node encoders (cell and gene)\n",
    "        self.node_encoders = NodeFeatureEncoders(hidden_dim)\n",
    "\n",
    "        # === Edge MLP for cell ‚Üí gene\n",
    "        self.edge_mlp_cell_gene = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Message Passing (only cell ‚Üí gene)\n",
    "        self.cell_to_gene_conv = NNConv(hidden_dim, hidden_dim, self.edge_mlp_cell_gene, aggr='mean')\n",
    "\n",
    "        # === Final fusion for graph-level embedding\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fuse_global = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Optional auxiliary head\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_aux_outputs)\n",
    "        )\n",
    "\n",
    "        # === Virtual Node (Dosage-aware)\n",
    "        if self.use_virtual_node:\n",
    "            lstm_dim = lstm_hidden_dim or hidden_dim\n",
    "            self.dosage_embeddings = nn.Embedding(num_dosages, hidden_dim)\n",
    "            self.virtual_norm = nn.LayerNorm(hidden_dim)\n",
    "            self.dosage_lstm = nn.LSTM(hidden_dim, lstm_dim, batch_first=True)\n",
    "\n",
    "            self.fuse_cell_virtual = nn.Sequential(\n",
    "                nn.Linear(hidden_dim + lstm_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            )\n",
    "            self.fuse_gene_virtual = nn.Sequential(\n",
    "                nn.Linear(hidden_dim + lstm_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            )\n",
    "\n",
    "    def refine_virtuals_with_lstm(self):\n",
    "        raw_dosage_embeddings = self.dosage_embeddings.weight.unsqueeze(0)  # [1, num_dosages, H]\n",
    "        lstm_out, _ = self.dosage_lstm(raw_dosage_embeddings)\n",
    "        return self.virtual_norm(lstm_out.squeeze(0))  # [num_dosages, H]\n",
    "\n",
    "    def get_batch_safe(self, node_data, device):\n",
    "        \"\"\"Return .batch if available, else dummy zeros\"\"\"\n",
    "        batch = getattr(node_data, \"batch\", None)\n",
    "        if batch is None:\n",
    "            return torch.zeros(node_data.num_nodes, dtype=torch.long, device=device)\n",
    "        return batch\n",
    "\n",
    "    def forward(self, data, dosage_idx=None):\n",
    "        cell_x = data[\"cell\"].x\n",
    "        gene_x = data[\"gene\"].x\n",
    "        device = cell_x.device\n",
    "\n",
    "        # === Node feature encoding\n",
    "        h_cell, h_gene = self.node_encoders(cell_x, gene_x)\n",
    "\n",
    "        # === Handle virtual dosage node\n",
    "        if self.use_virtual_node:\n",
    "            refined_dosage_virtuals = self.refine_virtuals_with_lstm()\n",
    "            dosage_virtual = refined_dosage_virtuals[dosage_idx]  # [B, H]\n",
    "\n",
    "            cell_batch = self.get_batch_safe(data[\"cell\"], device)\n",
    "            gene_batch = self.get_batch_safe(data[\"gene\"], device)\n",
    "\n",
    "            h_cell = self.fuse_cell_virtual(torch.cat([h_cell, dosage_virtual[cell_batch]], dim=1))\n",
    "            h_gene = self.fuse_gene_virtual(torch.cat([h_gene, dosage_virtual[gene_batch]], dim=1))\n",
    "        else:\n",
    "            dosage_virtual = torch.zeros(h_cell.size(0), self.hidden_dim, device=h_cell.device)\n",
    "\n",
    "        # === Message Passing (cell ‚Üí gene)\n",
    "        h_gene_updated = self.cell_to_gene_conv(\n",
    "            (h_cell, h_gene),\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_index,\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_attr\n",
    "        )\n",
    "\n",
    "        # === Graph embedding via global mean pooling over genes\n",
    "        gene_batch = self.get_batch_safe(data[\"gene\"], device)\n",
    "        pooled_gene = global_mean_pool(h_gene_updated, gene_batch)\n",
    "\n",
    "        graph_embedding = self.fuse_global(torch.cat([\n",
    "            pooled_gene, dosage_virtual\n",
    "        ], dim=1))\n",
    "\n",
    "        aux_output = self.aux_head(graph_embedding)\n",
    "\n",
    "        # === Normalize outputs for cosine comparison\n",
    "        h_cell = F.normalize(h_cell, p=2, dim=-1)\n",
    "        h_gene_updated = F.normalize(h_gene_updated, p=2, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"h_cell\": h_cell,\n",
    "            \"h_gene\": h_gene_updated,\n",
    "            \"dosage_virtual\": dosage_virtual,\n",
    "            \"graph_embedding\": graph_embedding,\n",
    "            \"aux_output\": aux_output.squeeze(),\n",
    "            \"gene_attention_weights\": None  # <== No attention in this model\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf563d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GeneToCellDecoder_NoAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, cell_feature_dim=7, dropout=0.1, use_virtual_node=True):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.cell_feature_dim = cell_feature_dim  # ‚úÖ store for later use\n",
    "        self.use_virtual_node = use_virtual_node\n",
    "\n",
    "        # === Pool gene embeddings to single graph embedding\n",
    "        self.gene_pool_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Cell Reconstruction\n",
    "        self.decode_to_cells_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.decode_to_cells_proj = nn.Linear(hidden_dim, cell_feature_dim)  # ‚úÖ used here\n",
    "\n",
    "        # === Gene Reconstruction\n",
    "        self.decode_to_genes_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.decode_to_genes_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        if self.use_virtual_node:\n",
    "            self.dosage_embedding = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, h_gene_updated, h_cell, graph_embedding, dosage_virtual=None):\n",
    "        B, N_cells, _ = h_cell.size()\n",
    "        _, N_genes, _ = h_gene_updated.size()\n",
    "\n",
    "        # === Virtual node adjustment\n",
    "        if self.use_virtual_node and dosage_virtual is not None:\n",
    "            graph_embedding = graph_embedding + self.dosage_embedding(dosage_virtual)\n",
    "\n",
    "        # === Pool gene embeddings to graph embedding\n",
    "        h_gene_pooled = h_gene_updated.mean(dim=1)  # [B, H]\n",
    "        gene_graph_embedding = self.gene_pool_proj(h_gene_pooled)  # [B, H]\n",
    "\n",
    "        # === Expand to match number of cells\n",
    "        gene_to_cell_input = gene_graph_embedding.unsqueeze(1).expand(-1, N_cells, -1)  # [B, N_cells, H]\n",
    "\n",
    "        # === Decode cells\n",
    "        cell_recon = gene_to_cell_input + h_cell  # Residual connection\n",
    "        cell_recon = self.decode_to_cells_fc(cell_recon)\n",
    "        cell_recon = F.normalize(self.decode_to_cells_proj(cell_recon), p=2, dim=-1)  # ‚úÖ 64-d output\n",
    "\n",
    "        # === Decode genes\n",
    "        gene_recon = self.decode_to_genes_fc(h_gene_updated)\n",
    "        gene_recon = F.normalize(self.decode_to_genes_proj(gene_recon), p=2, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"reconstructed_cells\": cell_recon,      # ‚úÖ [B, N_cells, 64]\n",
    "            \"reconstructed_genes\": gene_recon,      # ‚úÖ [B, N_genes, 64]\n",
    "            \"attention_gene_to_cell\": None,\n",
    "            \"attention_entropy\": None,\n",
    "            \"attention_kl_div\": None\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d679392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data.storage import NodeStorage\n",
    "\n",
    "# ‚úÖ Whitelist NodeStorage for unpickling in PyTorch ‚â• 2.6\n",
    "torch.serialization.add_safe_globals([NodeStorage])\n",
    "\n",
    "def load_all_dosage_graphs_for_batching(graph_dir, pattern_prefix=\"HeteroGraph_T\"):\n",
    "    graphs = []\n",
    "    dosage_keys = []\n",
    "\n",
    "    for fname in os.listdir(graph_dir):\n",
    "        if fname.startswith(pattern_prefix) and fname.endswith(\".pt\"):\n",
    "            dosage_key = fname.replace(\".pt\", \"\").replace(pattern_prefix, \"T\")\n",
    "            path = os.path.join(graph_dir, fname)\n",
    "            \n",
    "            # ‚úÖ Explicitly allow full object loading\n",
    "            data = torch.load(path, weights_only=False)\n",
    "            \n",
    "            data.dosage_key = dosage_key  # for reference\n",
    "            dosage_keys.append(dosage_key)\n",
    "            graphs.append(data)\n",
    "\n",
    "    # Sort graphs and dosage keys by numeric dosage (T1, T2.5, ..., T320)\n",
    "    sorted_pairs = sorted(zip(dosage_keys, graphs), key=lambda x: float(x[0].replace(\"T\", \"\")))\n",
    "    sorted_dosage_keys, sorted_graphs = zip(*sorted_pairs)\n",
    "\n",
    "    # Create dosage index mapping\n",
    "    dosage_levels = [float(k.replace(\"T\", \"\")) for k in sorted_dosage_keys]\n",
    "    dosage_to_idx = {\n",
    "        f\"T{int(d) if d.is_integer() else d}\": i for i, d in enumerate(dosage_levels)\n",
    "    }\n",
    "\n",
    "    # Add dosage_idx to each graph\n",
    "    for graph, key in zip(sorted_graphs, sorted_dosage_keys):\n",
    "        graph.dosage_idx = torch.tensor([dosage_to_idx[key]], dtype=torch.long)\n",
    "\n",
    "    return list(sorted_graphs), dosage_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e52dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GeneToCellLoss_NoAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lambda_cell=1.0,\n",
    "        lambda_gene=1.0,\n",
    "        use_stat_alignment=True,\n",
    "        reduction='mean',\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lambda_cell = lambda_cell\n",
    "        self.lambda_gene = lambda_gene\n",
    "        self.use_stat_alignment = use_stat_alignment\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, recon, target):\n",
    "        loss_components = {}\n",
    "\n",
    "        # === Gene Reconstruction Loss\n",
    "        recon_gene = recon[\"reconstructed_genes\"]\n",
    "        target_gene = target[\"h_gene\"]\n",
    "\n",
    "        recon_gene = recon_gene.view(-1, recon_gene.shape[-1])\n",
    "        target_gene = target_gene.view(-1, target_gene.shape[-1])\n",
    "\n",
    "        L_gene = F.mse_loss(recon_gene, target_gene, reduction=self.reduction)\n",
    "\n",
    "        if self.use_stat_alignment:\n",
    "            std_diff = F.mse_loss(recon_gene.std(dim=0), target_gene.std(dim=0), reduction=self.reduction)\n",
    "            mean_diff = F.mse_loss(recon_gene.mean(dim=0), target_gene.mean(dim=0), reduction=self.reduction)\n",
    "            L_gene += std_diff + mean_diff\n",
    "\n",
    "        loss_components[\"gene_loss\"] = self.lambda_gene * L_gene\n",
    "\n",
    "        # === Cell Reconstruction Loss\n",
    "        recon_cell = recon[\"reconstructed_cells\"]\n",
    "        target_cell = target[\"h_cell\"]\n",
    "\n",
    "        recon_cell = recon_cell.view(-1, recon_cell.shape[-1])\n",
    "        target_cell = target_cell.view(-1, target_cell.shape[-1])\n",
    "\n",
    "        L_cell = F.mse_loss(recon_cell, target_cell, reduction=self.reduction)\n",
    "        loss_components[\"cell_loss\"] = self.lambda_cell * L_cell\n",
    "\n",
    "        # === Total Loss\n",
    "        total = sum(loss_components.values())\n",
    "        loss_components[\"total_loss\"] = total\n",
    "\n",
    "        return total, loss_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86cc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gene_to_cell_model_no_attention(\n",
    "    encoder, decoder, graphs_list, dosage_to_idx,\n",
    "    optimizer=None,\n",
    "    device='cuda',\n",
    "    epochs=100,\n",
    "    loss_weights=None,\n",
    "    save_path=None,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    patience=30,\n",
    "    min_delta=1e-3,\n",
    "    batch_size=2\n",
    "):\n",
    "    import os\n",
    "    import json\n",
    "    import torch\n",
    "    from torch_geometric.utils import to_dense_batch\n",
    "    from torch_geometric.loader import DataLoader\n",
    "    from torch.optim import Adam\n",
    "    from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    loss_kwargs = {k: v for k, v in (loss_weights or {}).items() if k not in [\"log_grad_norm\", \"monitored_losses\"]}\n",
    "    criterion = GeneToCellLoss_NoAttention(**loss_kwargs).to(device)\n",
    "\n",
    "    monitored_keys = loss_weights.get(\"monitored_losses\", [\"total_loss\"]) if loss_weights else [\"total_loss\"]\n",
    "    best_monitored_loss = {k: float(\"inf\") for k in monitored_keys} if len(monitored_keys) > 1 else float(\"inf\")\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5, verbose=True, min_lr=1e-5)\n",
    "    loader = DataLoader(graphs_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    loss_log = []\n",
    "    recon_outputs_log = []\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        epoch_loss_dict = {k: 0.0 for k in [\"cell_loss\", \"gene_loss\", \"total_loss\"]}\n",
    "\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            encoder_out = encoder(batch, batch.dosage_idx)\n",
    "\n",
    "            h_gene, _ = to_dense_batch(encoder_out[\"h_gene\"], batch[\"gene\"].batch)\n",
    "            h_cell, _ = to_dense_batch(encoder_out[\"h_cell\"], batch[\"cell\"].batch)\n",
    "\n",
    "            decoder_out = decoder(\n",
    "                h_gene_updated=h_gene,\n",
    "                h_cell=h_cell,\n",
    "                graph_embedding=encoder_out[\"graph_embedding\"],\n",
    "                dosage_virtual=encoder_out.get(\"dosage_virtual\")\n",
    "            )\n",
    "\n",
    "            targets = {\n",
    "                \"h_cell\": h_cell.detach(),\n",
    "                \"h_gene\": h_gene.detach(),\n",
    "                \"cell_batch\": batch[\"cell\"].batch,\n",
    "                \"gene_batch\": batch[\"gene\"].batch\n",
    "            }\n",
    "\n",
    "            loss, loss_components = criterion(decoder_out, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            for key in epoch_loss_dict:\n",
    "                epoch_loss_dict[key] += loss_components.get(key, 0.0)\n",
    "\n",
    "            recon_outputs_log.append({\n",
    "                \"dosage_idx\": int(batch.dosage_idx.item()),\n",
    "                \"attention\": None,\n",
    "                \"reconstructed_cells\": decoder_out[\"reconstructed_cells\"].detach().cpu().tolist(),\n",
    "                \"reconstructed_genes\": decoder_out[\"reconstructed_genes\"].detach().cpu().tolist(),\n",
    "                \"real_cell_embeddings\": h_cell.detach().cpu().tolist(),\n",
    "                \"real_gene_embeddings\": h_gene.detach().cpu().tolist()\n",
    "            })\n",
    "\n",
    "        num_batches = len(loader)\n",
    "        avg_loss_dict = {k: v / num_batches for k, v in epoch_loss_dict.items()}\n",
    "        loss_log.append(avg_loss_dict)\n",
    "\n",
    "        scheduler_loss = avg_loss_dict[\"total_loss\"]\n",
    "        scheduler.step(scheduler_loss)\n",
    "\n",
    "        improvement = False\n",
    "        for k in monitored_keys:\n",
    "            current = avg_loss_dict[k]\n",
    "            if isinstance(best_monitored_loss, dict):\n",
    "                if current < best_monitored_loss[k] - min_delta:\n",
    "                    best_monitored_loss[k] = current\n",
    "                    improvement = True\n",
    "            else:\n",
    "                if current < best_monitored_loss - min_delta:\n",
    "                    best_monitored_loss = current\n",
    "                    improvement = True\n",
    "\n",
    "        print(\"Epoch {:03d} | Total: {:.4f} | Cell: {:.4f}, Gene: {:.4f}\".format(\n",
    "            epoch + 1, avg_loss_dict['total_loss'], avg_loss_dict['cell_loss'], avg_loss_dict['gene_loss']\n",
    "        ))\n",
    "\n",
    "        if improvement:\n",
    "            best_epoch = epoch + 1\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping at epoch {} after {} stagnant epochs.\".format(epoch + 1, patience))\n",
    "            break\n",
    "\n",
    "    # === Save model and logs for best epoch only\n",
    "    if save_path:\n",
    "        torch.save({\n",
    "            \"encoder\": encoder.state_dict(),\n",
    "            \"decoder\": decoder.state_dict()\n",
    "        }, save_path)\n",
    "        print(\"Model saved to {}\".format(save_path))\n",
    "\n",
    "        def tensor_to_python(x):\n",
    "            if isinstance(x, torch.Tensor):\n",
    "                return x.item() if x.dim() == 0 else x.detach().cpu().tolist()\n",
    "            elif isinstance(x, dict):\n",
    "                return {k: tensor_to_python(v) for k, v in x.items()}\n",
    "            elif isinstance(x, list):\n",
    "                return [tensor_to_python(i) for i in x]\n",
    "            return x\n",
    "\n",
    "        def save_json(path, obj):\n",
    "            obj_clean = tensor_to_python(obj)\n",
    "            with open(path, \"w\") as f:\n",
    "                json.dump(obj_clean, f, indent=2)\n",
    "\n",
    "        loss_log = loss_log[:best_epoch]\n",
    "        best_recon_outputs = recon_outputs_log[(best_epoch - 1) * len(loader): best_epoch * len(loader)]\n",
    "\n",
    "        save_json(save_path.replace(\".pth\", \"_loss_log.json\"), loss_log)\n",
    "        save_json(save_path.replace(\".pth\", \"_recon_outputs.json\"), best_recon_outputs)\n",
    "\n",
    "    return encoder, decoder, loss_log, best_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# === Step 1: Load graphs\n",
    "graph_dir = \"Graph_Results/HeteroGraphs_ScaledFinal\"\n",
    "graphs_list, dosage_to_idx = load_all_dosage_graphs_for_batching(graph_dir)\n",
    "\n",
    "# === Step 2: Instantiate models (no-attention versions)\n",
    "hidden_dim = 64\n",
    "encoder = SharedHierarchicalEncoder_NoAttention(hidden_dim=hidden_dim, num_dosages=len(dosage_to_idx))\n",
    "decoder = GeneToCellDecoder_NoAttention(hidden_dim=hidden_dim, cell_feature_dim=64)\n",
    "\n",
    "# === Step 3: Define loss weights (no attention)\n",
    "loss_weights = {\n",
    "    \"lambda_cell\": 1.0,\n",
    "    \"lambda_gene\": 1.0,\n",
    "    \"use_stat_alignment\": True,\n",
    "    \"monitored_losses\": [\"total_loss\"]\n",
    "}\n",
    "\n",
    "# === Step 4: Train using no-attention trainer\n",
    "trained_encoder, trained_decoder, loss_log, best_epoch = train_gene_to_cell_model_no_attention(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    graphs_list=graphs_list,\n",
    "    dosage_to_idx=dosage_to_idx,\n",
    "    device='cpu',\n",
    "    epochs=45,\n",
    "    save_path=\"trained_gene_to_cell_model_no_attention.pth\",\n",
    "    loss_weights=loss_weights,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Best Epoch: {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1ff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "# === Model and file paths\n",
    "model_path = \"trained_gene_to_cell_model_no_attention.pth\"\n",
    "model_prefix = model_path.replace(\".pth\", \"\")\n",
    "\n",
    "# === Architecture config (must match training config exactly!)\n",
    "hidden_dim = 64\n",
    "cell_feature_dim = 64       # ‚úÖ FIXED: this matches trained decoder output\n",
    "dropout = 0.2\n",
    "use_virtual_node = True\n",
    "\n",
    "# === Rebuild encoder and decoder (NoAttention versions)\n",
    "encoder = SharedHierarchicalEncoder_NoAttention(\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_dosages=len(dosage_to_idx),\n",
    "    use_virtual_node=use_virtual_node,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "decoder = GeneToCellDecoder_NoAttention(\n",
    "    hidden_dim=hidden_dim,\n",
    "    cell_feature_dim=cell_feature_dim,  # ‚úÖ Now matches saved model\n",
    "    dropout=dropout,\n",
    "    use_virtual_node=use_virtual_node\n",
    ")\n",
    "\n",
    "# === Load weights\n",
    "state_dict = torch.load(model_path, map_location='cpu')\n",
    "encoder.load_state_dict(state_dict[\"encoder\"])\n",
    "decoder.load_state_dict(state_dict[\"decoder\"])\n",
    "\n",
    "# === Set to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# === Move to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "print(f\"‚úÖ No-Attention Model successfully loaded and moved to {device}\")\n",
    "\n",
    "# === Optional: Load saved JSON logs (for post hoc analysis)\n",
    "def load_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "loss_log_path = model_prefix + \"_loss_log.json\"\n",
    "recon_outputs_path = model_prefix + \"_recon_outputs.json\"\n",
    "\n",
    "# === Load logs if they exist\n",
    "if os.path.exists(loss_log_path):\n",
    "    loss_log = load_json(loss_log_path)\n",
    "    print(f\"üìà Loaded loss log ({len(loss_log)} epochs)\")\n",
    "\n",
    "if os.path.exists(recon_outputs_path):\n",
    "    recon_outputs = load_json(recon_outputs_path)\n",
    "    print(f\"üìä Loaded {len(recon_outputs)} graph reconstructions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "import matplotlib as mpl\n",
    "\n",
    "# === Step 1: Load recon outputs from no-attention model\n",
    "with open(\"trained_gene_to_cell_model_no_attention_recon_outputs.json\", \"r\") as f:\n",
    "    recon_outputs = json.load(f)\n",
    "\n",
    "# === Step 2: Dosage label mapping\n",
    "dosage_to_idx = {\n",
    "    \"T1\": 0, \"T2.5\": 1, \"T5\": 2, \"T10\": 3, \"T20\": 4,\n",
    "    \"T40\": 5, \"T80\": 6, \"T160\": 7, \"T320\": 8\n",
    "}\n",
    "idx_to_dosage = {v: k for k, v in dosage_to_idx.items()}\n",
    "\n",
    "# === Step 3: Aggregate real + recon cell embeddings\n",
    "real_all, recon_all = [], []\n",
    "real_labels, recon_labels = [], []\n",
    "\n",
    "for entry in recon_outputs:\n",
    "    dosage = idx_to_dosage.get(entry[\"dosage_idx\"], f\"IDX_{entry['dosage_idx']}\")\n",
    "    real = np.array(entry[\"real_cell_embeddings\"]).squeeze(0)\n",
    "    recon = np.array(entry[\"reconstructed_cells\"]).squeeze(0)\n",
    "\n",
    "    if real.shape[1] != recon.shape[1]:\n",
    "        print(f\"‚ö†Ô∏è Skipping {dosage}: real={real.shape}, recon={recon.shape}\")\n",
    "        continue\n",
    "\n",
    "    real_all.append(real)\n",
    "    recon_all.append(recon)\n",
    "    real_labels.extend([dosage] * len(real))\n",
    "    recon_labels.extend([dosage] * len(recon))\n",
    "\n",
    "real_all = np.vstack(real_all)\n",
    "recon_all = np.vstack(recon_all)\n",
    "\n",
    "# === Check that dimensions match before applying PCA\n",
    "assert real_all.shape == recon_all.shape, f\"Shape mismatch: real {real_all.shape}, recon {recon_all.shape}\"\n",
    "\n",
    "# === Step 4: PCA smoothing\n",
    "n_features = real_all.shape[1]\n",
    "pca = PCA(n_components=min(n_features, 7))\n",
    "real_pca = pca.fit_transform(real_all)\n",
    "recon_pca = pca.transform(recon_all)\n",
    "\n",
    "# === Step 5: UMAP (shared init)\n",
    "# === Step 5: UMAP (fit on real, transform recon)\n",
    "umap = UMAP(n_neighbors=30, min_dist=0.4, metric='cosine', random_state=42, init=\"spectral\")\n",
    "real_umap = umap.fit_transform(real_pca)\n",
    "recon_umap = umap.transform(recon_pca)  # ‚úÖ Ensures shared manifold\n",
    "\n",
    "\n",
    "# === Optional: Save UMAP embeddings for reproducibility\n",
    "np.save(\"umap_real_no_attention.npy\", real_umap)\n",
    "np.save(\"umap_recon_no_attention.npy\", recon_umap)\n",
    "\n",
    "# === Step 6: Plot config\n",
    "mpl.rcParams.update({\n",
    "    \"font.size\": 12,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 13,\n",
    "    \"legend.fontsize\": 11\n",
    "})\n",
    "\n",
    "dosages = sorted(set(real_labels))\n",
    "color_map = plt.get_cmap('tab10')\n",
    "color_dict = {d: color_map(i % 10) for i, d in enumerate(dosages)}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6), sharex=True, sharey=True)\n",
    "\n",
    "# === Left: Real (Encoded from Encoder)\n",
    "for d in dosages:\n",
    "    idxs = [i for i, l in enumerate(real_labels) if l == d]\n",
    "    axs[0].scatter(real_umap[idxs, 0], real_umap[idxs, 1],\n",
    "                   label=d, s=15, alpha=0.75, edgecolor='k', linewidth=0.2,\n",
    "                   color=color_dict[d])\n",
    "axs[0].set_title(\"Encoded Cell Embeddings (No Attention)\", weight='bold')\n",
    "axs[0].set_xlabel(\"UMAP-1\")\n",
    "axs[0].set_ylabel(\"UMAP-2\")\n",
    "\n",
    "# === Right: Reconstructed (Decoder Output)\n",
    "for d in dosages:\n",
    "    idxs = [i for i, l in enumerate(recon_labels) if l == d]\n",
    "    axs[1].scatter(recon_umap[idxs, 0], recon_umap[idxs, 1],\n",
    "                   label=d, s=15, alpha=0.75, edgecolor='k', linewidth=0.2,\n",
    "                   color=color_dict[d])\n",
    "axs[1].set_title(\"Reconstructed Cell Embeddings (No Attention)\", weight='bold')\n",
    "axs[1].set_xlabel(\"UMAP-1\")\n",
    "\n",
    "# === Legend\n",
    "axs[1].legend(title=\"Dosage\", bbox_to_anchor=(1.05, 1), loc='upper left', markerscale=1.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "# === Optional: Save to file\n",
    "# plt.savefig(\"umap_real_vs_recon_no_attention.png\", dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a6249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load recon outputs from no-attention model\n",
    "with open(\"trained_gene_to_cell_model_no_attention_recon_outputs.json\", \"r\") as f:\n",
    "    recon_outputs = json.load(f)\n",
    "\n",
    "# === Step 2: Dosage ID mapping\n",
    "dosage_to_idx = {\n",
    "    \"T1\": 0, \"T2.5\": 1, \"T5\": 2, \"T10\": 3, \"T20\": 4,\n",
    "    \"T40\": 5, \"T80\": 6, \"T160\": 7, \"T320\": 8\n",
    "}\n",
    "idx_to_dosage = {v: k for k, v in dosage_to_idx.items()}\n",
    "\n",
    "# === Step 3: Compute metrics per dosage\n",
    "results = []\n",
    "real_all = []\n",
    "recon_all = []\n",
    "\n",
    "for entry in recon_outputs:\n",
    "    dosage = idx_to_dosage.get(entry[\"dosage_idx\"], \"unknown\")\n",
    "    \n",
    "    real = torch.tensor(entry[\"real_cell_embeddings\"], dtype=torch.float).squeeze(0)\n",
    "    recon = torch.tensor(entry[\"reconstructed_cells\"], dtype=torch.float).squeeze(0)\n",
    "    \n",
    "    if real.shape != recon.shape:\n",
    "        print(f\"‚ö†Ô∏è Skipping {dosage} due to shape mismatch: {real.shape} vs {recon.shape}\")\n",
    "        continue\n",
    "\n",
    "    # Mean Squared Error\n",
    "    mse = F.mse_loss(recon, real, reduction='mean').item()\n",
    "\n",
    "    # Cosine Similarity\n",
    "    real_norm = F.normalize(real, dim=-1)\n",
    "    recon_norm = F.normalize(recon, dim=-1)\n",
    "    cosine_sim = F.cosine_similarity(real_norm, recon_norm, dim=-1).mean().item()\n",
    "\n",
    "    results.append({\n",
    "        \"Dosage\": dosage,\n",
    "        \"MSE\": round(mse, 6),\n",
    "        \"CosineSimilarity\": round(cosine_sim, 6)\n",
    "    })\n",
    "\n",
    "    real_all.append(real)\n",
    "    recon_all.append(recon)\n",
    "\n",
    "# === Step 4: Output as DataFrame (sorted)\n",
    "df_metrics = pd.DataFrame(results)\n",
    "df_metrics = df_metrics.sort_values(by=\"Dosage\", key=lambda col: [dosage_to_idx.get(d, 999) for d in col])\n",
    "\n",
    "# === Step 5: Overall metrics\n",
    "real_all = torch.cat(real_all, dim=0)\n",
    "recon_all = torch.cat(recon_all, dim=0)\n",
    "\n",
    "mse_all = F.mse_loss(recon_all, real_all, reduction='mean').item()\n",
    "cosine_all = F.cosine_similarity(\n",
    "    F.normalize(recon_all, dim=-1),\n",
    "    F.normalize(real_all, dim=-1),\n",
    "    dim=-1\n",
    ").mean().item()\n",
    "\n",
    "# Add overall row\n",
    "df_metrics.loc[len(df_metrics.index)] = {\n",
    "    \"Dosage\": \"Overall\",\n",
    "    \"MSE\": round(mse_all, 6),\n",
    "    \"CosineSimilarity\": round(cosine_all, 6)\n",
    "}\n",
    "\n",
    "# === Print table\n",
    "print(\"\\nüìä Per-dosage and Overall Reconstruction Metrics:\")\n",
    "print(df_metrics.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94681d",
   "metadata": {},
   "source": [
    "## NO LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedHierarchicalEncoder_NoLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_dosages=9, num_aux_outputs=1,\n",
    "                 dropout=0.1, use_virtual_node=True):\n",
    "        super().__init__()\n",
    "        self.use_virtual_node = use_virtual_node\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # === Node encoders (cell and gene)\n",
    "        self.node_encoders = NodeFeatureEncoders(hidden_dim)\n",
    "\n",
    "        # === Edge MLP for cell ‚Üí gene\n",
    "        self.edge_mlp_cell_gene = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Message Passing (only cell ‚Üí gene)\n",
    "        self.cell_to_gene_conv = NNConv(hidden_dim, hidden_dim, self.edge_mlp_cell_gene, aggr='mean')\n",
    "\n",
    "        # === Attention Pooling over genes\n",
    "        self.att_pool = GlobalAttentionWithWeights(gate_nn=nn.Linear(hidden_dim, 1))\n",
    "\n",
    "        # === Final fusion for graph-level embedding\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fuse_global = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Optional auxiliary head\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_aux_outputs)\n",
    "        )\n",
    "\n",
    "        # === Virtual Node (Dosage-aware, no LSTM)\n",
    "        if self.use_virtual_node:\n",
    "            self.dosage_embeddings = nn.Embedding(num_dosages, hidden_dim)\n",
    "            self.virtual_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "            self.fuse_cell_virtual = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            )\n",
    "            self.fuse_gene_virtual = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            )\n",
    "\n",
    "    def get_batch_safe(self, node_data, device):\n",
    "        batch = getattr(node_data, \"batch\", None)\n",
    "        if batch is None:\n",
    "            return torch.zeros(node_data.num_nodes, dtype=torch.long, device=device)\n",
    "        return batch\n",
    "\n",
    "    def forward(self, data, dosage_idx=None):\n",
    "        cell_x = data[\"cell\"].x\n",
    "        gene_x = data[\"gene\"].x\n",
    "        device = cell_x.device\n",
    "\n",
    "        h_cell, h_gene = self.node_encoders(cell_x, gene_x)\n",
    "\n",
    "        if self.use_virtual_node and dosage_idx is not None:\n",
    "            dosage_virtual = self.virtual_norm(self.dosage_embeddings(dosage_idx))\n",
    "            cell_batch = self.get_batch_safe(data[\"cell\"], device)\n",
    "            gene_batch = self.get_batch_safe(data[\"gene\"], device)\n",
    "\n",
    "            h_cell = self.fuse_cell_virtual(torch.cat([h_cell, dosage_virtual[cell_batch]], dim=1))\n",
    "            h_gene = self.fuse_gene_virtual(torch.cat([h_gene, dosage_virtual[gene_batch]], dim=1))\n",
    "        else:\n",
    "            dosage_virtual = torch.zeros(h_cell.size(0), self.hidden_dim, device=device)\n",
    "\n",
    "        h_gene_updated = self.cell_to_gene_conv(\n",
    "            (h_cell, h_gene),\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_index,\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_attr\n",
    "        )\n",
    "\n",
    "        gene_batch = self.get_batch_safe(data[\"gene\"], device)\n",
    "        pooled_gene, gene_attention_weights = self.att_pool(h_gene_updated, gene_batch)\n",
    "\n",
    "        graph_embedding = self.fuse_global(torch.cat([\n",
    "            pooled_gene, dosage_virtual[:pooled_gene.size(0)]\n",
    "        ], dim=1))\n",
    "\n",
    "        aux_output = self.aux_head(graph_embedding)\n",
    "\n",
    "        h_cell = F.normalize(h_cell, p=2, dim=-1)\n",
    "        h_gene_updated = F.normalize(h_gene_updated, p=2, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"h_cell\": h_cell,\n",
    "            \"h_gene\": h_gene_updated,\n",
    "            \"dosage_virtual\": dosage_virtual,\n",
    "            \"graph_embedding\": graph_embedding,\n",
    "            \"aux_output\": aux_output.squeeze(),\n",
    "            \"gene_attention_weights\": gene_attention_weights\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049894cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GeneToCellDecoder_NoLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_heads=2, dropout=0.1, temperature=1.0, use_virtual_node=True):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.temperature = temperature\n",
    "        self.use_virtual_node = use_virtual_node\n",
    "\n",
    "        self.gene_proj_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "        self.cell_query_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.decode_to_cells_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.decode_to_cells_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.decode_to_genes_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.decode_to_genes_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, h_gene_updated, h_cell, graph_embedding, dosage_virtual=None):\n",
    "        B, N_cells, _ = h_cell.size()\n",
    "        _, N_genes, _ = h_gene_updated.size()\n",
    "\n",
    "        # ‚úÖ Graph embedding already includes dosage effect ‚Äî no need to reapply\n",
    "        h_gene = self.gene_proj_head(h_gene_updated)\n",
    "        h_cell_q = self.cell_query_proj(h_cell)\n",
    "\n",
    "        h_gene_scaled = h_gene / self.temperature\n",
    "        cell_recon, attn_weights = self.attn(\n",
    "            query=h_cell_q,\n",
    "            key=h_gene_scaled,\n",
    "            value=h_gene_scaled,\n",
    "            need_weights=True,\n",
    "            average_attn_weights=False\n",
    "        )\n",
    "\n",
    "        # === Attention diagnostics\n",
    "        attn_weights = attn_weights / (attn_weights.sum(dim=-1, keepdim=True) + 1e-8)\n",
    "        attn_probs = attn_weights.clamp(min=1e-6)\n",
    "        entropy_per_head = (-attn_probs * torch.log(attn_probs)).sum(dim=-1)\n",
    "        attention_entropy = entropy_per_head.mean()\n",
    "\n",
    "        uniform_probs = torch.full_like(attn_probs, 1.0 / attn_probs.size(-1))\n",
    "        attention_kl_div = F.kl_div(attn_probs.log(), uniform_probs, reduction='batchmean')\n",
    "\n",
    "        # === Final reconstruction\n",
    "        cell_recon = F.dropout(cell_recon, p=0.1, training=self.training) + h_cell\n",
    "        cell_recon = self.decode_to_cells_fc(cell_recon)\n",
    "        cell_recon = F.normalize(self.decode_to_cells_proj(cell_recon), p=2, dim=-1)\n",
    "\n",
    "        gene_recon = self.decode_to_genes_fc(h_gene)\n",
    "        gene_recon = F.normalize(self.decode_to_genes_proj(gene_recon), p=2, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"reconstructed_cells\": cell_recon,\n",
    "            \"reconstructed_genes\": gene_recon,\n",
    "            \"attention_gene_to_cell\": attn_weights,\n",
    "            \"attention_entropy\": attention_entropy,\n",
    "            \"attention_kl_div\": attention_kl_div\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GeneToCellLoss_NoLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lambda_cell=1.0,\n",
    "        lambda_gene=1.0,\n",
    "        lambda_attention=0.1,\n",
    "        lambda_kl=0.01,\n",
    "        use_stat_alignment=False,\n",
    "        reduction='mean',\n",
    "        attention_reg_type='kl',  # 'kl', 'entropy', 'both'\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lambda_cell = lambda_cell\n",
    "        self.lambda_gene = lambda_gene\n",
    "        self.lambda_attention = lambda_attention\n",
    "        self.lambda_kl = lambda_kl\n",
    "        self.use_stat_alignment = use_stat_alignment\n",
    "        self.reduction = reduction\n",
    "        self.attention_reg_type = attention_reg_type.lower()\n",
    "\n",
    "    def forward(self, recon, target):\n",
    "        loss_components = {}\n",
    "\n",
    "        # === Gene Reconstruction Loss ===\n",
    "        recon_gene = recon[\"reconstructed_genes\"]\n",
    "        target_gene = target[\"h_gene\"]\n",
    "\n",
    "        recon_gene = recon_gene.view(-1, recon_gene.shape[-1])\n",
    "        target_gene = target_gene.view(-1, target_gene.shape[-1])\n",
    "\n",
    "        L_gene = F.mse_loss(recon_gene, target_gene, reduction=self.reduction)\n",
    "\n",
    "        if self.use_stat_alignment:\n",
    "            std_diff = F.mse_loss(recon_gene.std(dim=0), target_gene.std(dim=0), reduction=self.reduction)\n",
    "            mean_diff = F.mse_loss(recon_gene.mean(dim=0), target_gene.mean(dim=0), reduction=self.reduction)\n",
    "            L_gene += std_diff + mean_diff\n",
    "\n",
    "        loss_components[\"gene_loss\"] = self.lambda_gene * L_gene\n",
    "\n",
    "        # === Cell Reconstruction Loss ===\n",
    "        recon_cell = recon[\"reconstructed_cells\"]\n",
    "        target_cell = target[\"h_cell\"]\n",
    "\n",
    "        recon_cell = recon_cell.view(-1, recon_cell.shape[-1])\n",
    "        target_cell = target_cell.view(-1, target_cell.shape[-1])\n",
    "\n",
    "        L_cell = F.mse_loss(recon_cell, target_cell, reduction=self.reduction)\n",
    "        loss_components[\"cell_loss\"] = self.lambda_cell * L_cell\n",
    "\n",
    "        # === Attention Regularization ===\n",
    "        attn_reg_loss = 0.0\n",
    "\n",
    "        if self.attention_reg_type in ['entropy', 'both']:\n",
    "            entropy = recon.get(\"attention_entropy\", None)\n",
    "            if entropy is not None and torch.is_tensor(entropy):\n",
    "                attn_reg_loss += -entropy.mean()  # ‚ùóÔ∏èmaximize entropy\n",
    "\n",
    "        if self.attention_reg_type in ['kl', 'both']:\n",
    "            kl_div = recon.get(\"attention_kl_div\", None)\n",
    "            if kl_div is not None and torch.is_tensor(kl_div):\n",
    "                attn_reg_loss += kl_div\n",
    "\n",
    "        loss_components[\"attention_reg_loss\"] = self.lambda_attention * attn_reg_loss\n",
    "\n",
    "        # === Total Loss\n",
    "        total = (\n",
    "            loss_components[\"gene_loss\"] +\n",
    "            loss_components[\"cell_loss\"] +\n",
    "            loss_components[\"attention_reg_loss\"]\n",
    "        )\n",
    "        loss_components[\"total_loss\"] = total\n",
    "\n",
    "        return total, loss_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abe641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gene_to_cell_model_NoLSTM(\n",
    "    encoder, decoder, graphs_list, dosage_to_idx,\n",
    "    optimizer=None,\n",
    "    device='cuda',\n",
    "    epochs=100,\n",
    "    loss_weights=None,\n",
    "    save_path=None,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    patience=30,\n",
    "    min_delta=1e-3,\n",
    "    batch_size=2\n",
    "):\n",
    "    import os\n",
    "    import json\n",
    "    import torch\n",
    "    from torch_geometric.utils import to_dense_batch\n",
    "    from torch_geometric.loader import DataLoader\n",
    "    from torch.optim import Adam\n",
    "    from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    loss_kwargs = {k: v for k, v in (loss_weights or {}).items() if k not in [\"log_grad_norm\", \"monitored_losses\"]}\n",
    "    criterion = GeneToCellLoss(**loss_kwargs).to(device)\n",
    "\n",
    "    monitored_keys = loss_weights.get(\"monitored_losses\", [\"total_loss\"]) if loss_weights else [\"total_loss\"]\n",
    "    best_monitored_loss = {k: float(\"inf\") for k in monitored_keys} if len(monitored_keys) > 1 else float(\"inf\")\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5, verbose=True, min_lr=1e-5)\n",
    "    loader = DataLoader(graphs_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    loss_log = []\n",
    "    attention_log = []\n",
    "    kl_div_log = []\n",
    "    recon_outputs_log = []\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        epoch_loss_dict = {k: 0.0 for k in [\"cell_loss\", \"gene_loss\", \"attention_reg_loss\", \"total_loss\"]}\n",
    "        epoch_attn_entropy = []\n",
    "        epoch_attn_kl = []\n",
    "\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            encoder_out = encoder(batch, batch.dosage_idx)\n",
    "\n",
    "            h_gene, _ = to_dense_batch(encoder_out[\"h_gene\"], batch[\"gene\"].batch)\n",
    "            h_cell, _ = to_dense_batch(encoder_out[\"h_cell\"], batch[\"cell\"].batch)\n",
    "\n",
    "            decoder_out = decoder(\n",
    "                h_gene_updated=h_gene,\n",
    "                h_cell=h_cell,\n",
    "                graph_embedding=encoder_out[\"graph_embedding\"],\n",
    "                dosage_virtual=encoder_out.get(\"dosage_virtual\")\n",
    "            )\n",
    "\n",
    "            # === Target: 64-dim normalized embeddings from encoder\n",
    "            targets = {\n",
    "                \"h_cell\": h_cell.detach(),\n",
    "                \"h_gene\": h_gene.detach(),\n",
    "                \"cell_batch\": batch[\"cell\"].batch,\n",
    "                \"gene_batch\": batch[\"gene\"].batch\n",
    "            }\n",
    "\n",
    "            loss, loss_components = criterion(decoder_out, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            for key in epoch_loss_dict:\n",
    "                epoch_loss_dict[key] += loss_components.get(key, 0.0)\n",
    "\n",
    "            recon_outputs_log.append({\n",
    "                \"dosage_idx\": int(batch.dosage_idx.item()),\n",
    "                \"attention\": decoder_out.get(\"attention_gene_to_cell\", None).detach().cpu().tolist()\n",
    "                if decoder_out.get(\"attention_gene_to_cell\") is not None else None,\n",
    "                \"reconstructed_cells\": decoder_out[\"reconstructed_cells\"].detach().cpu().tolist(),\n",
    "                \"reconstructed_genes\": decoder_out[\"reconstructed_genes\"].detach().cpu().tolist(),\n",
    "                \"real_cell_embeddings\": h_cell.detach().cpu().tolist(),\n",
    "                \"real_gene_embeddings\": h_gene.detach().cpu().tolist()\n",
    "            })\n",
    "\n",
    "            # === Updated: record attention metrics\n",
    "            entropy = decoder_out.get(\"attention_entropy\", None)\n",
    "            if entropy is not None and torch.is_tensor(entropy):\n",
    "                epoch_attn_entropy.append(entropy.detach().cpu())\n",
    "\n",
    "            kl_div = decoder_out.get(\"attention_kl_div\", None)\n",
    "            if kl_div is not None and torch.is_tensor(kl_div):\n",
    "                epoch_attn_kl.append(kl_div.detach().cpu())\n",
    "\n",
    "        num_batches = len(loader)\n",
    "        avg_loss_dict = {k: v / num_batches for k, v in epoch_loss_dict.items()}\n",
    "        loss_log.append(avg_loss_dict)\n",
    "\n",
    "        mean_entropy = torch.stack(epoch_attn_entropy).mean().item() if epoch_attn_entropy else 0.0\n",
    "        attention_log.append(mean_entropy)\n",
    "\n",
    "        mean_kl = torch.stack(epoch_attn_kl).mean().item() if epoch_attn_kl else 0.0\n",
    "        kl_div_log.append(mean_kl)\n",
    "\n",
    "        scheduler_loss = avg_loss_dict[\"total_loss\"]\n",
    "        scheduler.step(scheduler_loss)\n",
    "\n",
    "        improvement = False\n",
    "        for k in monitored_keys:\n",
    "            current = avg_loss_dict[k]\n",
    "            if isinstance(best_monitored_loss, dict):\n",
    "                if current < best_monitored_loss[k] - min_delta:\n",
    "                    best_monitored_loss[k] = current\n",
    "                    improvement = True\n",
    "            else:\n",
    "                if current < best_monitored_loss - min_delta:\n",
    "                    best_monitored_loss = current\n",
    "                    improvement = True\n",
    "\n",
    "        print(\"Epoch {:03d} | Total: {:.4f} | Cell: {:.4f}, Gene: {:.4f}, AttnReg: {:.4f} | Entropy: {:.4f} | KLDiv: {:.4f}\".format(\n",
    "            epoch + 1, avg_loss_dict['total_loss'], avg_loss_dict['cell_loss'],\n",
    "            avg_loss_dict['gene_loss'], avg_loss_dict['attention_reg_loss'],\n",
    "            mean_entropy, mean_kl\n",
    "        ))\n",
    "\n",
    "        if improvement:\n",
    "            best_epoch = epoch + 1\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping at epoch {} after {} stagnant epochs.\".format(epoch + 1, patience))\n",
    "            break\n",
    "\n",
    "    # === Save model + logs at best epoch\n",
    "    if save_path:\n",
    "        torch.save({\n",
    "            \"encoder\": encoder.state_dict(),\n",
    "            \"decoder\": decoder.state_dict()\n",
    "        }, save_path)\n",
    "        print(\"Model saved to {}\".format(save_path))\n",
    "\n",
    "        def tensor_to_python(x):\n",
    "            if isinstance(x, torch.Tensor):\n",
    "                return x.item() if x.dim() == 0 else x.detach().cpu().tolist()\n",
    "            elif isinstance(x, dict):\n",
    "                return {k: tensor_to_python(v) for k, v in x.items()}\n",
    "            elif isinstance(x, list):\n",
    "                return [tensor_to_python(i) for i in x]\n",
    "            return x\n",
    "\n",
    "        def save_json(path, obj):\n",
    "            obj_clean = tensor_to_python(obj)\n",
    "            with open(path, \"w\") as f:\n",
    "                json.dump(obj_clean, f, indent=2)\n",
    "\n",
    "        loss_log = loss_log[:best_epoch]\n",
    "        attention_log = attention_log[:best_epoch]\n",
    "        kl_div_log = kl_div_log[:best_epoch]\n",
    "        best_recon_outputs = recon_outputs_log[(best_epoch - 1) * len(loader): best_epoch * len(loader)]\n",
    "\n",
    "        save_json(save_path.replace(\".pth\", \"_loss_log.json\"), loss_log)\n",
    "        save_json(save_path.replace(\".pth\", \"_attn_entropy.json\"), attention_log)\n",
    "        save_json(save_path.replace(\".pth\", \"_attn_kl_div.json\"), kl_div_log)\n",
    "        save_json(save_path.replace(\".pth\", \"_recon_outputs.json\"), best_recon_outputs)\n",
    "\n",
    "    return encoder, decoder, loss_log, best_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ffcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# === Step 1: Load graphs\n",
    "graph_dir = \"Graph_Results/HeteroGraphs_ScaledFinal\"\n",
    "graphs_list, dosage_to_idx = load_all_dosage_graphs_for_batching(graph_dir)\n",
    "\n",
    "# === Step 2: Instantiate models (NoLSTM encoder and NoLSTM decoder)\n",
    "hidden_dim = 64\n",
    "\n",
    "encoder = SharedHierarchicalEncoder_NoLSTM(  # ‚úÖ No LSTM version\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_dosages=len(dosage_to_idx),\n",
    "    use_virtual_node=True,  # ‚úÖ still uses virtual node but with no LSTM\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "decoder = GeneToCellDecoder_NoLSTM(  # ‚úÖ NoLSTM version of decoder\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_heads=2,\n",
    "    dropout=0.2,\n",
    "    temperature=1.0,\n",
    "    use_virtual_node=True\n",
    ")\n",
    "\n",
    "# === Step 3: Define loss weights\n",
    "loss_weights = {\n",
    "    \"lambda_cell\": 1.0,\n",
    "    \"lambda_gene\": 1.0,\n",
    "    \"lambda_attention\": 0.05,\n",
    "    \"lambda_kl\": 0.01,\n",
    "    \"use_stat_alignment\": True,\n",
    "    \"monitored_losses\": [\"total_loss\"]\n",
    "}\n",
    "\n",
    "trained_encoder, trained_decoder, loss_log, best_epoch = train_gene_to_cell_model_NoLSTM(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    graphs_list=graphs_list,\n",
    "    dosage_to_idx=dosage_to_idx,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    epochs=30,\n",
    "    save_path=\"trained_gene_to_cell_model_NoLSTM.pth\",  # ‚úÖ updated filename\n",
    "    loss_weights=loss_weights,\n",
    "    batch_size=1\n",
    ")\n",
    "print(f\"\\nüéØ Best Epoch: {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae725889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "# === Define architecture config (must match training)\n",
    "hidden_dim = 64\n",
    "num_heads = 2\n",
    "dropout = 0.2\n",
    "use_virtual_node = True\n",
    "\n",
    "# === Dosage mapping (required for instantiating encoder)\n",
    "# Replace with your actual mapping if not already defined\n",
    "dosage_to_idx = {\n",
    "    \"T1\": 0, \"T2.5\": 1, \"T5\": 2, \"T10\": 3, \"T20\": 4,\n",
    "    \"T40\": 5, \"T80\": 6, \"T160\": 7, \"T320\": 8\n",
    "}\n",
    "\n",
    "# === File paths\n",
    "model_path = \"trained_gene_to_cell_model_NoLSTM.pth\"  # ‚úÖ Updated\n",
    "model_prefix = model_path.replace(\".pth\", \"\")\n",
    "\n",
    "# === Instantiate NoLSTM encoder and decoder\n",
    "encoder = SharedHierarchicalEncoder_NoLSTM(\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_dosages=len(dosage_to_idx),\n",
    "    use_virtual_node=use_virtual_node,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "decoder = GeneToCellDecoder_NoLSTM(\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_heads=num_heads,\n",
    "    dropout=dropout,\n",
    "    use_virtual_node=use_virtual_node\n",
    ")\n",
    "\n",
    "# === Load model weights\n",
    "state_dict = torch.load(model_path, map_location='cpu')\n",
    "encoder.load_state_dict(state_dict[\"encoder\"])\n",
    "decoder.load_state_dict(state_dict[\"decoder\"])\n",
    "\n",
    "# === Set to eval mode and move to device\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "print(f\"‚úÖ NoLSTM Model successfully loaded and moved to {device}\")\n",
    "\n",
    "# === Optional: Load JSON logs\n",
    "def load_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# === Load training logs (loss, attention, reconstruction)\n",
    "loss_log_path = model_prefix + \"_loss_log.json\"\n",
    "entropy_log_path = model_prefix + \"_attn_entropy.json\"\n",
    "kl_div_log_path = model_prefix + \"_attn_kl_div.json\"\n",
    "recon_outputs_path = model_prefix + \"_recon_outputs.json\"\n",
    "\n",
    "if os.path.exists(loss_log_path):\n",
    "    loss_log = load_json(loss_log_path)\n",
    "    print(f\"üìà Loaded loss log ({len(loss_log)} epochs)\")\n",
    "\n",
    "if os.path.exists(entropy_log_path):\n",
    "    attention_entropy_log = load_json(entropy_log_path)\n",
    "    print(f\"üß† Loaded attention entropy log ({len(attention_entropy_log)} epochs)\")\n",
    "\n",
    "if os.path.exists(kl_div_log_path):\n",
    "    kl_div_log = load_json(kl_div_log_path)\n",
    "    print(f\"üìâ Loaded attention KL divergence log ({len(kl_div_log)} epochs)\")\n",
    "\n",
    "if os.path.exists(recon_outputs_path):\n",
    "    recon_outputs = load_json(recon_outputs_path)\n",
    "    print(f\"üìä Loaded {len(recon_outputs)} graph reconstructions with attention maps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594511d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "import matplotlib as mpl\n",
    "\n",
    "# === Step 1: Load recon outputs\n",
    "with open(\"trained_gene_to_cell_model_NoLSTM_recon_outputs.json\", \"r\") as f:\n",
    "    recon_outputs = json.load(f)\n",
    "\n",
    "# === Step 2: Dosage label mapping\n",
    "dosage_to_idx = {\n",
    "    \"T1\": 0, \"T2.5\": 1, \"T5\": 2, \"T10\": 3, \"T20\": 4,\n",
    "    \"T40\": 5, \"T80\": 6, \"T160\": 7, \"T320\": 8\n",
    "}\n",
    "idx_to_dosage = {v: k for k, v in dosage_to_idx.items()}\n",
    "\n",
    "# === Step 3: Aggregate data\n",
    "real_all, recon_all = [], []\n",
    "real_labels, recon_labels = [], []\n",
    "\n",
    "for entry in recon_outputs:\n",
    "    dosage = idx_to_dosage.get(entry[\"dosage_idx\"], f\"IDX_{entry['dosage_idx']}\")\n",
    "    real = np.array(entry[\"real_cell_embeddings\"]).squeeze(0)\n",
    "    recon = np.array(entry[\"reconstructed_cells\"]).squeeze(0)\n",
    "\n",
    "    if real.shape[1] != recon.shape[1]:\n",
    "        print(f\"‚ö†Ô∏è Skipping {dosage}: real={real.shape}, recon={recon.shape}\")\n",
    "        continue\n",
    "\n",
    "    real_all.append(real)\n",
    "    recon_all.append(recon)\n",
    "    real_labels.extend([dosage] * len(real))\n",
    "    recon_labels.extend([dosage] * len(recon))\n",
    "\n",
    "real_all = np.vstack(real_all)\n",
    "recon_all = np.vstack(recon_all)\n",
    "\n",
    "# === Step 4: Optional L2 normalization\n",
    "real_all = real_all / (np.linalg.norm(real_all, axis=1, keepdims=True) + 1e-8)\n",
    "recon_all = recon_all / (np.linalg.norm(recon_all, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# === Step 5: PCA\n",
    "n_features = real_all.shape[1]\n",
    "pca = PCA(n_components=min(n_features, 7))\n",
    "pca_real = pca.fit_transform(real_all)\n",
    "pca_recon = pca.transform(recon_all)\n",
    "\n",
    "# === Step 6: Shared UMAP projection\n",
    "combined = np.vstack([pca_real, pca_recon])\n",
    "umap = UMAP(n_neighbors=30, min_dist=0.4, metric='cosine', random_state=42, init=\"spectral\")\n",
    "combined_umap = umap.fit_transform(combined)\n",
    "real_umap = combined_umap[:len(pca_real)]\n",
    "recon_umap = combined_umap[len(pca_real):]\n",
    "\n",
    "# === Step 7: Plot\n",
    "mpl.rcParams.update({\n",
    "    \"font.size\": 12,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 13,\n",
    "    \"legend.fontsize\": 11\n",
    "})\n",
    "\n",
    "dosages = sorted(set(real_labels))\n",
    "color_map = plt.get_cmap('tab10')\n",
    "color_dict = {d: color_map(i % 10) for i, d in enumerate(dosages)}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6), sharex=True, sharey=True)\n",
    "\n",
    "# === Plot real embeddings\n",
    "for d in dosages:\n",
    "    idxs = [i for i, l in enumerate(real_labels) if l == d]\n",
    "    axs[0].scatter(real_umap[idxs, 0], real_umap[idxs, 1],\n",
    "                   label=d, s=15, alpha=0.75, edgecolor='k', linewidth=0.2,\n",
    "                   color=color_dict[d])\n",
    "axs[0].set_title(\"Real Cell Embeddings (No LSTM)\", weight='bold')\n",
    "axs[0].set_xlabel(\"UMAP-1\")\n",
    "axs[0].set_ylabel(\"UMAP-2\")\n",
    "\n",
    "# === Plot reconstructed embeddings\n",
    "for d in dosages:\n",
    "    idxs = [i for i, l in enumerate(recon_labels) if l == d]\n",
    "    axs[1].scatter(recon_umap[idxs, 0], recon_umap[idxs, 1],\n",
    "                   label=d, s=15, alpha=0.75, edgecolor='k', linewidth=0.2,\n",
    "                   color=color_dict[d])\n",
    "axs[1].set_title(\"Reconstructed Cell Embeddings (No LSTM)\", weight='bold')\n",
    "axs[1].set_xlabel(\"UMAP-1\")\n",
    "\n",
    "# === Shared formatting\n",
    "for ax in axs:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "axs[1].legend(title=\"Dosage\", bbox_to_anchor=(1.05, 1), loc='upper left', markerscale=1.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5676b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load recon outputs for No LSTM model\n",
    "with open(\"trained_gene_to_cell_model_NoLSTM_recon_outputs.json\", \"r\") as f:\n",
    "    recon_outputs = json.load(f)\n",
    "\n",
    "# === Step 2: Dosage ID mapping\n",
    "dosage_to_idx = {\n",
    "    \"T1\": 0, \"T2.5\": 1, \"T5\": 2, \"T10\": 3, \"T20\": 4,\n",
    "    \"T40\": 5, \"T80\": 6, \"T160\": 7, \"T320\": 8\n",
    "}\n",
    "idx_to_dosage = {v: k for k, v in dosage_to_idx.items()}\n",
    "\n",
    "# === Step 3: Compute metrics per dosage\n",
    "results = []\n",
    "all_real = []\n",
    "all_recon = []\n",
    "\n",
    "for entry in recon_outputs:\n",
    "    dosage = idx_to_dosage.get(entry[\"dosage_idx\"], \"unknown\")\n",
    "    \n",
    "    real = torch.tensor(entry[\"real_cell_embeddings\"], dtype=torch.float).squeeze(0)\n",
    "    recon = torch.tensor(entry[\"reconstructed_cells\"], dtype=torch.float).squeeze(0)\n",
    "    \n",
    "    if real.shape != recon.shape:\n",
    "        print(f\"‚ö†Ô∏è Skipping {dosage} due to shape mismatch: {real.shape} vs {recon.shape}\")\n",
    "        continue\n",
    "\n",
    "    # Store for global metrics\n",
    "    all_real.append(real)\n",
    "    all_recon.append(recon)\n",
    "\n",
    "    # Mean Squared Error\n",
    "    mse = F.mse_loss(recon, real, reduction='mean').item()\n",
    "\n",
    "    # Cosine Similarity\n",
    "    real_norm = F.normalize(real, dim=-1)\n",
    "    recon_norm = F.normalize(recon, dim=-1)\n",
    "    cosine_sim = F.cosine_similarity(real_norm, recon_norm, dim=-1).mean().item()\n",
    "\n",
    "    results.append({\n",
    "        \"Dosage\": dosage,\n",
    "        \"MSE\": round(mse, 6),\n",
    "        \"CosineSimilarity\": round(cosine_sim, 6)\n",
    "    })\n",
    "\n",
    "# === Step 4: Global metrics\n",
    "real_all = torch.cat(all_real, dim=0)\n",
    "recon_all = torch.cat(all_recon, dim=0)\n",
    "\n",
    "global_mse = F.mse_loss(recon_all, real_all, reduction='mean').item()\n",
    "global_cosine = F.cosine_similarity(\n",
    "    F.normalize(real_all, dim=-1),\n",
    "    F.normalize(recon_all, dim=-1),\n",
    "    dim=-1\n",
    ").mean().item()\n",
    "\n",
    "# === Step 5: Output as DataFrame\n",
    "df_metrics = pd.DataFrame(results)\n",
    "df_metrics = df_metrics.sort_values(by=\"Dosage\", key=lambda col: [dosage_to_idx.get(d, 999) for d in col])\n",
    "\n",
    "print(df_metrics.to_string(index=False))\n",
    "print(f\"\\nüìä Global MSE: {round(global_mse, 6)}\")\n",
    "print(f\"üìä Global Cosine Similarity: {round(global_cosine, 6)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb3639",
   "metadata": {},
   "source": [
    "## No Virtual Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "\n",
    "class SharedHierarchicalEncoder_NoVirtualNode(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_aux_outputs=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # === Node encoders (cell and gene)\n",
    "        self.node_encoders = NodeFeatureEncoders(hidden_dim)\n",
    "\n",
    "        # === Edge MLP for cell ‚Üí gene\n",
    "        self.edge_mlp_cell_gene = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Message Passing (only cell ‚Üí gene)\n",
    "        self.cell_to_gene_conv = NNConv(hidden_dim, hidden_dim, self.edge_mlp_cell_gene, aggr='mean')\n",
    "\n",
    "        # === Attention Pooling over genes\n",
    "        self.att_pool = GlobalAttentionWithWeights(gate_nn=nn.Linear(hidden_dim, 1))\n",
    "\n",
    "        # === Final fusion for graph-level embedding\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fuse_global = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),  # Only pooled_gene now\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Optional auxiliary head\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_aux_outputs)\n",
    "        )\n",
    "\n",
    "    def get_batch_safe(self, node_data, device):\n",
    "        batch = getattr(node_data, \"batch\", None)\n",
    "        if batch is None:\n",
    "            return torch.zeros(node_data.num_nodes, dtype=torch.long, device=device)\n",
    "        return batch\n",
    "\n",
    "    def forward(self, data):\n",
    "        cell_x = data[\"cell\"].x\n",
    "        gene_x = data[\"gene\"].x\n",
    "        device = cell_x.device\n",
    "\n",
    "        # === Node feature encoding\n",
    "        h_cell, h_gene = self.node_encoders(cell_x, gene_x)\n",
    "\n",
    "        # === Message Passing (cell ‚Üí gene)\n",
    "        h_gene_updated = self.cell_to_gene_conv(\n",
    "            (h_cell, h_gene),\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_index,\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_attr\n",
    "        )\n",
    "\n",
    "        # === Graph embedding via gene attention pooling\n",
    "        gene_batch = self.get_batch_safe(data[\"gene\"], device)\n",
    "        pooled_gene, gene_attention_weights = self.att_pool(h_gene_updated, gene_batch)\n",
    "\n",
    "        # === Final fusion (no dosage virtual)\n",
    "        graph_embedding = self.fuse_global(pooled_gene)\n",
    "\n",
    "        # === Auxiliary output\n",
    "        aux_output = self.aux_head(graph_embedding)\n",
    "\n",
    "        # === Normalize outputs for cosine comparison\n",
    "        h_cell = F.normalize(h_cell, p=2, dim=-1)\n",
    "        h_gene_updated = F.normalize(h_gene_updated, p=2, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"h_cell\": h_cell,\n",
    "            \"h_gene\": h_gene_updated,\n",
    "            \"graph_embedding\": graph_embedding,\n",
    "            \"aux_output\": aux_output.squeeze(),\n",
    "            \"gene_attention_weights\": gene_attention_weights\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GeneToCellDecoder_NoVirtualNode(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_heads=2, dropout=0.1, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.gene_proj_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "        self.cell_query_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.decode_to_cells_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.decode_to_cells_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.decode_to_genes_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.decode_to_genes_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, h_gene_updated, h_cell, graph_embedding):\n",
    "        B, N_cells, _ = h_cell.size()\n",
    "        _, N_genes, _ = h_gene_updated.size()\n",
    "\n",
    "        h_gene = self.gene_proj_head(h_gene_updated)\n",
    "        h_cell_q = self.cell_query_proj(h_cell)\n",
    "\n",
    "        h_gene_scaled = h_gene / self.temperature\n",
    "        cell_recon, attn_weights = self.attn(\n",
    "            query=h_cell_q,\n",
    "            key=h_gene_scaled,\n",
    "            value=h_gene_scaled,\n",
    "            need_weights=True,\n",
    "            average_attn_weights=False\n",
    "        )\n",
    "\n",
    "        attn_weights = attn_weights / (attn_weights.sum(dim=-1, keepdim=True) + 1e-8)\n",
    "        attn_probs = attn_weights.clamp(min=1e-6)\n",
    "        entropy_per_head = (-attn_probs * torch.log(attn_probs)).sum(dim=-1)\n",
    "        attention_entropy = entropy_per_head.mean()\n",
    "\n",
    "        uniform_probs = torch.full_like(attn_probs, 1.0 / attn_probs.size(-1))\n",
    "        attention_kl_div = F.kl_div(attn_probs.log(), uniform_probs, reduction='batchmean')\n",
    "\n",
    "        cell_recon = F.dropout(cell_recon, p=0.1, training=self.training) + h_cell\n",
    "        cell_recon = self.decode_to_cells_fc(cell_recon)\n",
    "        cell_recon = F.normalize(self.decode_to_cells_proj(cell_recon), p=2, dim=-1)\n",
    "\n",
    "        gene_recon = self.decode_to_genes_fc(h_gene)\n",
    "        gene_recon = F.normalize(self.decode_to_genes_proj(gene_recon), p=2, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"reconstructed_cells\": cell_recon,\n",
    "            \"reconstructed_genes\": gene_recon,\n",
    "            \"attention_gene_to_cell\": attn_weights,\n",
    "            \"attention_entropy\": attention_entropy,\n",
    "            \"attention_kl_div\": attention_kl_div\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b5019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GeneToCellLoss_NoVirtualNode(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lambda_cell=1.0,\n",
    "        lambda_gene=1.0,\n",
    "        lambda_attention=0.1,\n",
    "        lambda_kl=0.01,\n",
    "        use_stat_alignment=False,\n",
    "        reduction='mean',\n",
    "        attention_reg_type='kl',  # 'kl', 'entropy', 'both'\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lambda_cell = lambda_cell\n",
    "        self.lambda_gene = lambda_gene\n",
    "        self.lambda_attention = lambda_attention\n",
    "        self.lambda_kl = lambda_kl\n",
    "        self.use_stat_alignment = use_stat_alignment\n",
    "        self.reduction = reduction\n",
    "        self.attention_reg_type = attention_reg_type.lower()\n",
    "\n",
    "    def forward(self, recon, target):\n",
    "        loss_components = {}\n",
    "\n",
    "        # === Gene Reconstruction Loss ===\n",
    "        recon_gene = recon[\"reconstructed_genes\"].view(-1, recon[\"reconstructed_genes\"].shape[-1])\n",
    "        target_gene = target[\"h_gene\"].view(-1, target[\"h_gene\"].shape[-1])\n",
    "\n",
    "        L_gene = F.mse_loss(recon_gene, target_gene, reduction=self.reduction)\n",
    "\n",
    "        if self.use_stat_alignment:\n",
    "            std_diff = F.mse_loss(recon_gene.std(dim=0), target_gene.std(dim=0), reduction=self.reduction)\n",
    "            mean_diff = F.mse_loss(recon_gene.mean(dim=0), target_gene.mean(dim=0), reduction=self.reduction)\n",
    "            L_gene += std_diff + mean_diff\n",
    "\n",
    "        loss_components[\"gene_loss\"] = self.lambda_gene * L_gene\n",
    "\n",
    "        # === Cell Reconstruction Loss ===\n",
    "        recon_cell = recon[\"reconstructed_cells\"].view(-1, recon[\"reconstructed_cells\"].shape[-1])\n",
    "        target_cell = target[\"h_cell\"].view(-1, target[\"h_cell\"].shape[-1])\n",
    "\n",
    "        L_cell = F.mse_loss(recon_cell, target_cell, reduction=self.reduction)\n",
    "        loss_components[\"cell_loss\"] = self.lambda_cell * L_cell\n",
    "\n",
    "        # === Attention Regularization ===\n",
    "        attn_reg_loss = 0.0\n",
    "        if self.attention_reg_type in ['entropy', 'both']:\n",
    "            entropy = recon.get(\"attention_entropy\", None)\n",
    "            if isinstance(entropy, torch.Tensor):\n",
    "                attn_reg_loss += -entropy.mean()  # Maximize entropy\n",
    "\n",
    "        if self.attention_reg_type in ['kl', 'both']:\n",
    "            kl_div = recon.get(\"attention_kl_div\", None)\n",
    "            if isinstance(kl_div, torch.Tensor):\n",
    "                attn_reg_loss += kl_div\n",
    "\n",
    "        loss_components[\"attention_reg_loss\"] = self.lambda_attention * attn_reg_loss\n",
    "\n",
    "        # === Total Loss ===\n",
    "        total = (\n",
    "            loss_components[\"gene_loss\"] +\n",
    "            loss_components[\"cell_loss\"] +\n",
    "            loss_components[\"attention_reg_loss\"]\n",
    "        )\n",
    "        loss_components[\"total_loss\"] = total\n",
    "\n",
    "        return total, loss_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gene_to_cell_model_no_virtual(\n",
    "    encoder, decoder, graphs_list,\n",
    "    optimizer=None,\n",
    "    device='cuda',\n",
    "    epochs=100,\n",
    "    loss_weights=None,\n",
    "    save_path=None,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    patience=30,\n",
    "    min_delta=1e-3,\n",
    "    batch_size=2\n",
    "):\n",
    "    import os\n",
    "    import json\n",
    "    import torch\n",
    "    from torch_geometric.utils import to_dense_batch\n",
    "    from torch_geometric.loader import DataLoader\n",
    "    from torch.optim import Adam\n",
    "    from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    loss_kwargs = {k: v for k, v in (loss_weights or {}).items() if k not in [\"log_grad_norm\", \"monitored_losses\"]}\n",
    "    criterion = GeneToCellLoss_NoVirtualNode(**loss_kwargs).to(device)\n",
    "\n",
    "    monitored_keys = loss_weights.get(\"monitored_losses\", [\"total_loss\"]) if loss_weights else [\"total_loss\"]\n",
    "    best_monitored_loss = {k: float(\"inf\") for k in monitored_keys} if len(monitored_keys) > 1 else float(\"inf\")\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5, verbose=True, min_lr=1e-5)\n",
    "    loader = DataLoader(graphs_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    loss_log = []\n",
    "    attention_log = []\n",
    "    kl_div_log = []\n",
    "    recon_outputs_log = []\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        epoch_loss_dict = {k: 0.0 for k in [\"cell_loss\", \"gene_loss\", \"attention_reg_loss\", \"total_loss\"]}\n",
    "        epoch_attn_entropy = []\n",
    "        epoch_attn_kl = []\n",
    "\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            encoder_out = encoder(batch)\n",
    "\n",
    "            h_gene, _ = to_dense_batch(encoder_out[\"h_gene\"], batch[\"gene\"].batch)\n",
    "            h_cell, _ = to_dense_batch(encoder_out[\"h_cell\"], batch[\"cell\"].batch)\n",
    "\n",
    "            decoder_out = decoder(\n",
    "                h_gene_updated=h_gene,\n",
    "                h_cell=h_cell,\n",
    "                graph_embedding=encoder_out[\"graph_embedding\"]\n",
    "            )\n",
    "\n",
    "            targets = {\n",
    "                \"h_cell\": h_cell.detach(),\n",
    "                \"h_gene\": h_gene.detach(),\n",
    "                \"cell_batch\": batch[\"cell\"].batch,\n",
    "                \"gene_batch\": batch[\"gene\"].batch\n",
    "            }\n",
    "\n",
    "            loss, loss_components = criterion(decoder_out, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            for key in epoch_loss_dict:\n",
    "                epoch_loss_dict[key] += loss_components.get(key, 0.0)\n",
    "\n",
    "            # Inside training loop:\n",
    "            dosage_idx = batch.dosage_idx.item() if hasattr(batch, \"dosage_idx\") else -1\n",
    "            \n",
    "            recon_outputs_log.append({\n",
    "                \"dosage_idx\": dosage_idx,\n",
    "                \"attention\": decoder_out.get(\"attention_gene_to_cell\", None).detach().cpu().tolist()\n",
    "                if decoder_out.get(\"attention_gene_to_cell\") is not None else None,\n",
    "                \"reconstructed_cells\": decoder_out[\"reconstructed_cells\"].detach().cpu().tolist(),\n",
    "                \"reconstructed_genes\": decoder_out[\"reconstructed_genes\"].detach().cpu().tolist(),\n",
    "                \"real_cell_embeddings\": h_cell.detach().cpu().tolist(),\n",
    "                \"real_gene_embeddings\": h_gene.detach().cpu().tolist()\n",
    "            })\n",
    "\n",
    "\n",
    "            entropy = decoder_out.get(\"attention_entropy\", None)\n",
    "            if entropy is not None and torch.is_tensor(entropy):\n",
    "                epoch_attn_entropy.append(entropy.detach().cpu())\n",
    "\n",
    "            kl_div = decoder_out.get(\"attention_kl_div\", None)\n",
    "            if kl_div is not None and torch.is_tensor(kl_div):\n",
    "                epoch_attn_kl.append(kl_div.detach().cpu())\n",
    "\n",
    "        num_batches = len(loader)\n",
    "        avg_loss_dict = {k: v / num_batches for k, v in epoch_loss_dict.items()}\n",
    "        loss_log.append(avg_loss_dict)\n",
    "\n",
    "        mean_entropy = torch.stack(epoch_attn_entropy).mean().item() if epoch_attn_entropy else 0.0\n",
    "        attention_log.append(mean_entropy)\n",
    "\n",
    "        mean_kl = torch.stack(epoch_attn_kl).mean().item() if epoch_attn_kl else 0.0\n",
    "        kl_div_log.append(mean_kl)\n",
    "\n",
    "        scheduler_loss = avg_loss_dict[\"total_loss\"]\n",
    "        scheduler.step(scheduler_loss)\n",
    "\n",
    "        improvement = False\n",
    "        for k in monitored_keys:\n",
    "            current = avg_loss_dict[k]\n",
    "            if isinstance(best_monitored_loss, dict):\n",
    "                if current < best_monitored_loss[k] - min_delta:\n",
    "                    best_monitored_loss[k] = current\n",
    "                    improvement = True\n",
    "            else:\n",
    "                if current < best_monitored_loss - min_delta:\n",
    "                    best_monitored_loss = current\n",
    "                    improvement = True\n",
    "\n",
    "        print(\"Epoch {:03d} | Total: {:.4f} | Cell: {:.4f}, Gene: {:.4f}, AttnReg: {:.4f} | Entropy: {:.4f} | KLDiv: {:.4f}\".format(\n",
    "            epoch + 1, avg_loss_dict['total_loss'], avg_loss_dict['cell_loss'],\n",
    "            avg_loss_dict['gene_loss'], avg_loss_dict['attention_reg_loss'],\n",
    "            mean_entropy, mean_kl\n",
    "        ))\n",
    "\n",
    "        if improvement:\n",
    "            best_epoch = epoch + 1\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping at epoch {} after {} stagnant epochs.\".format(epoch + 1, patience))\n",
    "            break\n",
    "\n",
    "    # === Save model + logs at best epoch\n",
    "    if save_path:\n",
    "        torch.save({\n",
    "            \"encoder\": encoder.state_dict(),\n",
    "            \"decoder\": decoder.state_dict()\n",
    "        }, save_path)\n",
    "        print(\"Model saved to {}\".format(save_path))\n",
    "\n",
    "        def tensor_to_python(x):\n",
    "            if isinstance(x, torch.Tensor):\n",
    "                return x.item() if x.dim() == 0 else x.detach().cpu().tolist()\n",
    "            elif isinstance(x, dict):\n",
    "                return {k: tensor_to_python(v) for k, v in x.items()}\n",
    "            elif isinstance(x, list):\n",
    "                return [tensor_to_python(i) for i in x]\n",
    "            return x\n",
    "\n",
    "        def save_json(path, obj):\n",
    "            obj_clean = tensor_to_python(obj)\n",
    "            with open(path, \"w\") as f:\n",
    "                json.dump(obj_clean, f, indent=2)\n",
    "\n",
    "        loss_log = loss_log[:best_epoch]\n",
    "        attention_log = attention_log[:best_epoch]\n",
    "        kl_div_log = kl_div_log[:best_epoch]\n",
    "        best_recon_outputs = recon_outputs_log[(best_epoch - 1) * len(loader): best_epoch * len(loader)]\n",
    "\n",
    "        save_json(save_path.replace(\".pth\", \"_loss_log.json\"), loss_log)\n",
    "        save_json(save_path.replace(\".pth\", \"_attn_entropy.json\"), attention_log)\n",
    "        save_json(save_path.replace(\".pth\", \"_attn_kl_div.json\"), kl_div_log)\n",
    "        save_json(save_path.replace(\".pth\", \"_recon_outputs.json\"), best_recon_outputs)\n",
    "\n",
    "    return encoder, decoder, loss_log, best_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb89ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# === Step 1: Load graphs\n",
    "graph_dir = \"Graph_Results/HeteroGraphs_ScaledFinal\"\n",
    "graphs_list, _ = load_all_dosage_graphs_for_batching(graph_dir)  # ‚úÖ dosage_to_idx no longer needed\n",
    "\n",
    "# === Step 2: Instantiate models\n",
    "hidden_dim = 64\n",
    "encoder = SharedHierarchicalEncoder_NoVirtualNode(hidden_dim=hidden_dim)\n",
    "\n",
    "decoder = GeneToCellDecoder_NoVirtualNode(hidden_dim=hidden_dim)\n",
    "\n",
    "# === Step 3: Define loss weights\n",
    "loss_weights = {\n",
    "    \"lambda_cell\": 1.0,\n",
    "    \"lambda_gene\": 1.0,\n",
    "    \"lambda_attention\": 0.05,\n",
    "    \"lambda_kl\": 0.01,\n",
    "    \"use_stat_alignment\": True,\n",
    "    \"monitored_losses\": [\"total_loss\"]\n",
    "}\n",
    "\n",
    "# === Step 4: Train\n",
    "trained_encoder, trained_decoder, loss_log, best_epoch = train_gene_to_cell_model_no_virtual(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    graphs_list=graphs_list,\n",
    "    device='cpu',\n",
    "    epochs=30,\n",
    "    save_path=\"trained_gene_to_cell_model_novirtual.pth\",\n",
    "    loss_weights=loss_weights,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Best Epoch: {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c065034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "# === Model and file paths\n",
    "model_path = \"trained_gene_to_cell_model_novirtual.pth\"\n",
    "model_prefix = model_path.replace(\".pth\", \"\")\n",
    "\n",
    "# === Architecture config (must match training)\n",
    "hidden_dim = 64\n",
    "num_heads = 2\n",
    "dropout = 0.2\n",
    "\n",
    "# === Instantiate models\n",
    "encoder = SharedHierarchicalEncoder_NoVirtualNode(\n",
    "    hidden_dim=hidden_dim,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "decoder = GeneToCellDecoder_NoVirtualNode(\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_heads=num_heads,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "# === Load weights\n",
    "state_dict = torch.load(model_path, map_location='cpu')\n",
    "encoder.load_state_dict(state_dict[\"encoder\"])\n",
    "decoder.load_state_dict(state_dict[\"decoder\"])\n",
    "\n",
    "# === Set to eval mode and move to device\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "print(f\"‚úÖ Model successfully loaded and moved to {device}\")\n",
    "\n",
    "# === Optional: Load saved JSON logs\n",
    "def load_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# === File paths\n",
    "loss_log_path = model_prefix + \"_loss_log.json\"\n",
    "entropy_log_path = model_prefix + \"_attn_entropy.json\"\n",
    "kl_div_log_path = model_prefix + \"_attn_kl_div.json\"\n",
    "recon_outputs_path = model_prefix + \"_recon_outputs.json\"\n",
    "\n",
    "# === Load logs\n",
    "if os.path.exists(loss_log_path):\n",
    "    loss_log = load_json(loss_log_path)\n",
    "    print(f\"üìà Loaded loss log ({len(loss_log)} epochs)\")\n",
    "\n",
    "if os.path.exists(entropy_log_path):\n",
    "    attention_entropy_log = load_json(entropy_log_path)\n",
    "    print(f\"üß† Loaded attention entropy log ({len(attention_entropy_log)} epochs)\")\n",
    "\n",
    "if os.path.exists(kl_div_log_path):\n",
    "    kl_div_log = load_json(kl_div_log_path)\n",
    "    print(f\"üìâ Loaded attention KL divergence log ({len(kl_div_log)} epochs)\")\n",
    "\n",
    "if os.path.exists(recon_outputs_path):\n",
    "    recon_outputs = load_json(recon_outputs_path)\n",
    "    print(f\"üìä Loaded {len(recon_outputs)} graph reconstructions with attention maps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499bfe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trained_gene_to_cell_model_novirtual_recon_outputs.json\", \"r\") as f:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "import matplotlib as mpl\n",
    "\n",
    "# === Step 1: Load recon outputs\n",
    "with open(\"trained_gene_to_cell_model_novirtual_recon_outputs.json\", \"r\") as f:\n",
    "    recon_outputs = json.load(f)\n",
    "\n",
    "# === Step 2: Dosage label mapping\n",
    "dosage_to_idx = {\n",
    "    \"T1\": 0, \"T2.5\": 1, \"T5\": 2, \"T10\": 3, \"T20\": 4,\n",
    "    \"T40\": 5, \"T80\": 6, \"T160\": 7, \"T320\": 8\n",
    "}\n",
    "idx_to_dosage = {v: k for k, v in dosage_to_idx.items()}\n",
    "\n",
    "# === Step 3: Aggregate data\n",
    "real_all, recon_all = [], []\n",
    "real_labels, recon_labels = [], []\n",
    "\n",
    "for entry in recon_outputs:\n",
    "    dosage = idx_to_dosage.get(entry[\"dosage_idx\"], f\"IDX_{entry['dosage_idx']}\")\n",
    "    real = np.array(entry[\"real_cell_embeddings\"]).squeeze(0)\n",
    "    recon = np.array(entry[\"reconstructed_cells\"]).squeeze(0)\n",
    "\n",
    "    if real.shape[1] != recon.shape[1]:\n",
    "        print(f\"‚ö†Ô∏è Skipping {dosage}: real={real.shape}, recon={recon.shape}\")\n",
    "        continue\n",
    "\n",
    "    real_all.append(real)\n",
    "    recon_all.append(recon)\n",
    "    real_labels.extend([dosage] * len(real))\n",
    "    recon_labels.extend([dosage] * len(recon))\n",
    "\n",
    "real_all = np.vstack(real_all)\n",
    "recon_all = np.vstack(recon_all)\n",
    "\n",
    "# === Step 4: Optional L2 normalization (if not already normalized)\n",
    "real_all = real_all / (np.linalg.norm(real_all, axis=1, keepdims=True) + 1e-8)\n",
    "recon_all = recon_all / (np.linalg.norm(recon_all, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# === Step 5: PCA\n",
    "n_features = real_all.shape[1]\n",
    "pca = PCA(n_components=min(n_features, 7))\n",
    "pca_real = pca.fit_transform(real_all)\n",
    "pca_recon = pca.transform(recon_all)\n",
    "\n",
    "# === Step 6: Shared UMAP projection\n",
    "combined = np.vstack([pca_real, pca_recon])\n",
    "umap = UMAP(n_neighbors=30, min_dist=0.4, metric='cosine', random_state=42, init=\"spectral\")\n",
    "combined_umap = umap.fit_transform(combined)\n",
    "real_umap = combined_umap[:len(pca_real)]\n",
    "recon_umap = combined_umap[len(pca_real):]\n",
    "\n",
    "# === Step 7: Plot\n",
    "mpl.rcParams.update({\n",
    "    \"font.size\": 12,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 13,\n",
    "    \"legend.fontsize\": 11\n",
    "})\n",
    "\n",
    "dosages = sorted(set(real_labels))\n",
    "color_map = plt.get_cmap('tab10')\n",
    "color_dict = {d: color_map(i % 10) for i, d in enumerate(dosages)}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6), sharex=True, sharey=True)\n",
    "\n",
    "# === Plot real embeddings\n",
    "for d in dosages:\n",
    "    idxs = [i for i, l in enumerate(real_labels) if l == d]\n",
    "    axs[0].scatter(real_umap[idxs, 0], real_umap[idxs, 1],\n",
    "                   label=d, s=15, alpha=0.75, edgecolor='k', linewidth=0.2,\n",
    "                   color=color_dict[d])\n",
    "axs[0].set_title(\"Real Cell Embeddings\", weight='bold')\n",
    "axs[0].set_xlabel(\"UMAP-1\")\n",
    "axs[0].set_ylabel(\"UMAP-2\")\n",
    "\n",
    "# === Plot reconstructed embeddings\n",
    "for d in dosages:\n",
    "    idxs = [i for i, l in enumerate(recon_labels) if l == d]\n",
    "    axs[1].scatter(recon_umap[idxs, 0], recon_umap[idxs, 1],\n",
    "                   label=d, s=15, alpha=0.75, edgecolor='k', linewidth=0.2,\n",
    "                   color=color_dict[d])\n",
    "axs[1].set_title(\"Reconstructed Cell Embeddings\", weight='bold')\n",
    "axs[1].set_xlabel(\"UMAP-1\")\n",
    "\n",
    "# === Shared formatting\n",
    "for ax in axs:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "axs[1].legend(title=\"Dosage\", bbox_to_anchor=(1.05, 1), loc='upper left', markerscale=1.5)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"umap_real_vs_recon.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load recon outputs\n",
    "with open(\"trained_gene_to_cell_model_novirtual_recon_outputs.json\", \"r\") as f:\n",
    "    recon_outputs = json.load(f)\n",
    "\n",
    "# === Step 2: Dosage ID mapping\n",
    "dosage_to_idx = {\n",
    "    \"T1\": 0, \"T2.5\": 1, \"T5\": 2, \"T10\": 3, \"T20\": 4,\n",
    "    \"T40\": 5, \"T80\": 6, \"T160\": 7, \"T320\": 8\n",
    "}\n",
    "idx_to_dosage = {v: k for k, v in dosage_to_idx.items()}\n",
    "\n",
    "# === Step 3: Compute metrics per dosage\n",
    "results = []\n",
    "all_mse, all_cos = [], []\n",
    "\n",
    "for entry in recon_outputs:\n",
    "    dosage = idx_to_dosage.get(entry[\"dosage_idx\"], \"unknown\")\n",
    "    \n",
    "    real = torch.tensor(entry[\"real_cell_embeddings\"], dtype=torch.float).squeeze(0)\n",
    "    recon = torch.tensor(entry[\"reconstructed_cells\"], dtype=torch.float).squeeze(0)\n",
    "    \n",
    "    if real.shape != recon.shape:\n",
    "        print(f\"‚ö†Ô∏è Skipping {dosage} due to shape mismatch: {real.shape} vs {recon.shape}\")\n",
    "        continue\n",
    "\n",
    "    # Mean Squared Error\n",
    "    mse = F.mse_loss(recon, real, reduction='mean').item()\n",
    "\n",
    "    # Cosine Similarity\n",
    "    real_norm = F.normalize(real, dim=-1)\n",
    "    recon_norm = F.normalize(recon, dim=-1)\n",
    "    cosine_sim = F.cosine_similarity(real_norm, recon_norm, dim=-1).mean().item()\n",
    "\n",
    "    results.append({\n",
    "        \"Dosage\": dosage,\n",
    "        \"MSE\": round(mse, 6),\n",
    "        \"CosineSimilarity\": round(cosine_sim, 6)\n",
    "    })\n",
    "\n",
    "    all_mse.append(mse)\n",
    "    all_cos.append(cosine_sim)\n",
    "\n",
    "# === Step 4: Format output\n",
    "df_metrics = pd.DataFrame(results)\n",
    "df_metrics = df_metrics.sort_values(by=\"Dosage\", key=lambda col: [dosage_to_idx.get(d, 999) for d in col])\n",
    "\n",
    "# === Step 5: Add average row\n",
    "average_row = pd.DataFrame([{\n",
    "    \"Dosage\": \"Average\",\n",
    "    \"MSE\": round(sum(all_mse) / len(all_mse), 6),\n",
    "    \"CosineSimilarity\": round(sum(all_cos) / len(all_cos), 6)\n",
    "}])\n",
    "\n",
    "df_metrics = pd.concat([df_metrics, average_row], ignore_index=True)\n",
    "\n",
    "# === Display result\n",
    "print(df_metrics.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "pyg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
