{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import NNConv, global_mean_pool \n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GlobalAttention\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the hetero graph\n",
    "data = torch.load(\"Graph_Results/HeteroGraphs_ScaledFinal/HeteroGraph_T1.pt\", weights_only=False)\n",
    "\n",
    "# Print node types and sizes\n",
    "print(\"Node Types and Features:\")\n",
    "for ntype in data.node_types:\n",
    "    print(f\"  {ntype}: {data[ntype].x.shape}\")\n",
    "\n",
    "# Print edge types and count\n",
    "print(\"\\nEdge Types:\")\n",
    "for etype in data.edge_types:\n",
    "    edge_index = data[etype].edge_index\n",
    "    print(f\"  {etype}: {edge_index.shape[1]} edges\")\n",
    "\n",
    "# Check a few values from cell node features\n",
    "print(\"\\nSample cell node features (first 5 rows):\")\n",
    "print(data[\"cell\"].x[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NodeFeatureEncoders(nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cell_encoder = nn.Sequential(\n",
    "            nn.Linear(7, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),  # üîÅ Replaced BatchNorm1d\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.gene_encoder = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),  # üîÅ Replaced BatchNorm1d\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pathway_encoder = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),  # üîÅ Replaced BatchNorm1d\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, cell_x, gene_x, pathway_x):\n",
    "        h_cell = self.cell_encoder(cell_x)\n",
    "        h_gene = self.gene_encoder(gene_x)\n",
    "        h_pathway = self.pathway_encoder(pathway_x)\n",
    "        return h_cell, h_gene, h_pathway\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import NNConv, global_mean_pool\n",
    "\n",
    "class SharedHierarchicalEncoder_NoAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, lstm_hidden_dim=None, num_dosages=9, num_aux_outputs=1,\n",
    "                 dropout=0.1, use_virtual_node=True):\n",
    "        super().__init__()\n",
    "        self.use_virtual_node = use_virtual_node\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # === Node encoders\n",
    "        self.node_encoders = NodeFeatureEncoders(hidden_dim)\n",
    "\n",
    "        # === Edge MLPs for NNConv\n",
    "        self.edge_mlp_cell_gene = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        self.edge_mlp_gene_pathway = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Message Passing\n",
    "        self.cell_to_gene_conv = NNConv(hidden_dim, hidden_dim, self.edge_mlp_cell_gene, aggr='mean')\n",
    "        self.gene_to_pathway_conv = NNConv(hidden_dim, hidden_dim, self.edge_mlp_gene_pathway, aggr='mean')\n",
    "\n",
    "        # === Global Mean Pooling (replaces attention)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fuse_global = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Optional auxiliary regression/classification head\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_aux_outputs)\n",
    "        )\n",
    "\n",
    "        # === Virtual Node (Dosage-aware)\n",
    "        if self.use_virtual_node:\n",
    "            lstm_dim = lstm_hidden_dim or hidden_dim\n",
    "            self.dosage_embeddings = nn.Embedding(num_dosages, hidden_dim)\n",
    "            self.virtual_norm = nn.LayerNorm(hidden_dim)\n",
    "            self.dosage_lstm = nn.LSTM(hidden_dim, lstm_dim, batch_first=True)\n",
    "\n",
    "            self.fuse_cell_virtual = nn.Sequential(\n",
    "                nn.Linear(hidden_dim + lstm_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            )\n",
    "            self.fuse_gene_virtual = nn.Sequential(\n",
    "                nn.Linear(hidden_dim + lstm_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            )\n",
    "            self.fuse_pathway_virtual = nn.Sequential(\n",
    "                nn.Linear(hidden_dim + lstm_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            )\n",
    "\n",
    "    def refine_virtuals_with_lstm(self):\n",
    "        raw_dosage_embeddings = self.dosage_embeddings.weight.unsqueeze(0)\n",
    "        lstm_out, _ = self.dosage_lstm(raw_dosage_embeddings)\n",
    "        return self.virtual_norm(lstm_out.squeeze(0))\n",
    "\n",
    "    def forward(self, data, dosage_idx=None):\n",
    "        cell_x = data[\"cell\"].x\n",
    "        gene_x = data[\"gene\"].x\n",
    "        pathway_x = data[\"pathway\"].x\n",
    "\n",
    "        h_cell, h_gene, h_pathway = self.node_encoders(cell_x, gene_x, pathway_x)\n",
    "\n",
    "        if self.use_virtual_node:\n",
    "            refined_dosage_virtuals = self.refine_virtuals_with_lstm()\n",
    "            dosage_virtual = refined_dosage_virtuals[dosage_idx]\n",
    "\n",
    "            cell_batch = data[\"cell\"].batch\n",
    "            gene_batch = data[\"gene\"].batch\n",
    "            pathway_batch = data[\"pathway\"].batch\n",
    "\n",
    "            h_cell = self.fuse_cell_virtual(torch.cat([h_cell, dosage_virtual[cell_batch]], dim=1))\n",
    "            h_gene = self.fuse_gene_virtual(torch.cat([h_gene, dosage_virtual[gene_batch]], dim=1))\n",
    "            h_pathway = self.fuse_pathway_virtual(torch.cat([h_pathway, dosage_virtual[pathway_batch]], dim=1))\n",
    "        else:\n",
    "            dosage_virtual = torch.zeros(h_cell.size(0), self.hidden_dim, device=h_cell.device)\n",
    "\n",
    "        # === Message Passing\n",
    "        h_gene_updated = self.cell_to_gene_conv(\n",
    "            (h_cell, h_gene),\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_index,\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_attr\n",
    "        )\n",
    "        h_pathway_updated = self.gene_to_pathway_conv(\n",
    "            (h_gene_updated, h_pathway),\n",
    "            data[\"gene\", \"involved_in\", \"pathway\"].edge_index,\n",
    "            data[\"gene\", \"involved_in\", \"pathway\"].edge_attr\n",
    "        )\n",
    "\n",
    "        # === Global Mean Pooling (instead of attention)\n",
    "        pooled_pathway = global_mean_pool(h_pathway_updated, data['pathway'].batch)\n",
    "\n",
    "        graph_embedding = self.fuse_global(torch.cat([\n",
    "            pooled_pathway,\n",
    "            dosage_virtual\n",
    "        ], dim=1))\n",
    "\n",
    "        aux_output = self.aux_head(graph_embedding)\n",
    "\n",
    "        # === Normalize\n",
    "        h_cell = F.normalize(h_cell, p=2, dim=-1)\n",
    "        h_gene_updated = F.normalize(h_gene_updated, p=2, dim=-1)\n",
    "        h_pathway_updated = F.normalize(h_pathway_updated, p=2, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"h_cell\": h_cell,\n",
    "            \"h_gene\": h_gene_updated,\n",
    "            \"h_pathway\": h_pathway_updated,\n",
    "            \"dosage_virtual\": dosage_virtual,\n",
    "            \"graph_embedding\": graph_embedding,\n",
    "            \"aux_output\": aux_output.squeeze(),\n",
    "            \"pathway_attention_weights\": None  # <-- explicitly None now\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HierarchicalDecoder_NoAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, dropout=0.1, use_virtual_node=True):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.use_virtual_node = use_virtual_node\n",
    "\n",
    "        # === Pathway ‚Üí Gene decoding\n",
    "        self.decode_to_pathways_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.decode_to_pathways_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Gene reconstruction MLP\n",
    "        self.gene_reconstruction_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Optional dosage conditioning\n",
    "        if self.use_virtual_node:\n",
    "            self.dosage_embedding = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        # === Optional auxiliary head\n",
    "        self.aux_pathway_score_head = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, h_pathway_updated, h_gene_updated, graph_embedding, dosage_virtual=None):\n",
    "        B, N_pathways, H = h_pathway_updated.size()\n",
    "        _, N_genes, _ = h_gene_updated.size()\n",
    "\n",
    "        if self.use_virtual_node and dosage_virtual is not None:\n",
    "            graph_embedding = graph_embedding + self.dosage_embedding(dosage_virtual)\n",
    "\n",
    "        # === Pathway reconstruction\n",
    "        graph_expanded = graph_embedding.unsqueeze(1).expand(-1, N_pathways, -1)\n",
    "        pathway_input = torch.cat([h_pathway_updated, graph_expanded], dim=-1)\n",
    "        pathway_hidden = self.decode_to_pathways_fc(pathway_input)\n",
    "        pathway_recon = self.decode_to_pathways_proj(pathway_hidden)  # [B, N_pathways, H]\n",
    "\n",
    "        # === Gene reconstruction (simple projection)\n",
    "        gene_recon = self.gene_reconstruction_fc(h_gene_updated)      # [B, N_genes, H]\n",
    "        gene_recon = F.normalize(gene_recon, p=2, dim=-1)\n",
    "\n",
    "        # === Pathway auxiliary scores\n",
    "        aux_pathway_scores = self.aux_pathway_score_head(pathway_recon).squeeze(-1)\n",
    "\n",
    "        return {\n",
    "            \"reconstructed_pathways\": pathway_recon,\n",
    "            \"reconstructed_genes\": gene_recon,\n",
    "            \"aux_pathway_scores\": aux_pathway_scores,\n",
    "            \"reconstructed_cells\": None,\n",
    "            \"aux_cell_scores\": None,\n",
    "            \"attention_pathway_to_gene\": None,\n",
    "            \"attention_gene_to_cell\": None\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9fc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def load_all_dosage_graphs_for_batching(graph_dir, pattern_prefix=\"HeteroGraph_T\"):\n",
    "    graphs = []\n",
    "    dosage_keys = []\n",
    "\n",
    "    for fname in os.listdir(graph_dir):\n",
    "        if fname.startswith(pattern_prefix) and fname.endswith(\".pt\"):\n",
    "            dosage_key = fname.replace(\".pt\", \"\").replace(pattern_prefix, \"T\")\n",
    "            path = os.path.join(graph_dir, fname)\n",
    "            data = torch.load(path, weights_only=False)\n",
    "            data.dosage_key = dosage_key  # for reference\n",
    "            dosage_keys.append(dosage_key)\n",
    "            graphs.append(data)\n",
    "\n",
    "    # Sort graphs and dosage keys by numeric dosage (T1, T2.5, ..., T320)\n",
    "    sorted_pairs = sorted(zip(dosage_keys, graphs), key=lambda x: float(x[0].replace(\"T\", \"\")))\n",
    "    sorted_dosage_keys, sorted_graphs = zip(*sorted_pairs)\n",
    "\n",
    "    # Create dosage index mapping\n",
    "    dosage_levels = [float(k.replace(\"T\", \"\")) for k in sorted_dosage_keys]\n",
    "    dosage_to_idx = {\n",
    "        f\"T{int(d) if d.is_integer() else d}\": i for i, d in enumerate(dosage_levels)\n",
    "    }\n",
    "\n",
    "    # Add dosage_idx to each graph\n",
    "    for graph, key in zip(sorted_graphs, sorted_dosage_keys):\n",
    "        graph.dosage_idx = torch.tensor([dosage_to_idx[key]], dtype=torch.long)\n",
    "\n",
    "    return list(sorted_graphs), dosage_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac42c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HierarchicalLoss_NoAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lambda_pathway=1.0,\n",
    "        lambda_gene=1.0,\n",
    "        use_stat_alignment=True,\n",
    "        reduction='mean'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lambda_pathway = lambda_pathway\n",
    "        self.lambda_gene = lambda_gene\n",
    "        self.use_stat_alignment = use_stat_alignment\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        loss_components = {}\n",
    "\n",
    "        # === Pathway reconstruction loss\n",
    "        L_pathway = F.mse_loss(\n",
    "            outputs[\"reconstructed_pathways\"],\n",
    "            targets[\"h_pathway\"],\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "        loss_components[\"pathway_loss\"] = L_pathway\n",
    "\n",
    "        # === Gene reconstruction loss\n",
    "        recon = outputs[\"reconstructed_genes\"]\n",
    "        target = targets[\"h_gene\"]\n",
    "        L_gene = F.mse_loss(recon, target, reduction=self.reduction)\n",
    "\n",
    "        if self.use_stat_alignment:\n",
    "            std_diff = F.mse_loss(recon.std(dim=1), target.std(dim=1), reduction=self.reduction)\n",
    "            mean_diff = F.mse_loss(recon.mean(dim=1), target.mean(dim=1), reduction=self.reduction)\n",
    "            L_gene += 0.2 * (std_diff + mean_diff)\n",
    "\n",
    "        loss_components[\"gene_loss\"] = L_gene\n",
    "\n",
    "        # === Total loss (no attention term)\n",
    "        total = self.lambda_pathway * L_pathway + self.lambda_gene * L_gene\n",
    "        loss_components[\"total_loss\"] = total\n",
    "\n",
    "        return total, loss_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ec44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HierarchicalLoss_NoAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lambda_pathway=1.0,\n",
    "        lambda_gene=1.0,\n",
    "        use_stat_alignment=True,\n",
    "        reduction='mean'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lambda_pathway = lambda_pathway\n",
    "        self.lambda_gene = lambda_gene\n",
    "        self.use_stat_alignment = use_stat_alignment\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        loss_components = {}\n",
    "\n",
    "        # === Pathway reconstruction loss\n",
    "        L_pathway = F.mse_loss(\n",
    "            outputs[\"reconstructed_pathways\"],\n",
    "            targets[\"h_pathway\"],\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "        loss_components[\"pathway_loss\"] = L_pathway\n",
    "\n",
    "        # === Gene reconstruction loss\n",
    "        recon = outputs[\"reconstructed_genes\"]\n",
    "        target = targets[\"h_gene\"]\n",
    "        L_gene = F.mse_loss(recon, target, reduction=self.reduction)\n",
    "\n",
    "        if self.use_stat_alignment:\n",
    "            std_diff = F.mse_loss(recon.std(dim=1), target.std(dim=1), reduction=self.reduction)\n",
    "            mean_diff = F.mse_loss(recon.mean(dim=1), target.mean(dim=1), reduction=self.reduction)\n",
    "            L_gene += 0.2 * (std_diff + mean_diff)\n",
    "\n",
    "        loss_components[\"gene_loss\"] = L_gene\n",
    "\n",
    "        # === Total loss (no attention term)\n",
    "        total = self.lambda_pathway * L_pathway + self.lambda_gene * L_gene\n",
    "        loss_components[\"total_loss\"] = total\n",
    "\n",
    "        return total, loss_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_encoder_decoder_model_no_attention(\n",
    "    encoder, decoder, graphs_list, dosage_to_idx,\n",
    "    optimizer=None,\n",
    "    device='cuda',\n",
    "    epochs=100,\n",
    "    loss_weights=None,\n",
    "    save_path=None,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    patience=30,\n",
    "    min_delta=1e-3,\n",
    "    batch_size=2\n",
    "):\n",
    "    import os\n",
    "    import json\n",
    "    from torch_geometric.loader import DataLoader\n",
    "    from torch_geometric.utils import to_dense_batch\n",
    "    from torch.optim import Adam\n",
    "    from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    loss_kwargs = {k: v for k, v in (loss_weights or {}).items() if k != \"monitored_losses\"}\n",
    "    criterion = HierarchicalLoss_NoAttention(**loss_kwargs).to(device)\n",
    "\n",
    "    monitored_keys = loss_weights.get(\"monitored_losses\", [\"total_loss\"]) if loss_weights else [\"total_loss\"]\n",
    "    best_monitored_loss = {k: float(\"inf\") for k in monitored_keys} if len(monitored_keys) > 1 else float(\"inf\")\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = Adam(\n",
    "            list(encoder.parameters()) + list(decoder.parameters()),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5, verbose=True, min_lr=1e-5)\n",
    "    loader = DataLoader(graphs_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    loss_log = []\n",
    "    best_recon_outputs_log = []  # ‚úÖ Store only the best epoch's outputs\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        epoch_loss_dict = {k: 0.0 for k in [\"pathway_loss\", \"gene_loss\", \"total_loss\"]}\n",
    "        epoch_recon_outputs = []  # ‚úÖ Temp buffer for this epoch\n",
    "\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            encoder_out = encoder(batch, batch.dosage_idx)\n",
    "\n",
    "            h_pathway, _ = to_dense_batch(encoder_out[\"h_pathway\"], batch[\"pathway\"].batch)\n",
    "            h_gene, _ = to_dense_batch(encoder_out[\"h_gene\"], batch[\"gene\"].batch)\n",
    "\n",
    "            decoder_out = decoder(\n",
    "                h_pathway_updated=h_pathway,\n",
    "                h_gene_updated=h_gene,\n",
    "                graph_embedding=encoder_out[\"graph_embedding\"],\n",
    "                dosage_virtual=encoder_out.get(\"dosage_virtual\")\n",
    "            )\n",
    "\n",
    "            targets = {\n",
    "                \"h_pathway\": h_pathway.detach(),\n",
    "                \"h_gene\": h_gene.detach()\n",
    "            }\n",
    "\n",
    "            loss, loss_components = criterion(decoder_out, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            for key in epoch_loss_dict:\n",
    "                epoch_loss_dict[key] += loss_components[key].item()\n",
    "\n",
    "            # ‚úÖ Save current batch reconstruction to temp buffer\n",
    "            epoch_recon_outputs.append({\n",
    "                \"dosage_idx\": int(batch.dosage_idx.item()),\n",
    "                \"real_h_gene\": h_gene.detach().cpu().tolist(),\n",
    "                \"real_h_pathway\": h_pathway.detach().cpu().tolist(),\n",
    "                \"reconstructed_genes\": decoder_out[\"reconstructed_genes\"].detach().cpu().tolist(),\n",
    "                \"reconstructed_pathways\": decoder_out[\"reconstructed_pathways\"].detach().cpu().tolist()\n",
    "            })\n",
    "\n",
    "        # === Epoch summary ===\n",
    "        num_batches = len(loader)\n",
    "        avg_loss_dict = {k: v / num_batches for k, v in epoch_loss_dict.items()}\n",
    "        loss_log.append(avg_loss_dict)\n",
    "        scheduler_loss = avg_loss_dict[\"total_loss\"]\n",
    "        scheduler.step(scheduler_loss)\n",
    "\n",
    "        improvement = False\n",
    "        for k in monitored_keys:\n",
    "            current = avg_loss_dict[k]\n",
    "            if isinstance(best_monitored_loss, dict):\n",
    "                if current < best_monitored_loss[k] - min_delta:\n",
    "                    best_monitored_loss[k] = current\n",
    "                    improvement = True\n",
    "            else:\n",
    "                if current < best_monitored_loss - min_delta:\n",
    "                    best_monitored_loss = current\n",
    "                    improvement = True\n",
    "\n",
    "        graph_norm = encoder_out[\"graph_embedding\"].norm().item()\n",
    "        print(\"Epoch {:03d} | Total: {:.4f} | P: {:.4f}, G: {:.4f} | Graph Norm: {:.4f}\".format(\n",
    "            epoch+1, avg_loss_dict['total_loss'], avg_loss_dict['pathway_loss'],\n",
    "            avg_loss_dict['gene_loss'], graph_norm))\n",
    "\n",
    "        if improvement:\n",
    "            best_epoch = epoch + 1\n",
    "            best_recon_outputs_log = epoch_recon_outputs  # ‚úÖ Keep best\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping at epoch {} after {} stagnant epochs.\".format(epoch+1, patience))\n",
    "            break\n",
    "\n",
    "    # === Save model and logs ===\n",
    "    if save_path:\n",
    "        torch.save({\n",
    "            \"encoder\": encoder.state_dict(),\n",
    "            \"decoder\": decoder.state_dict()\n",
    "        }, save_path)\n",
    "        print(\"Model saved to {}\".format(save_path))\n",
    "\n",
    "        loss_log_path = save_path.replace(\".pth\", \"_loss_log.json\")\n",
    "        with open(loss_log_path, \"w\") as f:\n",
    "            json.dump(loss_log, f, indent=2)\n",
    "        print(\"Loss log saved to {}\".format(loss_log_path))\n",
    "\n",
    "        recon_output_path = save_path.replace(\".pth\", \"_recon_outputs.json\")\n",
    "        with open(recon_output_path, \"w\") as f:\n",
    "            json.dump(best_recon_outputs_log, f, indent=2)  # ‚úÖ Only best epoch\n",
    "        print(\"Best reconstructions saved to {}\".format(recon_output_path))\n",
    "\n",
    "    return encoder, decoder, loss_log, best_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c116b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# === Step 1: Load graphs\n",
    "graph_dir = \"Graph_Results/HeteroGraphs_ScaledFinal\"\n",
    "graphs_list, dosage_to_idx = load_all_dosage_graphs_for_batching(graph_dir)\n",
    "\n",
    "# === Step 2: Instantiate no-attention models\n",
    "hidden_dim = 64\n",
    "encoder = SharedHierarchicalEncoder_NoAttention(hidden_dim=hidden_dim, num_dosages=len(dosage_to_idx))\n",
    "decoder = HierarchicalDecoder_NoAttention(hidden_dim=hidden_dim)\n",
    "\n",
    "# === Step 3: Define loss weights\n",
    "loss_weights = {\n",
    "    \"lambda_pathway\": 2.0,\n",
    "    \"lambda_gene\": 1.0,\n",
    "    \"use_stat_alignment\": True,\n",
    "    \"monitored_losses\": [\"total_loss\"]\n",
    "}\n",
    "\n",
    "# === Step 4: Train\n",
    "trained_encoder, trained_decoder, loss_log, best_epoch = train_encoder_decoder_model_no_attention(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    graphs_list=graphs_list,\n",
    "    dosage_to_idx=dosage_to_idx,\n",
    "    device='cpu',\n",
    "    epochs=60,\n",
    "    save_path=\"trained_model_NoAttention.pth\",\n",
    "    loss_weights=loss_weights,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Best Epoch: {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# === Load dosage map\n",
    "graph_dir = \"Graph_Results/HeteroGraphs_ScaledFinal\"\n",
    "graphs_list, dosage_to_idx = load_all_dosage_graphs_for_batching(graph_dir)\n",
    "\n",
    "# === Instantiate model architectures (same as training)\n",
    "hidden_dim = 64\n",
    "encoder = SharedHierarchicalEncoder_NoAttention(hidden_dim=hidden_dim, num_dosages=len(dosage_to_idx))\n",
    "decoder = HierarchicalDecoder_NoAttention(hidden_dim=hidden_dim)\n",
    "\n",
    "# === Load trained weights\n",
    "checkpoint = torch.load(\"trained_model_NoAttention.pth\", map_location='cpu')\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "decoder.load_state_dict(checkpoint['decoder'])\n",
    "\n",
    "# === Set models to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load JSON output ===\n",
    "with open(\"trained_model_NoAttention_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687750af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trained_model_NoAttention_recon_outputs.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total entries in JSON: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad484fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load saved recon output ===\n",
    "with open(\"trained_model_NoAttention_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "# === Mapping index to dosage label ===\n",
    "idx_to_dosage = {\n",
    "    0: \"T1\", 1: \"T2.5\", 2: \"T5\", 3: \"T10\", 4: \"T20\",\n",
    "    5: \"T40\", 6: \"T80\", 7: \"T160\", 8: \"T320\"\n",
    "}\n",
    "\n",
    "# === Prepare containers ===\n",
    "real_feats = []\n",
    "recon_feats = []\n",
    "labels = []\n",
    "\n",
    "for entry in recon_data:\n",
    "    dosage_name = idx_to_dosage[entry[\"dosage_idx\"]]\n",
    "    \n",
    "    recon_gene = np.array(entry[\"reconstructed_genes\"]).squeeze(0)  # [N_genes, H]\n",
    "    real_gene = np.array(entry[\"real_h_gene\"]).squeeze(0)           # Corrected here ‚úÖ\n",
    "\n",
    "    recon_feats.append(recon_gene)\n",
    "    real_feats.append(real_gene)\n",
    "    labels += [dosage_name] * recon_gene.shape[0]\n",
    "\n",
    "# === Stack features\n",
    "recon_all = np.vstack(recon_feats)\n",
    "real_all = np.vstack(real_feats)\n",
    "\n",
    "# === Run UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=30, min_dist=0.3, metric=\"euclidean\", random_state=42)\n",
    "real_umap = umap_model.fit_transform(real_all)\n",
    "recon_umap = umap_model.fit_transform(recon_all)\n",
    "\n",
    "# === Create DataFrames\n",
    "real_df = pd.DataFrame(real_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "real_df[\"Dosage\"] = labels\n",
    "real_df[\"Type\"] = \"Real\"\n",
    "\n",
    "recon_df = pd.DataFrame(recon_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "recon_df[\"Dosage\"] = labels\n",
    "recon_df[\"Type\"] = \"Reconstructed\"\n",
    "\n",
    "# === Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(data=real_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[0],\n",
    "                s=40, alpha=0.7, palette=\"tab10\")\n",
    "axes[0].set_title(\"UMAP of Real Gene Embeddings (No Attention)\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "sns.scatterplot(data=recon_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[1],\n",
    "                s=40, alpha=0.7, palette=\"tab10\")\n",
    "axes[1].set_title(\"UMAP of Reconstructed Gene Embeddings ( No Attention)\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"UMAP_GENE_NoAttention.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# === Load saved recon output ===\n",
    "with open(\"trained_model_NoAttention_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "# === Mapping index to dosage label ===\n",
    "idx_to_dosage = {\n",
    "    0: \"T1\", 1: \"T2.5\", 2: \"T5\", 3: \"T10\", 4: \"T20\",\n",
    "    5: \"T40\", 6: \"T80\", 7: \"T160\", 8: \"T320\"\n",
    "}\n",
    "\n",
    "# === Compute metrics for each dosage\n",
    "results = []\n",
    "for entry in recon_data:\n",
    "    dosage = idx_to_dosage[entry[\"dosage_idx\"]]\n",
    "    \n",
    "    real = np.array(entry[\"real_h_gene\"]).squeeze(0)            # shape [N, H]\n",
    "    recon = np.array(entry[\"reconstructed_genes\"]).squeeze(0)   # shape [N, H]\n",
    "    \n",
    "    mse = mean_squared_error(real, recon)\n",
    "    cos_sim = cosine_similarity(real, recon).diagonal().mean()  # average across all gene embeddings\n",
    "\n",
    "    results.append({\n",
    "        \"Dosage\": dosage,\n",
    "        \"MSE\": mse,\n",
    "        \"CosineSimilarity\": cos_sim\n",
    "    })\n",
    "\n",
    "# === Convert to DataFrame and print\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load saved recon output ===\n",
    "with open(\"trained_model_NoAttention_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "# === Mapping index to dosage label ===\n",
    "idx_to_dosage = {\n",
    "    0: \"T1\", 1: \"T2.5\", 2: \"T5\", 3: \"T10\", 4: \"T20\",\n",
    "    5: \"T40\", 6: \"T80\", 7: \"T160\", 8: \"T320\"\n",
    "}\n",
    "\n",
    "# === Prepare containers ===\n",
    "real_feats = []\n",
    "recon_feats = []\n",
    "labels = []\n",
    "\n",
    "for entry in recon_data:\n",
    "    dosage_name = idx_to_dosage[entry[\"dosage_idx\"]]\n",
    "    \n",
    "    # shape: [N_pathways, H]\n",
    "    real_pathway = np.array(entry[\"real_h_pathway\"]).squeeze(0)\n",
    "    recon_pathway = np.array(entry[\"reconstructed_pathways\"]).squeeze(0)\n",
    "\n",
    "    real_feats.append(real_pathway)\n",
    "    recon_feats.append(recon_pathway)\n",
    "    labels += [dosage_name] * real_pathway.shape[0]\n",
    "\n",
    "# === Stack features\n",
    "real_all = np.vstack(real_feats)\n",
    "recon_all = np.vstack(recon_feats)\n",
    "\n",
    "# === Run UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.2, metric=\"cosine\", random_state=42)\n",
    "real_umap = umap_model.fit_transform(real_all)\n",
    "recon_umap = umap_model.fit_transform(recon_all)\n",
    "\n",
    "# === Create DataFrames\n",
    "real_df = pd.DataFrame(real_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "real_df[\"Dosage\"] = labels\n",
    "real_df[\"Type\"] = \"Real\"\n",
    "\n",
    "recon_df = pd.DataFrame(recon_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "recon_df[\"Dosage\"] = labels\n",
    "recon_df[\"Type\"] = \"Reconstructed\"\n",
    "\n",
    "# === Plot side-by-side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(data=real_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[0],\n",
    "                s=40, alpha=0.8, palette=\"tab10\")\n",
    "axes[0].set_title(\"UMAP of Real Pathway Embeddings\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "sns.scatterplot(data=recon_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[1],\n",
    "                s=40, alpha=0.8, palette=\"tab10\")\n",
    "axes[1].set_title(\"UMAP of Reconstructed Pathway Embeddings\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"UMAP_PATHWAY_NoAttention.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b567ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# === Load reconstruction outputs\n",
    "with open(\"trained_model_NoAttention_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "# === Dosage index mapping\n",
    "idx_to_dosage = {\n",
    "    0: \"T1\", 1: \"T2.5\", 2: \"T5\", 3: \"T10\", 4: \"T20\",\n",
    "    5: \"T40\", 6: \"T80\", 7: \"T160\", 8: \"T320\"\n",
    "}\n",
    "\n",
    "# === Store results\n",
    "metrics = []\n",
    "\n",
    "for entry in recon_data:\n",
    "    dosage_label = idx_to_dosage[entry[\"dosage_idx\"]]\n",
    "    real = np.array(entry[\"real_h_pathway\"]).squeeze(0)\n",
    "    recon = np.array(entry[\"reconstructed_pathways\"]).squeeze(0)\n",
    "\n",
    "    mse = mean_squared_error(real.flatten(), recon.flatten())\n",
    "    cosine_sim = np.mean(np.diag(cosine_similarity(real, recon)))\n",
    "\n",
    "    metrics.append([dosage_label, mse, cosine_sim])\n",
    "\n",
    "# === Create DataFrame\n",
    "df = pd.DataFrame(metrics, columns=[\"Dosage\", \"MSE\", \"CosineSimilarity\"])\n",
    "\n",
    "# === Sort by dosage numerically\n",
    "df[\"Dosage_num\"] = df[\"Dosage\"].str.replace(\"T\", \"\").astype(float)\n",
    "df = df.sort_values(\"Dosage_num\").drop(columns=[\"Dosage_num\"])\n",
    "\n",
    "# === Format and print\n",
    "df[\"MSE\"] = df[\"MSE\"].round(6)\n",
    "df[\"CosineSimilarity\"] = df[\"CosineSimilarity\"].round(6)\n",
    "\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628f930",
   "metadata": {},
   "source": [
    "## NO LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbedd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NodeFeatureEncoders(nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cell_encoder = nn.Sequential(\n",
    "            nn.Linear(7, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),  # üîÅ Replaced BatchNorm1d\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.gene_encoder = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),  # üîÅ Replaced BatchNorm1d\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pathway_encoder = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),  # üîÅ Replaced BatchNorm1d\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, cell_x, gene_x, pathway_x):\n",
    "        h_cell = self.cell_encoder(cell_x)\n",
    "        h_gene = self.gene_encoder(gene_x)\n",
    "        h_pathway = self.pathway_encoder(pathway_x)\n",
    "        return h_cell, h_gene, h_pathway\n",
    "        \n",
    "from torch_geometric.nn import GlobalAttention\n",
    "\n",
    "class GlobalAttentionWithWeights(GlobalAttention):\n",
    "    def forward(self, x, index, ptr=None, dim_size=None, dim=0):\n",
    "        \"\"\"\n",
    "        x: Node embeddings\n",
    "        index: Index tensor (typically the batch vector)\n",
    "        \"\"\"\n",
    "        gate = self.gate_nn(x).squeeze(-1)      # [N]\n",
    "        gate = torch.sigmoid(gate)              # attention weights\n",
    "        x_weighted = x * gate.unsqueeze(-1)     # [N, F]\n",
    "\n",
    "        # Perform aggregation (mean by default)\n",
    "        out = torch.zeros(dim_size or int(index.max()) + 1, x.size(-1), device=x.device)\n",
    "        out = out.index_add(dim, index, x_weighted)\n",
    "\n",
    "        return out, gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a9d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedHierarchicalEncoder_NoLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_dosages=9, num_aux_outputs=1,\n",
    "                 dropout=0.1, use_virtual_node=True):\n",
    "        super().__init__()\n",
    "        self.use_virtual_node = use_virtual_node\n",
    "        self.hidden_dim = hidden_dim             \n",
    "\n",
    "        self.node_encoders = NodeFeatureEncoders(hidden_dim)\n",
    "\n",
    "        self.edge_mlp_cell_gene = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        self.edge_mlp_gene_pathway = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.cell_to_gene_conv = NNConv(hidden_dim, hidden_dim, self.edge_mlp_cell_gene, aggr='mean')\n",
    "        self.gene_to_pathway_conv = NNConv(hidden_dim, hidden_dim, self.edge_mlp_gene_pathway, aggr='mean')\n",
    "\n",
    "        self.att_pool = GlobalAttentionWithWeights(gate_nn=nn.Linear(hidden_dim, 1))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fuse_global = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_aux_outputs)\n",
    "        )\n",
    "\n",
    "        if self.use_virtual_node:\n",
    "            self.dosage_embeddings = nn.Embedding(num_dosages, hidden_dim)\n",
    "            self.virtual_norm = nn.LayerNorm(hidden_dim)\n",
    "            self.fuse_cell_virtual = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            )\n",
    "            self.fuse_gene_virtual = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            )\n",
    "            self.fuse_pathway_virtual = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.LayerNorm(hidden_dim)\n",
    "            )\n",
    "\n",
    "    def forward(self, data, dosage_idx=None):\n",
    "        cell_x = data[\"cell\"].x\n",
    "        gene_x = data[\"gene\"].x\n",
    "        pathway_x = data[\"pathway\"].x\n",
    "\n",
    "        h_cell, h_gene, h_pathway = self.node_encoders(cell_x, gene_x, pathway_x)\n",
    "\n",
    "        if self.use_virtual_node:\n",
    "            dosage_virtual = self.virtual_norm(self.dosage_embeddings(dosage_idx))  # [B, H]\n",
    "            cell_batch = data[\"cell\"].batch\n",
    "            gene_batch = data[\"gene\"].batch\n",
    "            pathway_batch = data[\"pathway\"].batch\n",
    "\n",
    "            h_cell = self.fuse_cell_virtual(torch.cat([\n",
    "                h_cell, dosage_virtual[cell_batch]\n",
    "            ], dim=1))\n",
    "            h_gene = self.fuse_gene_virtual(torch.cat([\n",
    "                h_gene, dosage_virtual[gene_batch]\n",
    "            ], dim=1))\n",
    "            h_pathway = self.fuse_pathway_virtual(torch.cat([\n",
    "                h_pathway, dosage_virtual[pathway_batch]\n",
    "            ], dim=1))\n",
    "        else:\n",
    "            dosage_virtual = torch.zeros(h_cell.size(0), self.hidden_dim, device=h_cell.device)\n",
    "\n",
    "        h_gene_updated = self.cell_to_gene_conv(\n",
    "            (h_cell, h_gene),\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_index,\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_attr\n",
    "        )\n",
    "        h_pathway_updated = self.gene_to_pathway_conv(\n",
    "            (h_gene_updated, h_pathway),\n",
    "            data[\"gene\", \"involved_in\", \"pathway\"].edge_index,\n",
    "            data[\"gene\", \"involved_in\", \"pathway\"].edge_attr\n",
    "        )\n",
    "\n",
    "        pooled_pathway, pathway_attention_weights = self.att_pool(\n",
    "            h_pathway_updated, data[\"pathway\"].batch\n",
    "        )\n",
    "\n",
    "        graph_embedding = self.fuse_global(torch.cat([\n",
    "            pooled_pathway, dosage_virtual\n",
    "        ], dim=1))\n",
    "        aux_output = self.aux_head(graph_embedding)\n",
    "\n",
    "        h_cell = F.normalize(h_cell, p=2, dim=-1)\n",
    "        h_gene_updated = F.normalize(h_gene_updated, p=2, dim=-1)\n",
    "        h_pathway_updated = F.normalize(h_pathway_updated, p=2, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"h_cell\": h_cell,\n",
    "            \"h_gene\": h_gene_updated,\n",
    "            \"h_pathway\": h_pathway_updated,\n",
    "            \"dosage_virtual\": dosage_virtual,\n",
    "            \"graph_embedding\": graph_embedding,\n",
    "            \"aux_output\": aux_output.squeeze(),\n",
    "            \"pathway_attention_weights\": pathway_attention_weights\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d05fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HierarchicalDecoder_NoLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_heads=2, dropout=0.1, use_virtual_node=True):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.use_virtual_node = use_virtual_node\n",
    "\n",
    "        # === Pathway seed projection (unused unless you add seed later)\n",
    "        self.pathway_seed_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        # === Gene projection head before query\n",
    "        self.gene_proj_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Query projection for attention\n",
    "        self.gene_query_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Pathway reconstruction MLP\n",
    "        self.decode_to_pathways_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.decode_to_pathways_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Multi-head attention from pathway ‚Üí gene (store attn weights)\n",
    "        self.pathway_to_gene_attn = nn.MultiheadAttention(\n",
    "            hidden_dim, num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "\n",
    "        # === Optional dosage embedding\n",
    "        if self.use_virtual_node:\n",
    "            self.dosage_embedding = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        # === Auxiliary scoring head for interpretability\n",
    "        self.aux_pathway_score_head = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, h_pathway_updated, h_gene_updated, graph_embedding, dosage_virtual=None):\n",
    "        B, N_pathways, H = h_pathway_updated.size()\n",
    "        _, N_genes, _ = h_gene_updated.size()\n",
    "\n",
    "        # === Add virtual dosage node (if applicable)\n",
    "        if self.use_virtual_node and dosage_virtual is not None:\n",
    "            graph_embedding = graph_embedding + self.dosage_embedding(dosage_virtual)\n",
    "\n",
    "        # === Pathway reconstruction\n",
    "        graph_expanded = graph_embedding.unsqueeze(1).expand(-1, N_pathways, -1)\n",
    "        pathway_input = torch.cat([h_pathway_updated, graph_expanded], dim=-1)\n",
    "        pathway_hidden = self.decode_to_pathways_fc(pathway_input)\n",
    "        pathway_recon = self.decode_to_pathways_proj(pathway_hidden)  # [B, N_pathways, H]\n",
    "\n",
    "        # === Gene projection and attention-based reconstruction\n",
    "        h_gene_projected = self.gene_proj_head(h_gene_updated)\n",
    "        gene_query = self.gene_query_proj(h_gene_projected)\n",
    "\n",
    "        gene_recon, attn_p2g = self.pathway_to_gene_attn(\n",
    "            query=gene_query,\n",
    "            key=pathway_recon,\n",
    "            value=pathway_recon,\n",
    "            key_padding_mask=None,\n",
    "            need_weights=True\n",
    "        )\n",
    "\n",
    "        # Residual + dropout\n",
    "        gene_recon = F.dropout(gene_recon, p=0.1, training=self.training) + gene_query\n",
    "\n",
    "        # === New: L2 Normalize reconstructed gene embeddings\n",
    "        gene_recon = F.normalize(gene_recon, p=2, dim=-1)\n",
    "\n",
    "        # === Optional auxiliary output\n",
    "        aux_pathway_scores = self.aux_pathway_score_head(pathway_recon).squeeze(-1)\n",
    "\n",
    "        return {\n",
    "            \"reconstructed_pathways\": pathway_recon,\n",
    "            \"reconstructed_genes\": gene_recon,\n",
    "            \"aux_pathway_scores\": aux_pathway_scores,\n",
    "            \"attention_pathway_to_gene\": attn_p2g  # shape [B, num_heads, N_genes, N_pathways]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e698d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class HierarchicalLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lambda_pathway=1.0,\n",
    "        lambda_gene=1.0,\n",
    "        lambda_attention=0.2,\n",
    "        use_stat_alignment=True,\n",
    "        reduction='mean'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lambda_pathway = lambda_pathway\n",
    "        self.lambda_gene = lambda_gene\n",
    "        self.lambda_attention = lambda_attention\n",
    "        self.use_stat_alignment = use_stat_alignment\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        loss_components = {}\n",
    "\n",
    "        # Pathway reconstruction loss\n",
    "        L_pathway = F.mse_loss(\n",
    "            outputs[\"reconstructed_pathways\"],\n",
    "            targets[\"h_pathway\"],\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "        loss_components[\"pathway_loss\"] = L_pathway\n",
    "\n",
    "        # Gene reconstruction loss\n",
    "        recon = outputs[\"reconstructed_genes\"]\n",
    "        target = targets[\"h_gene\"]\n",
    "        L_gene = F.mse_loss(recon, target, reduction=self.reduction)\n",
    "\n",
    "        if self.use_stat_alignment:\n",
    "            std_diff = F.mse_loss(recon.std(dim=1), target.std(dim=1), reduction=self.reduction)\n",
    "            mean_diff = F.mse_loss(recon.mean(dim=1), target.mean(dim=1), reduction=self.reduction)\n",
    "            L_gene += 0.2 * (std_diff + mean_diff)\n",
    "\n",
    "        loss_components[\"gene_loss\"] = L_gene\n",
    "\n",
    "        # Attention regularization\n",
    "        attn = outputs.get(\"attention_pathway_to_gene\", None)\n",
    "        if attn is not None:\n",
    "            if attn.dim() == 4:\n",
    "                entropy = -(attn * torch.log(attn + 1e-8)).sum(dim=-1).mean()\n",
    "            elif attn.dim() == 3:\n",
    "                entropy = -(attn * torch.log(attn + 1e-8)).sum(dim=-1).mean()\n",
    "            else:\n",
    "                entropy = torch.tensor(0.0, device=attn.device)\n",
    "        else:\n",
    "            entropy = torch.tensor(0.0, device=recon.device)\n",
    "\n",
    "        loss_components[\"attention_reg_loss\"] = entropy\n",
    "\n",
    "        total = (\n",
    "            self.lambda_pathway * L_pathway +\n",
    "            self.lambda_gene * L_gene +\n",
    "            self.lambda_attention * entropy\n",
    "        )\n",
    "        loss_components[\"total_loss\"] = total\n",
    "\n",
    "        return total, loss_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def train_encoder_decoder_model(\n",
    "    encoder, decoder, graphs_list, dosage_to_idx,\n",
    "    optimizer=None,\n",
    "    device='cuda',\n",
    "    epochs=100,\n",
    "    loss_weights=None,\n",
    "    save_path=None,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    patience=30,\n",
    "    min_delta=1e-3,\n",
    "    batch_size=2\n",
    "):\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    loss_kwargs = {k: v for k, v in (loss_weights or {}).items() if k not in [\"log_grad_norm\", \"monitored_losses\"]}\n",
    "    criterion = HierarchicalLoss(**loss_kwargs).to(device)\n",
    "\n",
    "    monitored_keys = loss_weights.get(\"monitored_losses\", [\"total_loss\"]) if loss_weights else [\"total_loss\"]\n",
    "    best_monitored_loss = {k: float(\"inf\") for k in monitored_keys} if len(monitored_keys) > 1 else float(\"inf\")\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = Adam(\n",
    "            list(encoder.parameters()) + list(decoder.parameters()),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5, verbose=True, min_lr=1e-5)\n",
    "    loader = DataLoader(graphs_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    best_recon_outputs = None\n",
    "    best_attention_entropy = None\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        epoch_loss_dict = {k: 0.0 for k in [\"pathway_loss\", \"gene_loss\", \"attention_reg_loss\", \"total_loss\"]}\n",
    "        epoch_attn_entropy = []\n",
    "        epoch_recon_outputs = []\n",
    "\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            encoder_out = encoder(batch, batch.dosage_idx)\n",
    "            h_pathway, _ = to_dense_batch(encoder_out[\"h_pathway\"], batch[\"pathway\"].batch)\n",
    "            h_gene, _ = to_dense_batch(encoder_out[\"h_gene\"], batch[\"gene\"].batch)\n",
    "\n",
    "            decoder_out = decoder(\n",
    "                h_pathway_updated=h_pathway,\n",
    "                h_gene_updated=h_gene,\n",
    "                graph_embedding=encoder_out[\"graph_embedding\"],\n",
    "                dosage_virtual=encoder_out.get(\"dosage_virtual\")\n",
    "            )\n",
    "\n",
    "            targets = {\n",
    "                \"h_pathway\": h_pathway.detach(),\n",
    "                \"h_gene\": h_gene.detach()\n",
    "            }\n",
    "\n",
    "            loss, loss_components = criterion(decoder_out, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            for key in epoch_loss_dict:\n",
    "                epoch_loss_dict[key] += loss_components[key].item()\n",
    "\n",
    "            # Save reconstruction for best epoch only\n",
    "            epoch_recon_outputs.append({\n",
    "                \"dosage_idx\": int(batch.dosage_idx.item()),\n",
    "                \"attention\": decoder_out.get(\"attention_pathway_to_gene\", None).detach().cpu().tolist()\n",
    "                    if decoder_out.get(\"attention_pathway_to_gene\") is not None else None,\n",
    "                \"reconstructed_pathways\": decoder_out[\"reconstructed_pathways\"].detach().cpu().tolist(),\n",
    "                \"reconstructed_genes\": decoder_out[\"reconstructed_genes\"].detach().cpu().tolist(),\n",
    "                \"real_h_gene\": h_gene.detach().cpu().tolist(),         # ‚úÖ Added for UMAP/cosine similarity\n",
    "                \"real_h_pathway\": h_pathway.detach().cpu().tolist()    # ‚úÖ Added for future pathway analysis\n",
    "            })\n",
    "\n",
    "            # Track attention entropy\n",
    "            attn = decoder_out.get(\"attention_pathway_to_gene\", None)\n",
    "            if attn is not None:\n",
    "                entropy = (-attn * torch.log(attn + 1e-6)).sum(dim=-1)\n",
    "                entropy = entropy.mean(dim=-1).mean(dim=0)\n",
    "                epoch_attn_entropy.append(entropy.detach().cpu())\n",
    "\n",
    "        num_batches = len(loader)\n",
    "        avg_loss_dict = {k: v / num_batches for k, v in epoch_loss_dict.items()}\n",
    "\n",
    "        scheduler_loss = avg_loss_dict[\"total_loss\"]\n",
    "        scheduler.step(scheduler_loss)\n",
    "\n",
    "        improvement = False\n",
    "        for k in monitored_keys:\n",
    "            current = avg_loss_dict[k]\n",
    "            if isinstance(best_monitored_loss, dict):\n",
    "                if current < best_monitored_loss[k] - min_delta:\n",
    "                    best_monitored_loss[k] = current\n",
    "                    improvement = True\n",
    "            else:\n",
    "                if current < best_monitored_loss - min_delta:\n",
    "                    best_monitored_loss = current\n",
    "                    improvement = True\n",
    "\n",
    "        graph_norm = encoder_out[\"graph_embedding\"].norm().item()\n",
    "        print(\"Epoch {:03d} | Total: {:.4f} | P: {:.4f}, G: {:.4f}, A: {:.4f} | Graph Norm: {:.4f}\".format(\n",
    "            epoch+1, avg_loss_dict['total_loss'], avg_loss_dict['pathway_loss'],\n",
    "            avg_loss_dict['gene_loss'], avg_loss_dict['attention_reg_loss'], graph_norm))\n",
    "\n",
    "        if improvement:\n",
    "            best_epoch = epoch + 1\n",
    "            epochs_no_improve = 0\n",
    "            best_recon_outputs = epoch_recon_outputs\n",
    "            best_attention_entropy = torch.stack(epoch_attn_entropy).mean(dim=0).tolist() if epoch_attn_entropy else None\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping at epoch {} after {} stagnant epochs.\".format(epoch+1, patience))\n",
    "            break\n",
    "\n",
    "    # Save final model\n",
    "    if save_path:\n",
    "        torch.save({\n",
    "            \"encoder\": encoder.state_dict(),\n",
    "            \"decoder\": decoder.state_dict()\n",
    "        }, save_path)\n",
    "        print(\"‚úÖ Model saved to:\", save_path)\n",
    "\n",
    "        if best_recon_outputs:\n",
    "            recon_output_path = save_path.replace(\".pth\", \"_recon_outputs.json\")\n",
    "            with open(recon_output_path, \"w\") as f:\n",
    "                json.dump(best_recon_outputs, f, indent=2)\n",
    "            print(\"üß† Best epoch reconstruction saved to:\", recon_output_path)\n",
    "\n",
    "        if best_attention_entropy:\n",
    "            attn_log_path = save_path.replace(\".pth\", \"_attn_entropy.json\")\n",
    "            with open(attn_log_path, \"w\") as f:\n",
    "                json.dump(best_attention_entropy, f, indent=2)\n",
    "            print(\"üìä Best attention entropy saved to:\", attn_log_path)\n",
    "\n",
    "    return encoder, decoder, best_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# === Step 1: Load graphs\n",
    "graph_dir = \"Graph_Results/HeteroGraphs_ScaledFinal\"\n",
    "graphs_list, dosage_to_idx = load_all_dosage_graphs_for_batching(graph_dir)\n",
    "\n",
    "# === Step 2: Instantiate encoder and decoder (LSTM removed, attention retained)\n",
    "hidden_dim = 64\n",
    "encoder = SharedHierarchicalEncoder_NoLSTM(hidden_dim=hidden_dim, num_dosages=len(dosage_to_idx))\n",
    "decoder = HierarchicalDecoder_NoLSTM(hidden_dim=hidden_dim)  # ‚úÖ LSTM-free decoder\n",
    "\n",
    "# === Step 3: Define loss weights\n",
    "loss_weights = {\n",
    "    \"lambda_pathway\": 2.0,\n",
    "    \"lambda_gene\": 1.0,\n",
    "    \"lambda_attention\": 0.2,           # ‚úÖ Attention regularization\n",
    "    \"use_stat_alignment\": True,\n",
    "    \"log_grad_norm\": True,\n",
    "    \"monitored_losses\": [\"total_loss\"]\n",
    "}\n",
    "\n",
    "# === Step 4: Train and retain only best epoch's reconstructions\n",
    "trained_encoder, trained_decoder, best_epoch = train_encoder_decoder_model(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    graphs_list=graphs_list,\n",
    "    dosage_to_idx=dosage_to_idx,\n",
    "    device='cpu',                                \n",
    "    epochs=30,\n",
    "    save_path=\"trained_model_nolstm.pth\",        # ‚úÖ Save path reflects model variant\n",
    "    loss_weights=loss_weights,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Best Epoch (LSTM-free): {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703cae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# === Step 1: Load graphs and dosage map\n",
    "graph_dir = \"Graph_Results/HeteroGraphs_ScaledFinal\"\n",
    "graphs_list, dosage_to_idx = load_all_dosage_graphs_for_batching(graph_dir)\n",
    "\n",
    "# === Step 2: Instantiate model architectures (LSTM-free, attention-enabled)\n",
    "hidden_dim = 64\n",
    "encoder = SharedHierarchicalEncoder_NoLSTM(hidden_dim=hidden_dim, num_dosages=len(dosage_to_idx))\n",
    "decoder = HierarchicalDecoder_NoLSTM(hidden_dim=hidden_dim)\n",
    "\n",
    "# === Step 3: Load trained weights\n",
    "checkpoint_path = \"trained_model_nolstm.pth\"  # ‚úÖ Make sure path matches your training save\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')  # or 'cuda' if using GPU\n",
    "\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "decoder.load_state_dict(checkpoint['decoder'])\n",
    "\n",
    "# === Step 4: Set to evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# === Step 5 (optional): Move to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "print(\"‚úÖ Model successfully loaded and ready for inference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee007ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load JSON output from LSTM-free attention-enabled model ===\n",
    "with open(\"trained_model_nolstm_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "print(f\"Total entries in JSON: {len(recon_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90019bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load saved recon output from LSTM-free attention model ===\n",
    "with open(\"trained_model_nolstm_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "# === Mapping index to dosage label ===\n",
    "idx_to_dosage = {\n",
    "    0: \"T1\", 1: \"T2.5\", 2: \"T5\", 3: \"T10\", 4: \"T20\",\n",
    "    5: \"T40\", 6: \"T80\", 7: \"T160\", 8: \"T320\"\n",
    "}\n",
    "\n",
    "# === Prepare containers\n",
    "real_feats = []\n",
    "recon_feats = []\n",
    "labels = []\n",
    "\n",
    "for entry in recon_data:\n",
    "    dosage_name = idx_to_dosage[entry[\"dosage_idx\"]]\n",
    "\n",
    "    recon_gene = np.array(entry[\"reconstructed_genes\"]).squeeze(0)   # [N_genes, H]\n",
    "    real_gene = np.array(entry[\"real_h_gene\"]).squeeze(0)           # [N_genes, H]\n",
    "\n",
    "    recon_feats.append(recon_gene)\n",
    "    real_feats.append(real_gene)\n",
    "    labels += [dosage_name] * recon_gene.shape[0]\n",
    "\n",
    "# === Stack features\n",
    "recon_all = np.vstack(recon_feats)\n",
    "real_all = np.vstack(real_feats)\n",
    "\n",
    "# === Run UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=30, min_dist=0.3, metric=\"euclidean\", random_state=42)\n",
    "real_umap = umap_model.fit_transform(real_all)\n",
    "recon_umap = umap_model.fit_transform(recon_all)\n",
    "\n",
    "# === Create DataFrames\n",
    "real_df = pd.DataFrame(real_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "real_df[\"Dosage\"] = labels\n",
    "real_df[\"Type\"] = \"Real\"\n",
    "\n",
    "recon_df = pd.DataFrame(recon_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "recon_df[\"Dosage\"] = labels\n",
    "recon_df[\"Type\"] = \"Reconstructed\"\n",
    "\n",
    "# === Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(data=real_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[0],\n",
    "                s=40, alpha=0.7, palette=\"tab10\")\n",
    "axes[0].set_title(\"UMAP of Real Gene Embeddings (No LSTM)\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "sns.scatterplot(data=recon_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[1],\n",
    "                s=40, alpha=0.7, palette=\"tab10\")\n",
    "axes[1].set_title(\"UMAP of Reconstructed Gene Embeddings (No LSTM )\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"UMAP_GENE_nolstm_attention.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e978d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# === Load reconstructions ===\n",
    "with open(\"trained_model_nolstm_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "# === Index to dosage mapping ===\n",
    "idx_to_dosage = {\n",
    "    0: \"T1\", 1: \"T2.5\", 2: \"T5\", 3: \"T10\", 4: \"T20\",\n",
    "    5: \"T40\", 6: \"T80\", 7: \"T160\", 8: \"T320\"\n",
    "}\n",
    "\n",
    "# === Collect metrics\n",
    "metrics = []\n",
    "\n",
    "for entry in recon_data:\n",
    "    dosage = idx_to_dosage[entry[\"dosage_idx\"]]\n",
    "\n",
    "    real_gene = np.array(entry[\"real_h_gene\"]).squeeze(0)\n",
    "    recon_gene = np.array(entry[\"reconstructed_genes\"]).squeeze(0)\n",
    "\n",
    "    cos_sim = np.mean([\n",
    "        cosine_similarity(real_gene[i].reshape(1, -1), recon_gene[i].reshape(1, -1))[0, 0]\n",
    "        for i in range(real_gene.shape[0])\n",
    "    ])\n",
    "    mse = mean_squared_error(real_gene, recon_gene)\n",
    "\n",
    "    metrics.append({\n",
    "        \"Dosage\": dosage,\n",
    "        \"CosineSimilarity\": cos_sim,\n",
    "        \"MSE\": mse\n",
    "    })\n",
    "\n",
    "# === Aggregate by dosage\n",
    "df = pd.DataFrame(metrics)\n",
    "df_summary = df.groupby(\"Dosage\").mean().reset_index()\n",
    "\n",
    "# === Optional: sort dosages in order\n",
    "dosage_order = [\"T1\", \"T2.5\", \"T5\", \"T10\", \"T20\", \"T40\", \"T80\", \"T160\", \"T320\"]\n",
    "df_summary[\"Dosage\"] = pd.Categorical(df_summary[\"Dosage\"], categories=dosage_order, ordered=True)\n",
    "df_summary = df_summary.sort_values(\"Dosage\")\n",
    "\n",
    "# === Print the result\n",
    "print(\"\\nüìä Per-Dosage Gene Reconstruction Metrics:\")\n",
    "print(df_summary.to_string(index=False, float_format=\"%.6f\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load JSON outputs ===\n",
    "with open(\"trained_model_nolstm_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "# === Dosage map\n",
    "idx_to_dosage = {\n",
    "    0: \"T1\", 1: \"T2.5\", 2: \"T5\", 3: \"T10\", 4: \"T20\",\n",
    "    5: \"T40\", 6: \"T80\", 7: \"T160\", 8: \"T320\"\n",
    "}\n",
    "\n",
    "# === Containers\n",
    "real_feats = []\n",
    "recon_feats = []\n",
    "labels = []\n",
    "\n",
    "# === Extract pathway embeddings across all entries\n",
    "for entry in recon_data:\n",
    "    dosage = idx_to_dosage[entry[\"dosage_idx\"]]\n",
    "\n",
    "    real_pw = np.array(entry[\"real_h_pathway\"]).squeeze(0)             # [N_pathways, H]\n",
    "    recon_pw = np.array(entry[\"reconstructed_pathways\"]).squeeze(0)   # [N_pathways, H]\n",
    "\n",
    "    real_feats.append(real_pw)\n",
    "    recon_feats.append(recon_pw)\n",
    "    labels += [dosage] * real_pw.shape[0]\n",
    "\n",
    "# === Stack\n",
    "real_all = np.vstack(real_feats)\n",
    "recon_all = np.vstack(recon_feats)\n",
    "\n",
    "# === UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, metric=\"cosine\", random_state=42)\n",
    "real_umap = umap_model.fit_transform(real_all)\n",
    "recon_umap = umap_model.fit_transform(recon_all)\n",
    "\n",
    "# === Create DataFrames\n",
    "real_df = pd.DataFrame(real_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "real_df[\"Dosage\"] = labels\n",
    "real_df[\"Type\"] = \"Real\"\n",
    "\n",
    "recon_df = pd.DataFrame(recon_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "recon_df[\"Dosage\"] = labels\n",
    "recon_df[\"Type\"] = \"Reconstructed\"\n",
    "\n",
    "# === Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(data=real_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[0],\n",
    "                s=40, alpha=0.7, palette=\"tab10\")\n",
    "axes[0].set_title(\"UMAP of Real Pathway Embeddings (No LSTM)\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "sns.scatterplot(data=recon_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[1],\n",
    "                s=40, alpha=0.7, palette=\"tab10\")\n",
    "axes[1].set_title(\"UMAP of Reconstructed Pathway Embeddings (No LSTM )\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"UMAP_PATHWAY_nolstm_attention.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a562c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === Convert labels to numpy array\n",
    "labels = np.array(labels)\n",
    "\n",
    "# === Unique dosages\n",
    "dosages = sorted(set(labels), key=lambda x: float(x[1:]) if 'T' in x else x)\n",
    "\n",
    "# === Containers\n",
    "mse_per_dosage = []\n",
    "cosine_per_dosage = []\n",
    "\n",
    "# === Per-dosage evaluation\n",
    "for d in dosages:\n",
    "    idxs = labels == d\n",
    "    real_d = real_all[idxs]\n",
    "    recon_d = recon_all[idxs]\n",
    "\n",
    "    mse = mean_squared_error(real_d, recon_d)\n",
    "    cos_sim = np.mean(np.diag(cosine_similarity(real_d, recon_d)))\n",
    "\n",
    "    mse_per_dosage.append(mse)\n",
    "    cosine_per_dosage.append(cos_sim)\n",
    "\n",
    "# === Overall evaluation\n",
    "overall_mse = mean_squared_error(real_all, recon_all)\n",
    "overall_cosine = np.mean(np.diag(cosine_similarity(real_all, recon_all)))\n",
    "\n",
    "# === Create DataFrame\n",
    "df_eval = pd.DataFrame({\n",
    "    \"Dosage\": dosages,\n",
    "    \"MSE\": mse_per_dosage,\n",
    "    \"CosineSimilarity\": cosine_per_dosage\n",
    "})\n",
    "\n",
    "# Append overall\n",
    "df_eval.loc[len(df_eval)] = [\"Overall\", overall_mse, overall_cosine]\n",
    "\n",
    "# === Display\n",
    "print(df_eval.round(6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfbf1e9",
   "metadata": {},
   "source": [
    "## No Virtual Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cac730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "\n",
    "class SharedHierarchicalEncoder_NoVirtual(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_aux_outputs=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim             \n",
    "\n",
    "        # === Node encoders (external class expected)\n",
    "        self.node_encoders = NodeFeatureEncoders(hidden_dim)\n",
    "\n",
    "        # === Edge MLPs for NNConv\n",
    "        self.edge_mlp_cell_gene = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        self.edge_mlp_gene_pathway = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Message Passing\n",
    "        self.cell_to_gene_conv = NNConv(hidden_dim, hidden_dim, self.edge_mlp_cell_gene, aggr='mean')\n",
    "        self.gene_to_pathway_conv = NNConv(hidden_dim, hidden_dim, self.edge_mlp_gene_pathway, aggr='mean')\n",
    "\n",
    "        # === Attention Pooling\n",
    "        self.att_pool = GlobalAttentionWithWeights(gate_nn=nn.Linear(hidden_dim, 1))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # === Final graph fusion (no virtual node)\n",
    "        self.fuse_global = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Optional auxiliary regression/classification head\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_aux_outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, data, dosage_idx=None):\n",
    "        cell_x = data[\"cell\"].x\n",
    "        gene_x = data[\"gene\"].x\n",
    "        pathway_x = data[\"pathway\"].x\n",
    "\n",
    "        h_cell, h_gene, h_pathway = self.node_encoders(cell_x, gene_x, pathway_x)\n",
    "\n",
    "        # === Graph Convolution\n",
    "        h_gene_updated = self.cell_to_gene_conv(\n",
    "            (h_cell, h_gene),\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_index,\n",
    "            data[\"cell\", \"expresses\", \"gene\"].edge_attr\n",
    "        )\n",
    "        h_pathway_updated = self.gene_to_pathway_conv(\n",
    "            (h_gene_updated, h_pathway),\n",
    "            data[\"gene\", \"involved_in\", \"pathway\"].edge_index,\n",
    "            data[\"gene\", \"involved_in\", \"pathway\"].edge_attr\n",
    "        )\n",
    "\n",
    "        # === Attention Pooling (per-graph)\n",
    "        pooled_pathway, pathway_attention_weights = self.att_pool(\n",
    "            h_pathway_updated,\n",
    "            data['pathway'].batch\n",
    "        )\n",
    "\n",
    "        # === Fallback dosage virtual vector (zeros)\n",
    "        batch_size = pooled_pathway.size(0)\n",
    "        device = pooled_pathway.device\n",
    "        dosage_virtual = torch.zeros(batch_size, self.hidden_dim, device=device)\n",
    "\n",
    "        # === Final graph-level vector\n",
    "        graph_embedding = self.fuse_global(torch.cat([\n",
    "            pooled_pathway,\n",
    "            dosage_virtual\n",
    "        ], dim=1))\n",
    "\n",
    "        aux_output = self.aux_head(graph_embedding)\n",
    "\n",
    "        # === Normalize embeddings\n",
    "        h_cell = F.normalize(h_cell, p=2, dim=-1)\n",
    "        h_gene_updated = F.normalize(h_gene_updated, p=2, dim=-1)\n",
    "        h_pathway_updated = F.normalize(h_pathway_updated, p=2, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"h_cell\": h_cell,\n",
    "            \"h_gene\": h_gene_updated,\n",
    "            \"h_pathway\": h_pathway_updated,\n",
    "            \"dosage_virtual\": dosage_virtual,\n",
    "            \"graph_embedding\": graph_embedding,\n",
    "            \"aux_output\": aux_output.squeeze(),\n",
    "            \"pathway_attention_weights\": pathway_attention_weights\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdd5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HierarchicalDecoder_NoVirtual(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_heads=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # === Pathway seed projection (optional for seeding)\n",
    "        self.pathway_seed_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        # === Gene projection head before query\n",
    "        self.gene_proj_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Query projection for attention\n",
    "        self.gene_query_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Pathway reconstruction MLP\n",
    "        self.decode_to_pathways_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.decode_to_pathways_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "        # === Multi-head attention from pathway ‚Üí gene\n",
    "        self.pathway_to_gene_attn = nn.MultiheadAttention(\n",
    "            hidden_dim, num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "\n",
    "        # === Auxiliary pathway score head\n",
    "        self.aux_pathway_score_head = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, h_pathway_updated, h_gene_updated, graph_embedding, dosage_virtual=None):\n",
    "        B, N_pathways, H = h_pathway_updated.size()\n",
    "        _, N_genes, _ = h_gene_updated.size()\n",
    "\n",
    "        # === Use raw graph embedding (no dosage addition)\n",
    "        graph_expanded = graph_embedding.unsqueeze(1).expand(-1, N_pathways, -1)\n",
    "        pathway_input = torch.cat([h_pathway_updated, graph_expanded], dim=-1)\n",
    "        pathway_hidden = self.decode_to_pathways_fc(pathway_input)\n",
    "        pathway_recon = self.decode_to_pathways_proj(pathway_hidden)  # [B, N_pathways, H]\n",
    "\n",
    "        # === Gene reconstruction via attention\n",
    "        h_gene_projected = self.gene_proj_head(h_gene_updated)\n",
    "        gene_query = self.gene_query_proj(h_gene_projected)\n",
    "\n",
    "        gene_recon, attn_p2g = self.pathway_to_gene_attn(\n",
    "            query=gene_query,\n",
    "            key=pathway_recon,\n",
    "            value=pathway_recon,\n",
    "            key_padding_mask=None,\n",
    "            need_weights=True\n",
    "        )\n",
    "\n",
    "        gene_recon = F.dropout(gene_recon, p=0.1, training=self.training) + gene_query\n",
    "        gene_recon = F.normalize(gene_recon, p=2, dim=-1)\n",
    "\n",
    "        aux_pathway_scores = self.aux_pathway_score_head(pathway_recon).squeeze(-1)\n",
    "\n",
    "        return {\n",
    "            \"reconstructed_pathways\": pathway_recon,\n",
    "            \"reconstructed_genes\": gene_recon,\n",
    "            \"aux_pathway_scores\": aux_pathway_scores,\n",
    "            \"attention_pathway_to_gene\": attn_p2g\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class HierarchicalLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lambda_pathway=1.0,\n",
    "        lambda_gene=1.0,\n",
    "        lambda_attention=0.2,\n",
    "        use_stat_alignment=True,\n",
    "        reduction='mean'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lambda_pathway = lambda_pathway\n",
    "        self.lambda_gene = lambda_gene\n",
    "        self.lambda_attention = lambda_attention\n",
    "        self.use_stat_alignment = use_stat_alignment\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        loss_components = {}\n",
    "\n",
    "        # Pathway reconstruction loss\n",
    "        L_pathway = F.mse_loss(\n",
    "            outputs[\"reconstructed_pathways\"],\n",
    "            targets[\"h_pathway\"],\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "        loss_components[\"pathway_loss\"] = L_pathway\n",
    "\n",
    "        # Gene reconstruction loss\n",
    "        recon = outputs[\"reconstructed_genes\"]\n",
    "        target = targets[\"h_gene\"]\n",
    "        L_gene = F.mse_loss(recon, target, reduction=self.reduction)\n",
    "\n",
    "        if self.use_stat_alignment:\n",
    "            std_diff = F.mse_loss(recon.std(dim=1), target.std(dim=1), reduction=self.reduction)\n",
    "            mean_diff = F.mse_loss(recon.mean(dim=1), target.mean(dim=1), reduction=self.reduction)\n",
    "            L_gene += 0.2 * (std_diff + mean_diff)\n",
    "\n",
    "        loss_components[\"gene_loss\"] = L_gene\n",
    "\n",
    "        # Attention regularization\n",
    "        attn = outputs.get(\"attention_pathway_to_gene\", None)\n",
    "        if attn is not None:\n",
    "            if attn.dim() == 4:\n",
    "                entropy = -(attn * torch.log(attn + 1e-8)).sum(dim=-1).mean()\n",
    "            elif attn.dim() == 3:\n",
    "                entropy = -(attn * torch.log(attn + 1e-8)).sum(dim=-1).mean()\n",
    "            else:\n",
    "                entropy = torch.tensor(0.0, device=attn.device)\n",
    "        else:\n",
    "            entropy = torch.tensor(0.0, device=recon.device)\n",
    "\n",
    "        loss_components[\"attention_reg_loss\"] = entropy\n",
    "\n",
    "        total = (\n",
    "            self.lambda_pathway * L_pathway +\n",
    "            self.lambda_gene * L_gene +\n",
    "            self.lambda_attention * entropy\n",
    "        )\n",
    "        loss_components[\"total_loss\"] = total\n",
    "\n",
    "        return total, loss_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b347d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_encoder_decoder_model(\n",
    "    encoder, decoder, graphs_list, dosage_to_idx,\n",
    "    optimizer=None,\n",
    "    device='cuda',\n",
    "    epochs=100,\n",
    "    loss_weights=None,\n",
    "    save_path=None,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    patience=30,\n",
    "    min_delta=1e-3,\n",
    "    batch_size=2\n",
    "):\n",
    "    import os\n",
    "    import json\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    loss_kwargs = {k: v for k, v in (loss_weights or {}).items() if k not in [\"log_grad_norm\", \"monitored_losses\"]}\n",
    "    criterion = HierarchicalLoss(**loss_kwargs).to(device)\n",
    "\n",
    "    monitored_keys = loss_weights.get(\"monitored_losses\", [\"total_loss\"]) if loss_weights else [\"total_loss\"]\n",
    "    best_monitored_loss = {k: float(\"inf\") for k in monitored_keys} if len(monitored_keys) > 1 else float(\"inf\")\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = Adam(\n",
    "            list(encoder.parameters()) + list(decoder.parameters()),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5, verbose=True, min_lr=1e-5)\n",
    "    loader = DataLoader(graphs_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    loss_log = []\n",
    "    attention_log = []\n",
    "    best_recon_outputs_log = []  # ‚úÖ Best epoch only\n",
    "    best_epoch = 0\n",
    "    best_model = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        epoch_loss_dict = {k: 0.0 for k in [\"pathway_loss\", \"gene_loss\", \"attention_reg_loss\", \"total_loss\"]}\n",
    "        epoch_attn_entropy = []\n",
    "        current_recon_outputs_log = []  # ‚úÖ This epoch only\n",
    "\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            encoder_out = encoder(batch, batch.dosage_idx)\n",
    "            h_pathway, _ = to_dense_batch(encoder_out[\"h_pathway\"], batch[\"pathway\"].batch)\n",
    "            h_gene, _ = to_dense_batch(encoder_out[\"h_gene\"], batch[\"gene\"].batch)\n",
    "\n",
    "            decoder_out = decoder(\n",
    "                h_pathway_updated=h_pathway,\n",
    "                h_gene_updated=h_gene,\n",
    "                graph_embedding=encoder_out[\"graph_embedding\"],\n",
    "                dosage_virtual=encoder_out.get(\"dosage_virtual\", None)\n",
    "            )\n",
    "\n",
    "            targets = {\n",
    "                \"h_pathway\": h_pathway.detach(),\n",
    "                \"h_gene\": h_gene.detach()\n",
    "            }\n",
    "\n",
    "            loss, loss_components = criterion(decoder_out, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            for key in epoch_loss_dict:\n",
    "                epoch_loss_dict[key] += loss_components[key].item()\n",
    "\n",
    "            current_recon_outputs_log.append({\n",
    "                \"dosage_idx\": int(batch.dosage_idx.item()),\n",
    "                \"real_h_pathway\": h_pathway.detach().cpu().tolist(),\n",
    "                \"real_h_gene\": h_gene.detach().cpu().tolist(),\n",
    "                \"reconstructed_pathways\": decoder_out[\"reconstructed_pathways\"].detach().cpu().tolist(),\n",
    "                \"reconstructed_genes\": decoder_out[\"reconstructed_genes\"].detach().cpu().tolist(),\n",
    "                \"attention\": decoder_out.get(\"attention_pathway_to_gene\", None).detach().cpu().tolist()\n",
    "                    if decoder_out.get(\"attention_pathway_to_gene\") is not None else None\n",
    "            })\n",
    "\n",
    "            # Attention entropy\n",
    "            attn = decoder_out.get(\"attention_pathway_to_gene\", None)\n",
    "            if attn is not None:\n",
    "                entropy = (-attn * torch.log(attn + 1e-6)).sum(dim=-1)\n",
    "                entropy = entropy.mean(dim=-1).mean(dim=0)\n",
    "                epoch_attn_entropy.append(entropy.detach().cpu())\n",
    "\n",
    "        num_batches = len(loader)\n",
    "        avg_loss_dict = {k: v / num_batches for k, v in epoch_loss_dict.items()}\n",
    "        loss_log.append(avg_loss_dict)\n",
    "\n",
    "        if epoch_attn_entropy:\n",
    "            mean_entropy_tensor = torch.stack(epoch_attn_entropy).mean(dim=0)\n",
    "            mean_entropy = mean_entropy_tensor.tolist() if mean_entropy_tensor.ndim > 0 else [mean_entropy_tensor.item()]\n",
    "            print(\"Epoch {:03d} | Attention Entropy per Head: {}\".format(epoch+1, [\"{:.4f}\".format(e) for e in mean_entropy]))\n",
    "            attention_log.append(mean_entropy)\n",
    "\n",
    "        scheduler.step(avg_loss_dict[\"total_loss\"])\n",
    "\n",
    "        improvement = False\n",
    "        for k in monitored_keys:\n",
    "            current = avg_loss_dict[k]\n",
    "            if isinstance(best_monitored_loss, dict):\n",
    "                if current < best_monitored_loss[k] - min_delta:\n",
    "                    best_monitored_loss[k] = current\n",
    "                    improvement = True\n",
    "            else:\n",
    "                if current < best_monitored_loss - min_delta:\n",
    "                    best_monitored_loss = current\n",
    "                    improvement = True\n",
    "\n",
    "        print(\"Epoch {:03d} | Total: {:.4f} | P: {:.4f}, G: {:.4f}, A: {:.4f} | Graph Norm: {:.4f}\".format(\n",
    "            epoch+1, avg_loss_dict['total_loss'], avg_loss_dict['pathway_loss'],\n",
    "            avg_loss_dict['gene_loss'], avg_loss_dict['attention_reg_loss'],\n",
    "            encoder_out[\"graph_embedding\"].norm().item()\n",
    "        ))\n",
    "\n",
    "        if improvement:\n",
    "            best_epoch = epoch + 1\n",
    "            epochs_no_improve = 0\n",
    "            best_model = {\n",
    "                \"encoder\": encoder.state_dict(),\n",
    "                \"decoder\": decoder.state_dict()\n",
    "            }\n",
    "            best_recon_outputs_log = current_recon_outputs_log  # ‚úÖ Update best outputs\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping at epoch {} after {} stagnant epochs.\".format(epoch+1, patience))\n",
    "            break\n",
    "\n",
    "    # === Save best model + logs\n",
    "    if save_path and best_model:\n",
    "        torch.save(best_model, save_path)\n",
    "        print(\"‚úÖ Best model saved to:\", save_path)\n",
    "\n",
    "        with open(save_path.replace(\".pth\", \"_loss_log.json\"), \"w\") as f:\n",
    "            json.dump(loss_log, f, indent=2)\n",
    "\n",
    "        with open(save_path.replace(\".pth\", \"_attn_entropy.json\"), \"w\") as f:\n",
    "            json.dump(attention_log, f, indent=2)\n",
    "\n",
    "        with open(save_path.replace(\".pth\", \"_recon_outputs.json\"), \"w\") as f:\n",
    "            json.dump(best_recon_outputs_log, f, indent=2)  # ‚úÖ Only best\n",
    "\n",
    "        print(\"üìà Logs (loss, attention, recon outputs) saved successfully.\")\n",
    "\n",
    "    return encoder, decoder, loss_log, best_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a366eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# === Step 1: Load graphs\n",
    "graph_dir = \"Graph_Results/HeteroGraphs_ScaledFinal\"\n",
    "graphs_list, dosage_to_idx = load_all_dosage_graphs_for_batching(graph_dir)\n",
    "\n",
    "# === Step 2: Instantiate No-Virtual models\n",
    "hidden_dim = 64\n",
    "encoder = SharedHierarchicalEncoder_NoVirtual(hidden_dim=hidden_dim)\n",
    "decoder = HierarchicalDecoder_NoVirtual(hidden_dim=hidden_dim)\n",
    "\n",
    "# === Step 3: Define loss weights\n",
    "loss_weights = {\n",
    "    \"lambda_pathway\": 2.0,\n",
    "    \"lambda_gene\": 1.0,\n",
    "    \"lambda_attention\": 0.2,\n",
    "    \"use_stat_alignment\": True,\n",
    "    \"log_grad_norm\": True,\n",
    "    \"monitored_losses\": [\"total_loss\"]\n",
    "}\n",
    "\n",
    "# === Step 4: Train\n",
    "trained_encoder, trained_decoder, loss_log, best_epoch = train_encoder_decoder_model(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    graphs_list=graphs_list,\n",
    "    dosage_to_idx=dosage_to_idx,\n",
    "    device='cpu',\n",
    "    epochs=30,\n",
    "    save_path=\"trained_model_no_virtual.pth\",   # üîß New file name for clarity\n",
    "    loss_weights=loss_weights,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Best Epoch: {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba2328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# === Step 1: Load graphs and dosage map\n",
    "graph_dir = \"Graph_Results/HeteroGraphs_ScaledFinal\"\n",
    "graphs_list, dosage_to_idx = load_all_dosage_graphs_for_batching(graph_dir)\n",
    "\n",
    "# === Step 2: Instantiate model architectures (no virtual node)\n",
    "hidden_dim = 64\n",
    "encoder = SharedHierarchicalEncoder_NoVirtual(hidden_dim=hidden_dim)\n",
    "decoder = HierarchicalDecoder_NoVirtual(hidden_dim=hidden_dim)\n",
    "\n",
    "# === Step 3: Load trained weights\n",
    "checkpoint_path = \"trained_model_no_virtual.pth\"  # ‚úÖ Use correct path for no-virtual checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')  # or 'cuda' if using GPU\n",
    "\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "decoder.load_state_dict(checkpoint['decoder'])\n",
    "\n",
    "# === Step 4: Set to evaluation mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# === Step 5 (optional): Move to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "print(\"‚úÖ No-Virtual-Node model loaded and ready for inference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load JSON output from LSTM-free attention-enabled model ===\n",
    "with open(\"trained_model_no_virtual_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "print(f\"Total entries in JSON: {len(recon_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load saved recon output from No-Virtual-Node model ===\n",
    "with open(\"trained_model_no_virtual_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "# === Mapping index to dosage label ===\n",
    "idx_to_dosage = {\n",
    "    0: \"T1\", 1: \"T2.5\", 2: \"T5\", 3: \"T10\", 4: \"T20\",\n",
    "    5: \"T40\", 6: \"T80\", 7: \"T160\", 8: \"T320\"\n",
    "}\n",
    "\n",
    "# === Prepare containers\n",
    "real_feats = []\n",
    "recon_feats = []\n",
    "labels = []\n",
    "\n",
    "for entry in recon_data:\n",
    "    dosage_name = idx_to_dosage[entry[\"dosage_idx\"]]\n",
    "\n",
    "    recon_gene = np.array(entry[\"reconstructed_genes\"]).squeeze(0)   # [N_genes, H]\n",
    "    real_gene = np.array(entry[\"real_h_gene\"]).squeeze(0)           # [N_genes, H]\n",
    "\n",
    "    recon_feats.append(recon_gene)\n",
    "    real_feats.append(real_gene)\n",
    "    labels += [dosage_name] * recon_gene.shape[0]\n",
    "\n",
    "# === Stack features\n",
    "recon_all = np.vstack(recon_feats)\n",
    "real_all = np.vstack(real_feats)\n",
    "\n",
    "# === Run UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=30, min_dist=0.3, metric=\"euclidean\", random_state=42)\n",
    "real_umap = umap_model.fit_transform(real_all)\n",
    "recon_umap = umap_model.fit_transform(recon_all)\n",
    "\n",
    "# === Create DataFrames\n",
    "real_df = pd.DataFrame(real_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "real_df[\"Dosage\"] = labels\n",
    "real_df[\"Type\"] = \"Real\"\n",
    "\n",
    "recon_df = pd.DataFrame(recon_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "recon_df[\"Dosage\"] = labels\n",
    "recon_df[\"Type\"] = \"Reconstructed\"\n",
    "\n",
    "# === Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(data=real_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[0],\n",
    "                s=40, alpha=0.7, palette=\"tab10\")\n",
    "axes[0].set_title(\"UMAP of Real Gene Embeddings (No Virtual Node)\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "sns.scatterplot(data=recon_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[1],\n",
    "                s=40, alpha=0.7, palette=\"tab10\")\n",
    "axes[1].set_title(\"UMAP of Reconstructed Gene Embeddings (No Virtual Node)\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"UMAP_GENE_novirtual_attention.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a428b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# === Load reconstructions ===\n",
    "with open(\"trained_model_no_virtual_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "# === Index to dosage mapping ===\n",
    "idx_to_dosage = {\n",
    "    0: \"T1\", 1: \"T2.5\", 2: \"T5\", 3: \"T10\", 4: \"T20\",\n",
    "    5: \"T40\", 6: \"T80\", 7: \"T160\", 8: \"T320\"\n",
    "}\n",
    "\n",
    "# === Collect metrics\n",
    "metrics = []\n",
    "\n",
    "for entry in recon_data:\n",
    "    dosage = idx_to_dosage[entry[\"dosage_idx\"]]\n",
    "\n",
    "    real_gene = np.array(entry[\"real_h_gene\"]).squeeze(0)\n",
    "    recon_gene = np.array(entry[\"reconstructed_genes\"]).squeeze(0)\n",
    "\n",
    "    cos_sim = np.mean([\n",
    "        cosine_similarity(real_gene[i].reshape(1, -1), recon_gene[i].reshape(1, -1))[0, 0]\n",
    "        for i in range(real_gene.shape[0])\n",
    "    ])\n",
    "    mse = mean_squared_error(real_gene, recon_gene)\n",
    "\n",
    "    metrics.append({\n",
    "        \"Dosage\": dosage,\n",
    "        \"CosineSimilarity\": cos_sim,\n",
    "        \"MSE\": mse\n",
    "    })\n",
    "\n",
    "# === Aggregate by dosage\n",
    "df = pd.DataFrame(metrics)\n",
    "df_summary = df.groupby(\"Dosage\").mean().reset_index()\n",
    "\n",
    "# === Optional: sort dosages in order\n",
    "dosage_order = [\"T1\", \"T2.5\", \"T5\", \"T10\", \"T20\", \"T40\", \"T80\", \"T160\", \"T320\"]\n",
    "df_summary[\"Dosage\"] = pd.Categorical(df_summary[\"Dosage\"], categories=dosage_order, ordered=True)\n",
    "df_summary = df_summary.sort_values(\"Dosage\")\n",
    "\n",
    "# === Print the result\n",
    "print(\"===== Per-Dosage Gene Reconstruction Metrics (No Virtual Node) =====\")\n",
    "print(df_summary.to_string(index=False, float_format=\"%.6f\"))\n",
    "\n",
    "# === Optional: Save to CSV\n",
    "df_summary.to_csv(\"metrics_per_dosage_novirtual.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Load JSON outputs from No Virtual Node model ===\n",
    "with open(\"trained_model_no_virtual_recon_outputs.json\", \"r\") as f:\n",
    "    recon_data = json.load(f)\n",
    "\n",
    "# === Dosage index to label mapping ===\n",
    "idx_to_dosage = {\n",
    "    0: \"T1\", 1: \"T2.5\", 2: \"T5\", 3: \"T10\", 4: \"T20\",\n",
    "    5: \"T40\", 6: \"T80\", 7: \"T160\", 8: \"T320\"\n",
    "}\n",
    "\n",
    "# === Containers for pathway embeddings\n",
    "real_feats = []\n",
    "recon_feats = []\n",
    "labels = []\n",
    "\n",
    "# === Aggregate pathway-level features\n",
    "for entry in recon_data:\n",
    "    dosage = idx_to_dosage[entry[\"dosage_idx\"]]\n",
    "\n",
    "    real_pw = np.array(entry[\"real_h_pathway\"]).squeeze(0)\n",
    "    recon_pw = np.array(entry[\"reconstructed_pathways\"]).squeeze(0)\n",
    "\n",
    "    real_feats.append(real_pw)\n",
    "    recon_feats.append(recon_pw)\n",
    "    labels += [dosage] * real_pw.shape[0]\n",
    "\n",
    "# === Stack real and reconstructed pathway embeddings\n",
    "real_all = np.vstack(real_feats)\n",
    "recon_all = np.vstack(recon_feats)\n",
    "\n",
    "# === Apply UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, metric=\"cosine\", random_state=42)\n",
    "real_umap = umap_model.fit_transform(real_all)\n",
    "recon_umap = umap_model.fit_transform(recon_all)\n",
    "\n",
    "# === Create DataFrames for plotting\n",
    "real_df = pd.DataFrame(real_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "real_df[\"Dosage\"] = labels\n",
    "real_df[\"Type\"] = \"Real\"\n",
    "\n",
    "recon_df = pd.DataFrame(recon_umap, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "recon_df[\"Dosage\"] = labels\n",
    "recon_df[\"Type\"] = \"Reconstructed\"\n",
    "\n",
    "# === Plot side-by-side UMAPs\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(data=real_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[0],\n",
    "                s=40, alpha=0.7, palette=\"tab10\")\n",
    "axes[0].set_title(\"UMAP of Real Pathway Embeddings (No Virtual Node)\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "sns.scatterplot(data=recon_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"Dosage\", ax=axes[1],\n",
    "                s=40, alpha=0.7, palette=\"tab10\")\n",
    "axes[1].set_title(\"UMAP of Reconstructed Pathway Embeddings (No Virtual Node)\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"UMAP_PATHWAY_novirtual_attention.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41335381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === Ensure labels are numpy array\n",
    "labels = np.array(labels)\n",
    "\n",
    "# === Dosages in correct order\n",
    "dosages = [\"T1\", \"T2.5\", \"T5\", \"T10\", \"T20\", \"T40\", \"T80\", \"T160\", \"T320\"]\n",
    "\n",
    "# === Containers\n",
    "mse_per_dosage = []\n",
    "cosine_per_dosage = []\n",
    "\n",
    "# === Per-dosage reconstruction metrics\n",
    "for d in dosages:\n",
    "    idxs = labels == d\n",
    "    real_d = real_all[idxs]\n",
    "    recon_d = recon_all[idxs]\n",
    "\n",
    "    mse = mean_squared_error(real_d, recon_d)\n",
    "    cos_sim = np.mean(np.diag(cosine_similarity(real_d, recon_d)))\n",
    "\n",
    "    mse_per_dosage.append(mse)\n",
    "    cosine_per_dosage.append(cos_sim)\n",
    "\n",
    "# === Overall reconstruction metrics\n",
    "overall_mse = mean_squared_error(real_all, recon_all)\n",
    "overall_cosine = np.mean(np.diag(cosine_similarity(real_all, recon_all)))\n",
    "\n",
    "# === Create final summary table\n",
    "df_eval = pd.DataFrame({\n",
    "    \"Dosage\": dosages + [\"Overall\"],\n",
    "    \"MSE\": mse_per_dosage + [overall_mse],\n",
    "    \"CosineSimilarity\": cosine_per_dosage + [overall_cosine]\n",
    "})\n",
    "\n",
    "# === Show results\n",
    "print(\"\\n===== Per-Dosage Pathway Reconstruction Metrics (No Virtual Node) =====\")\n",
    "print(df_eval.round(6))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "pyg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
